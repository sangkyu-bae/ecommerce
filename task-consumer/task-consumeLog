2023-12-01 15:42:55.324 INFO  ---- [tartedMain] [TaskConsumerApplication:55] logStarting   Starting TaskConsumerApplication using Java 11.0.13 on DESKTOP-MNMB87E with PID 440 (C:\Users\tkdrb\IdeaProjects\ecommerce\task-consumer\build\classes\java\main started by tkdrb in C:\Users\tkdrb\IdeaProjects\ecommerce\task-consumer)
2023-12-01 15:42:55.374 INFO  ---- [tartedMain] [TaskConsumerApplication:631] logStartupProfileInfo   No active profile set, falling back to 1 default profile: "default"
2023-12-01 15:42:55.611 INFO  ---- [tartedMain] [DevToolsPropertyDefaultsPostProcessor:255] logTo   Devtools property defaults active! Set 'spring.devtools.add-properties' to 'false' to disable
2023-12-01 15:42:55.613 INFO  ---- [tartedMain] [DevToolsPropertyDefaultsPostProcessor:255] logTo   For additional web related logging consider setting the 'logging.level.web' property to 'DEBUG'
2023-12-01 15:42:58.716 INFO  ---- [tartedMain] [GenericScope:283] setSerializationId   BeanFactory id=7d336d03-7948-373b-80b2-3edd326128fe
2023-12-01 15:43:02.063 INFO  ---- [tartedMain] [TomcatWebServer:108] initialize   Tomcat initialized with port(s): 0 (http)
2023-12-01 15:43:02.087 INFO  ---- [tartedMain] [StandardService:173] log   Starting service [Tomcat]
2023-12-01 15:43:02.088 INFO  ---- [tartedMain] [StandardEngine:173] log   Starting Servlet engine: [Apache Tomcat/9.0.76]
2023-12-01 15:43:02.477 INFO  ---- [tartedMain] [[/]:173] log   Initializing Spring embedded WebApplicationContext
2023-12-01 15:43:02.478 INFO  ---- [tartedMain] [ServletWebServerApplicationContext:292] prepareWebApplicationContext   Root WebApplicationContext: initialization completed in 6863 ms
2023-12-01 15:43:03.701 INFO  ---- [tartedMain] [OptionalLiveReloadServer:59] startServer   LiveReload server is running on port 35729
2023-12-01 15:43:06.963 INFO  ---- [tartedMain] [DiscoveryClientOptionalArgsConfiguration:71] restTemplateDiscoveryClientOptionalArgs   Eureka HTTP Client uses RestTemplate.
2023-12-01 15:43:12.297 WARN  ---- [tartedMain] [LoadBalancerCacheAutoConfiguration$LoadBalancerCaffeineWarnLogger:83] logWarning   Spring Cloud LoadBalancer is currently working with the default cache. While this cache implementation is useful for development and tests, it's recommended to use Caffeine cache in production.You can switch to using Caffeine cache, by adding it and org.springframework.cache.caffeine.CaffeineCacheManager to the classpath.
2023-12-01 15:43:15.778 INFO  ---- [tartedMain] [ConsumerConfig:376] logAll   ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-order.group.v1-1
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = order.group.v1
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2023-12-01 15:43:16.719 INFO  ---- [tartedMain] [AppInfoParser:119] <init>   Kafka version: 3.1.2
2023-12-01 15:43:16.725 INFO  ---- [tartedMain] [AppInfoParser:120] <init>   Kafka commitId: f8c67dc3ae0a3265
2023-12-01 15:43:16.741 INFO  ---- [tartedMain] [AppInfoParser:121] <init>   Kafka startTimeMs: 1701412996702
2023-12-01 15:43:16.759 INFO  ---- [tartedMain] [KafkaConsumer:966] subscribe   [Consumer clientId=consumer-order.group.v1-1, groupId=order.group.v1] Subscribed to topic(s): order
2023-12-01 15:43:16.898 INFO  ---- [tartedMain] [ConsumerConfig:376] logAll   ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-task.product.v1-2
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = task.product.v1
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2023-12-01 15:43:16.929 INFO  ---- [tartedMain] [AppInfoParser:119] <init>   Kafka version: 3.1.2
2023-12-01 15:43:16.930 INFO  ---- [tartedMain] [AppInfoParser:120] <init>   Kafka commitId: f8c67dc3ae0a3265
2023-12-01 15:43:16.932 INFO  ---- [tartedMain] [AppInfoParser:121] <init>   Kafka startTimeMs: 1701412996929
2023-12-01 15:43:16.942 INFO  ---- [tartedMain] [KafkaConsumer:966] subscribe   [Consumer clientId=consumer-task.product.v1-2, groupId=task.product.v1] Subscribed to topic(s): task-product
2023-12-01 15:43:16.956 INFO  ---- [tartedMain] [ConsumerConfig:376] logAll   ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-task.member.v1-3
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = task.member.v1
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2023-12-01 15:43:16.982 INFO  ---- [tartedMain] [AppInfoParser:119] <init>   Kafka version: 3.1.2
2023-12-01 15:43:16.990 INFO  ---- [tartedMain] [AppInfoParser:120] <init>   Kafka commitId: f8c67dc3ae0a3265
2023-12-01 15:43:16.991 INFO  ---- [tartedMain] [AppInfoParser:121] <init>   Kafka startTimeMs: 1701412996982
2023-12-01 15:43:16.993 INFO  ---- [tartedMain] [KafkaConsumer:966] subscribe   [Consumer clientId=consumer-task.member.v1-3, groupId=task.member.v1] Subscribed to topic(s): task-member
2023-12-01 15:43:17.250 INFO  ---- [tartedMain] [TomcatWebServer:220] start   Tomcat started on port(s): 58950 (http) with context path ''
2023-12-01 15:43:17.255 INFO  ---- [tartedMain] [EurekaAutoServiceRegistration:144] onApplicationEvent   Updating port to 58950
2023-12-01 15:43:17.271 INFO  ---- [tartedMain] [InstanceInfoFactory:67] create   Setting initial instance status as: STARTING
2023-12-01 15:43:17.615 INFO  ---- [tartedMain] [DiscoveryClient:372] <init>   Initializing Eureka in region us-east-1
2023-12-01 15:43:17.675 INFO  ---- [tartedMain] [ConfigClusterResolver:43] getClusterEndpoints   Resolving eureka endpoints via configuration
2023-12-01 15:43:17.801 INFO  ---- [tartedMain] [DiscoveryClient:1007] fetchRegistry   Disable delta property : false
2023-12-01 15:43:17.804 INFO  ---- [tartedMain] [DiscoveryClient:1008] fetchRegistry   Single vip registry refresh property : null
2023-12-01 15:43:17.809 INFO  ---- [tartedMain] [DiscoveryClient:1009] fetchRegistry   Force full registry fetch : false
2023-12-01 15:43:17.812 INFO  ---- [tartedMain] [DiscoveryClient:1010] fetchRegistry   Application is null : false
2023-12-01 15:43:17.813 INFO  ---- [tartedMain] [DiscoveryClient:1011] fetchRegistry   Registered Applications size is zero : true
2023-12-01 15:43:17.814 INFO  ---- [tartedMain] [DiscoveryClient:1013] fetchRegistry   Application version is -1: true
2023-12-01 15:43:17.815 INFO  ---- [tartedMain] [DiscoveryClient:1097] getAndStoreFullRegistry   Getting all instance registry info from the eureka server
2023-12-01 15:43:20.956 INFO  ---- [tartedMain] [DiscoveryClient:1106] getAndStoreFullRegistry   The response status is 200
2023-12-01 15:43:20.968 INFO  ---- [tartedMain] [DiscoveryClient:1321] initScheduledTasks   Starting heartbeat executor: renew interval is: 30
2023-12-01 15:43:20.979 INFO  ---- [tartedMain] [InstanceInfoReplicator:60] <init>   InstanceInfoReplicator onDemand update allowed rate per min is 4
2023-12-01 15:43:21.058 INFO  ---- [tartedMain] [DiscoveryClient:492] <init>   Discovery Client initialized at timestamp 1701413000997 with initial instances count: 0
2023-12-01 15:43:21.065 INFO  ---- [tartedMain] [EurekaServiceRegistry:41] register   Registering application TASK-SERVICE with eureka with status UP
2023-12-01 15:43:21.069 INFO  ---- [tartedMain] [DiscoveryClient:1352] notify   Saw local status change event StatusChangeEvent [timestamp=1701413001069, current=UP, previous=STARTING]
2023-12-01 15:43:21.075 INFO  ---- [plicator-0] [DiscoveryClient:873] register   DiscoveryClient_TASK-SERVICE/192.168.0.17:6f51861f2dedd59369f6de219195a800: registering service...
2023-12-01 15:43:21.331 INFO  ---- [plicator-0] [DiscoveryClient:882] register   DiscoveryClient_TASK-SERVICE/192.168.0.17:6f51861f2dedd59369f6de219195a800 - registration status: 204
2023-12-01 15:43:21.660 INFO  ---- [er#0-0-C-1] [Metadata:402] updateLatestMetadata   [Consumer clientId=consumer-task.product.v1-2, groupId=task.product.v1] Resetting the last seen epoch of partition task-product-0 to 9 since the associated topicId changed from null to h57hDuqlT3KmUT32pFF5uQ
2023-12-01 15:43:21.660 INFO  ---- [er#2-0-C-1] [Metadata:402] updateLatestMetadata   [Consumer clientId=consumer-order.group.v1-1, groupId=order.group.v1] Resetting the last seen epoch of partition order-0 to 0 since the associated topicId changed from null to 8AIo0qkzSIiGJbn1bQxAkw
2023-12-01 15:43:21.663 INFO  ---- [er#1-0-C-1] [Metadata:402] updateLatestMetadata   [Consumer clientId=consumer-task.member.v1-3, groupId=task.member.v1] Resetting the last seen epoch of partition task-member-0 to 9 since the associated topicId changed from null to HvfbkcRhQ3meTIJFgCt9zw
2023-12-01 15:43:21.667 INFO  ---- [er#0-0-C-1] [Metadata:287] update   [Consumer clientId=consumer-task.product.v1-2, groupId=task.product.v1] Cluster ID: 5_U1uds-SGaR4vItj-jqUw
2023-12-01 15:43:21.667 INFO  ---- [er#1-0-C-1] [Metadata:287] update   [Consumer clientId=consumer-task.member.v1-3, groupId=task.member.v1] Cluster ID: 5_U1uds-SGaR4vItj-jqUw
2023-12-01 15:43:21.668 INFO  ---- [er#2-0-C-1] [Metadata:287] update   [Consumer clientId=consumer-order.group.v1-1, groupId=order.group.v1] Cluster ID: 5_U1uds-SGaR4vItj-jqUw
2023-12-01 15:43:21.671 INFO  ---- [er#0-0-C-1] [ConsumerCoordinator:853] onSuccess   [Consumer clientId=consumer-task.product.v1-2, groupId=task.product.v1] Discovered group coordinator 127.0.0.1:9091 (id: 2147483646 rack: null)
2023-12-01 15:43:21.671 INFO  ---- [er#1-0-C-1] [ConsumerCoordinator:853] onSuccess   [Consumer clientId=consumer-task.member.v1-3, groupId=task.member.v1] Discovered group coordinator 127.0.0.1:9093 (id: 2147483644 rack: null)
2023-12-01 15:43:21.671 INFO  ---- [er#2-0-C-1] [ConsumerCoordinator:853] onSuccess   [Consumer clientId=consumer-order.group.v1-1, groupId=order.group.v1] Discovered group coordinator 127.0.0.1:9091 (id: 2147483646 rack: null)
2023-12-01 15:43:21.680 INFO  ---- [er#2-0-C-1] [ConsumerCoordinator:535] sendJoinGroupRequest   [Consumer clientId=consumer-order.group.v1-1, groupId=order.group.v1] (Re-)joining group
2023-12-01 15:43:21.681 INFO  ---- [er#0-0-C-1] [ConsumerCoordinator:535] sendJoinGroupRequest   [Consumer clientId=consumer-task.product.v1-2, groupId=task.product.v1] (Re-)joining group
2023-12-01 15:43:21.681 INFO  ---- [er#1-0-C-1] [ConsumerCoordinator:535] sendJoinGroupRequest   [Consumer clientId=consumer-task.member.v1-3, groupId=task.member.v1] (Re-)joining group
2023-12-01 15:43:22.448 INFO  ---- [er#2-0-C-1] [ConsumerCoordinator:1000] requestRejoin   [Consumer clientId=consumer-order.group.v1-1, groupId=order.group.v1] Request joining group due to: need to re-join with the given member-id
2023-12-01 15:43:22.448 INFO  ---- [er#0-0-C-1] [ConsumerCoordinator:1000] requestRejoin   [Consumer clientId=consumer-task.product.v1-2, groupId=task.product.v1] Request joining group due to: need to re-join with the given member-id
2023-12-01 15:43:22.449 INFO  ---- [er#2-0-C-1] [ConsumerCoordinator:535] sendJoinGroupRequest   [Consumer clientId=consumer-order.group.v1-1, groupId=order.group.v1] (Re-)joining group
2023-12-01 15:43:22.449 INFO  ---- [er#0-0-C-1] [ConsumerCoordinator:535] sendJoinGroupRequest   [Consumer clientId=consumer-task.product.v1-2, groupId=task.product.v1] (Re-)joining group
2023-12-01 15:43:22.888 INFO  ---- [er#1-0-C-1] [ConsumerCoordinator:1000] requestRejoin   [Consumer clientId=consumer-task.member.v1-3, groupId=task.member.v1] Request joining group due to: need to re-join with the given member-id
2023-12-01 15:43:22.889 INFO  ---- [er#1-0-C-1] [ConsumerCoordinator:535] sendJoinGroupRequest   [Consumer clientId=consumer-task.member.v1-3, groupId=task.member.v1] (Re-)joining group
2023-12-01 15:43:25.803 INFO  ---- [er#2-0-C-1] [ConsumerCoordinator:595] handle   [Consumer clientId=consumer-order.group.v1-1, groupId=order.group.v1] Successfully joined group with generation Generation{generationId=5, memberId='consumer-order.group.v1-1-1dad7d98-9a02-435f-bb54-5d711e3b3e53', protocol='range'}
2023-12-01 15:43:25.803 INFO  ---- [er#0-0-C-1] [ConsumerCoordinator:595] handle   [Consumer clientId=consumer-task.product.v1-2, groupId=task.product.v1] Successfully joined group with generation Generation{generationId=48, memberId='consumer-task.product.v1-2-6bd5591f-ce67-456f-8e3f-5b284b0ad917', protocol='range'}
2023-12-01 15:43:25.812 INFO  ---- [er#0-0-C-1] [ConsumerCoordinator:659] performAssignment   [Consumer clientId=consumer-task.product.v1-2, groupId=task.product.v1] Finished assignment for group at generation 48: {consumer-task.product.v1-2-6bd5591f-ce67-456f-8e3f-5b284b0ad917=Assignment(partitions=[task-product-0])}
2023-12-01 15:43:25.812 INFO  ---- [er#2-0-C-1] [ConsumerCoordinator:659] performAssignment   [Consumer clientId=consumer-order.group.v1-1, groupId=order.group.v1] Finished assignment for group at generation 5: {consumer-order.group.v1-1-1dad7d98-9a02-435f-bb54-5d711e3b3e53=Assignment(partitions=[order-0])}
2023-12-01 15:43:26.004 INFO  ---- [er#1-0-C-1] [ConsumerCoordinator:595] handle   [Consumer clientId=consumer-task.member.v1-3, groupId=task.member.v1] Successfully joined group with generation Generation{generationId=48, memberId='consumer-task.member.v1-3-f2dea481-6259-48dd-a486-e6e9d773f3bd', protocol='range'}
2023-12-01 15:43:26.005 INFO  ---- [er#1-0-C-1] [ConsumerCoordinator:659] performAssignment   [Consumer clientId=consumer-task.member.v1-3, groupId=task.member.v1] Finished assignment for group at generation 48: {consumer-task.member.v1-3-f2dea481-6259-48dd-a486-e6e9d773f3bd=Assignment(partitions=[task-member-0])}
2023-12-01 15:43:26.128 INFO  ---- [er#0-0-C-1] [ConsumerCoordinator:761] handle   [Consumer clientId=consumer-task.product.v1-2, groupId=task.product.v1] Successfully synced group in generation Generation{generationId=48, memberId='consumer-task.product.v1-2-6bd5591f-ce67-456f-8e3f-5b284b0ad917', protocol='range'}
2023-12-01 15:43:26.128 INFO  ---- [er#2-0-C-1] [ConsumerCoordinator:761] handle   [Consumer clientId=consumer-order.group.v1-1, groupId=order.group.v1] Successfully synced group in generation Generation{generationId=5, memberId='consumer-order.group.v1-1-1dad7d98-9a02-435f-bb54-5d711e3b3e53', protocol='range'}
2023-12-01 15:43:26.130 INFO  ---- [er#2-0-C-1] [ConsumerCoordinator:280] invokeOnAssignment   [Consumer clientId=consumer-order.group.v1-1, groupId=order.group.v1] Notifying assignor about the new Assignment(partitions=[order-0])
2023-12-01 15:43:26.130 INFO  ---- [er#0-0-C-1] [ConsumerCoordinator:280] invokeOnAssignment   [Consumer clientId=consumer-task.product.v1-2, groupId=task.product.v1] Notifying assignor about the new Assignment(partitions=[task-product-0])
2023-12-01 15:43:26.143 INFO  ---- [er#2-0-C-1] [ConsumerCoordinator:292] invokePartitionsAssigned   [Consumer clientId=consumer-order.group.v1-1, groupId=order.group.v1] Adding newly assigned partitions: order-0
2023-12-01 15:43:26.143 INFO  ---- [er#0-0-C-1] [ConsumerCoordinator:292] invokePartitionsAssigned   [Consumer clientId=consumer-task.product.v1-2, groupId=task.product.v1] Adding newly assigned partitions: task-product-0
2023-12-01 15:43:26.235 INFO  ---- [er#1-0-C-1] [ConsumerCoordinator:761] handle   [Consumer clientId=consumer-task.member.v1-3, groupId=task.member.v1] Successfully synced group in generation Generation{generationId=48, memberId='consumer-task.member.v1-3-f2dea481-6259-48dd-a486-e6e9d773f3bd', protocol='range'}
2023-12-01 15:43:26.236 INFO  ---- [er#1-0-C-1] [ConsumerCoordinator:280] invokeOnAssignment   [Consumer clientId=consumer-task.member.v1-3, groupId=task.member.v1] Notifying assignor about the new Assignment(partitions=[task-member-0])
2023-12-01 15:43:26.237 INFO  ---- [er#1-0-C-1] [ConsumerCoordinator:292] invokePartitionsAssigned   [Consumer clientId=consumer-task.member.v1-3, groupId=task.member.v1] Adding newly assigned partitions: task-member-0
2023-12-01 15:43:26.848 INFO  ---- [er#1-0-C-1] [ConsumerCoordinator:851] refreshCommittedOffsetsIfNeeded   [Consumer clientId=consumer-task.member.v1-3, groupId=task.member.v1] Setting offset for partition task-member-0 to the committed offset FetchPosition{offset=2, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[127.0.0.1:9091 (id: 1 rack: null)], epoch=9}}
2023-12-01 15:43:26.849 INFO  ---- [er#2-0-C-1] [ConsumerCoordinator:851] refreshCommittedOffsetsIfNeeded   [Consumer clientId=consumer-order.group.v1-1, groupId=order.group.v1] Setting offset for partition order-0 to the committed offset FetchPosition{offset=2, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[127.0.0.1:9092 (id: 2 rack: null)], epoch=0}}
2023-12-01 15:43:26.851 INFO  ---- [er#0-0-C-1] [ConsumerCoordinator:851] refreshCommittedOffsetsIfNeeded   [Consumer clientId=consumer-task.product.v1-2, groupId=task.product.v1] Setting offset for partition task-product-0 to the committed offset FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[127.0.0.1:9091 (id: 1 rack: null)], epoch=9}}
2023-12-01 15:43:26.960 INFO  ---- [er#2-0-C-1] [KafkaMessageListenerContainer:292] info   order.group.v1: partitions assigned: [order-0]
2023-12-01 15:43:26.961 INFO  ---- [er#1-0-C-1] [KafkaMessageListenerContainer:292] info   task.member.v1: partitions assigned: [task-member-0]
2023-12-01 15:43:26.960 INFO  ---- [er#0-0-C-1] [KafkaMessageListenerContainer:292] info   task.product.v1: partitions assigned: [task-product-0]
2023-12-01 15:43:27.909 INFO  ---- [tartedMain] [TaskConsumerApplication:61] logStarted   Started TaskConsumerApplication in 39.623 seconds (JVM running for 42.397)
2023-12-01 15:43:50.991 INFO  ---- [Executor-0] [DiscoveryClient:1007] fetchRegistry   Disable delta property : false
2023-12-01 15:43:50.992 INFO  ---- [Executor-0] [DiscoveryClient:1008] fetchRegistry   Single vip registry refresh property : null
2023-12-01 15:43:50.992 INFO  ---- [Executor-0] [DiscoveryClient:1009] fetchRegistry   Force full registry fetch : false
2023-12-01 15:43:50.992 INFO  ---- [Executor-0] [DiscoveryClient:1010] fetchRegistry   Application is null : false
2023-12-01 15:43:50.993 INFO  ---- [Executor-0] [DiscoveryClient:1011] fetchRegistry   Registered Applications size is zero : true
2023-12-01 15:43:50.993 INFO  ---- [Executor-0] [DiscoveryClient:1013] fetchRegistry   Application version is -1: false
2023-12-01 15:43:50.993 INFO  ---- [Executor-0] [DiscoveryClient:1097] getAndStoreFullRegistry   Getting all instance registry info from the eureka server
2023-12-01 15:43:51.033 INFO  ---- [Executor-0] [DiscoveryClient:1106] getAndStoreFullRegistry   The response status is 200
2023-12-01 15:48:17.830 INFO  ---- [executor-0] [ConfigClusterResolver:43] getClusterEndpoints   Resolving eureka endpoints via configuration
2023-12-01 15:49:01.068 INFO  ---- [er#2-0-C-1] [ProducerConfig:376] logAll   ProducerConfig values: 
	acks = -1
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-1
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2023-12-01 15:49:01.139 INFO  ---- [er#2-0-C-1] [KafkaProducer:572] configureTransactionState   [Producer clientId=producer-1] Instantiated an idempotent producer.
2023-12-01 15:49:01.203 INFO  ---- [er#2-0-C-1] [AppInfoParser:119] <init>   Kafka version: 3.1.2
2023-12-01 15:49:01.204 INFO  ---- [er#2-0-C-1] [AppInfoParser:120] <init>   Kafka commitId: f8c67dc3ae0a3265
2023-12-01 15:49:01.204 INFO  ---- [er#2-0-C-1] [AppInfoParser:121] <init>   Kafka startTimeMs: 1701413341203
2023-12-01 15:49:01.265 INFO  ---- [producer-1] [Metadata:402] updateLatestMetadata   [Producer clientId=producer-1] Resetting the last seen epoch of partition member-check-0 to 4 since the associated topicId changed from null to KYr4s4QASse48T8_YcW_QA
2023-12-01 15:49:01.266 INFO  ---- [producer-1] [Metadata:287] update   [Producer clientId=producer-1] Cluster ID: 5_U1uds-SGaR4vItj-jqUw
2023-12-01 15:49:01.269 INFO  ---- [producer-1] [TransactionManager:554] setProducerIdAndEpoch   [Producer clientId=producer-1] ProducerId set to 4001 with epoch 0
2023-12-01 15:49:02.221 INFO  ---- [producer-1] [Metadata:402] updateLatestMetadata   [Producer clientId=producer-1] Resetting the last seen epoch of partition order-topic-0 to 0 since the associated topicId changed from null to oOCTsirOTd2wNxZ0w3g9kg
2023-12-01 15:52:21.783 INFO  ---- [er#1-0-C-1] [NetworkClient:935] handleDisconnections   [Consumer clientId=consumer-task.member.v1-3, groupId=task.member.v1] Node -1 disconnected.
2023-12-01 15:52:21.783 INFO  ---- [er#0-0-C-1] [NetworkClient:935] handleDisconnections   [Consumer clientId=consumer-task.product.v1-2, groupId=task.product.v1] Node -1 disconnected.
2023-12-01 15:52:21.785 INFO  ---- [er#2-0-C-1] [NetworkClient:935] handleDisconnections   [Consumer clientId=consumer-order.group.v1-1, groupId=order.group.v1] Node -1 disconnected.
2023-12-01 15:53:29.475 INFO  ---- [executor-0] [ConfigClusterResolver:43] getClusterEndpoints   Resolving eureka endpoints via configuration
2023-12-01 15:58:01.341 INFO  ---- [producer-1] [NetworkClient:935] handleDisconnections   [Producer clientId=producer-1] Node -1 disconnected.
2023-12-01 15:58:29.479 INFO  ---- [executor-0] [ConfigClusterResolver:43] getClusterEndpoints   Resolving eureka endpoints via configuration
2023-12-01 15:58:31.364 INFO  ---- [producer-1] [NetworkClient:935] handleDisconnections   [Producer clientId=producer-1] Node 2 disconnected.
2023-12-01 15:59:19.767 INFO  ---- [producer-1] [Metadata:402] updateLatestMetadata   [Producer clientId=producer-1] Resetting the last seen epoch of partition member-check-0 to 4 since the associated topicId changed from null to KYr4s4QASse48T8_YcW_QA
2023-12-01 15:59:19.912 INFO  ---- [producer-1] [Metadata:402] updateLatestMetadata   [Producer clientId=producer-1] Resetting the last seen epoch of partition order-topic-0 to 0 since the associated topicId changed from null to oOCTsirOTd2wNxZ0w3g9kg
2023-12-01 16:03:29.495 INFO  ---- [executor-0] [ConfigClusterResolver:43] getClusterEndpoints   Resolving eureka endpoints via configuration
2023-12-01 16:03:31.382 INFO  ---- [producer-1] [Metadata:402] updateLatestMetadata   [Producer clientId=producer-1] Resetting the last seen epoch of partition member-check-0 to 4 since the associated topicId changed from null to KYr4s4QASse48T8_YcW_QA
2023-12-01 16:05:10.734 ERROR ---- [er#2-0-C-1] [TaskOrderConsumer:47] orderTaskListener   orderTaskListener Error message = {"taskId":"adc461f3-d09b-44f9-9cbc-f2147820304d","taskName":"orderTask","subTaskList":[{"taskId":"365ca8e1-745b-44f4-818e-c7d25674ef6f","subTaskName":"validMemberTask : 멤버십 유효성 검사","status":"READY","type":"MEMBER","userId":1},{"taskId":"85338910-a5f7-42d5-926c-2a7a7849daa5","subTaskName":"validProductTask : 상품 유효성 검사","status":"READY","type":"PRODUCT","productId":269,"colorId":1,"quantity":3,"sizeId":271}]}
com.fasterxml.jackson.databind.exc.InvalidDefinitionException: Failed on call to `getDeclaredMethods()` on class `org.example.task.ProductTask`, problem: (java.lang.NoClassDefFoundError) org/example/task/ProductTask$ProductTaskBuilder
 at [Source: (String)"{"taskId":"adc461f3-d09b-44f9-9cbc-f2147820304d","taskName":"orderTask","subTaskList":[{"taskId":"365ca8e1-745b-44f4-818e-c7d25674ef6f","subTaskName":"validMemberTask : 멤버십 유효성 검사","status":"READY","type":"MEMBER","userId":1},{"taskId":"85338910-a5f7-42d5-926c-2a7a7849daa5","subTaskName":"validProductTask : 상품 유효성 검사","status":"READY","type":"PRODUCT","productId":269,"colorId":1,"quantity":3,"sizeId":271}]}"; line: 1, column: 345] (through reference chain: org.example.task.OrderTask["subTaskList"]->java.util.ArrayList[1])
	at com.fasterxml.jackson.databind.exc.InvalidDefinitionException.from(InvalidDefinitionException.java:62)
	at com.fasterxml.jackson.databind.deser.BeanDeserializerFactory.buildBeanDeserializer(BeanDeserializerFactory.java:268)
	at com.fasterxml.jackson.databind.deser.BeanDeserializerFactory.createBeanDeserializer(BeanDeserializerFactory.java:150)
	at com.fasterxml.jackson.databind.deser.DeserializerCache._createDeserializer2(DeserializerCache.java:415)
	at com.fasterxml.jackson.databind.deser.DeserializerCache._createDeserializer(DeserializerCache.java:350)
	at com.fasterxml.jackson.databind.deser.DeserializerCache._createAndCache2(DeserializerCache.java:264)
	at com.fasterxml.jackson.databind.deser.DeserializerCache._createAndCacheValueDeserializer(DeserializerCache.java:244)
	at com.fasterxml.jackson.databind.deser.DeserializerCache.findValueDeserializer(DeserializerCache.java:142)
	at com.fasterxml.jackson.databind.DeserializationContext.findContextualValueDeserializer(DeserializationContext.java:609)
	at com.fasterxml.jackson.databind.jsontype.impl.TypeDeserializerBase._findDeserializer(TypeDeserializerBase.java:203)
	at com.fasterxml.jackson.databind.jsontype.impl.AsPropertyTypeDeserializer._deserializeTypedForId(AsPropertyTypeDeserializer.java:125)
	at com.fasterxml.jackson.databind.jsontype.impl.AsPropertyTypeDeserializer.deserializeTypedFromObject(AsPropertyTypeDeserializer.java:110)
	at com.fasterxml.jackson.databind.deser.AbstractDeserializer.deserializeWithType(AbstractDeserializer.java:263)
	at com.fasterxml.jackson.databind.deser.std.CollectionDeserializer._deserializeFromArray(CollectionDeserializer.java:357)
	at com.fasterxml.jackson.databind.deser.std.CollectionDeserializer.deserialize(CollectionDeserializer.java:244)
	at com.fasterxml.jackson.databind.deser.std.CollectionDeserializer.deserialize(CollectionDeserializer.java:28)
	at com.fasterxml.jackson.databind.deser.impl.MethodProperty.deserializeAndSet(MethodProperty.java:129)
	at com.fasterxml.jackson.databind.deser.BeanDeserializer.deserializeFromObject(BeanDeserializer.java:392)
	at com.fasterxml.jackson.databind.deser.BeanDeserializer.deserialize(BeanDeserializer.java:185)
	at com.fasterxml.jackson.databind.deser.DefaultDeserializationContext.readRootValue(DefaultDeserializationContext.java:323)
	at com.fasterxml.jackson.databind.ObjectMapper._readMapAndClose(ObjectMapper.java:4674)
	at com.fasterxml.jackson.databind.ObjectMapper.readValue(ObjectMapper.java:3629)
	at com.fasterxml.jackson.databind.ObjectMapper.readValue(ObjectMapper.java:3597)
	at com.example.taskconsumer.consum.TaskOrderConsumer.orderTaskListener(TaskOrderConsumer.java:34)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
	at org.springframework.messaging.handler.invocation.InvocableHandlerMethod.doInvoke(InvocableHandlerMethod.java:169)
	at org.springframework.messaging.handler.invocation.InvocableHandlerMethod.invoke(InvocableHandlerMethod.java:119)
	at org.springframework.kafka.listener.adapter.HandlerAdapter.invoke(HandlerAdapter.java:56)
	at org.springframework.kafka.listener.adapter.MessagingMessageListenerAdapter.invokeHandler(MessagingMessageListenerAdapter.java:347)
	at org.springframework.kafka.listener.adapter.RecordMessagingMessageListenerAdapter.onMessage(RecordMessagingMessageListenerAdapter.java:92)
	at org.springframework.kafka.listener.adapter.RecordMessagingMessageListenerAdapter.onMessage(RecordMessagingMessageListenerAdapter.java:53)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeOnMessage(KafkaMessageListenerContainer.java:2670)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeOnMessage(KafkaMessageListenerContainer.java:2650)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeRecordListener(KafkaMessageListenerContainer.java:2577)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeWithRecords(KafkaMessageListenerContainer.java:2457)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeRecordListener(KafkaMessageListenerContainer.java:2335)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeListener(KafkaMessageListenerContainer.java:2006)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeIfHaveRecords(KafkaMessageListenerContainer.java:1375)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.pollAndInvoke(KafkaMessageListenerContainer.java:1366)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.run(KafkaMessageListenerContainer.java:1257)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.lang.Thread.run(Thread.java:834)
Caused by: java.lang.IllegalArgumentException: Failed on call to `getDeclaredMethods()` on class `org.example.task.ProductTask`, problem: (java.lang.NoClassDefFoundError) org/example/task/ProductTask$ProductTaskBuilder
	at com.fasterxml.jackson.databind.util.ClassUtil._failGetClassMethods(ClassUtil.java:1265)
	at com.fasterxml.jackson.databind.util.ClassUtil.getClassMethods(ClassUtil.java:1254)
	at com.fasterxml.jackson.databind.introspect.AnnotatedMethodCollector._addMemberMethods(AnnotatedMethodCollector.java:117)
	at com.fasterxml.jackson.databind.introspect.AnnotatedMethodCollector.collect(AnnotatedMethodCollector.java:49)
	at com.fasterxml.jackson.databind.introspect.AnnotatedMethodCollector.collectMethods(AnnotatedMethodCollector.java:40)
	at com.fasterxml.jackson.databind.introspect.AnnotatedClass._methods(AnnotatedClass.java:387)
	at com.fasterxml.jackson.databind.introspect.AnnotatedClass.memberMethods(AnnotatedClass.java:327)
	at com.fasterxml.jackson.databind.introspect.POJOPropertiesCollector._addMethods(POJOPropertiesCollector.java:680)
	at com.fasterxml.jackson.databind.introspect.POJOPropertiesCollector.collectAll(POJOPropertiesCollector.java:422)
	at com.fasterxml.jackson.databind.introspect.POJOPropertiesCollector.getPropertyMap(POJOPropertiesCollector.java:386)
	at com.fasterxml.jackson.databind.introspect.POJOPropertiesCollector.getProperties(POJOPropertiesCollector.java:233)
	at com.fasterxml.jackson.databind.introspect.BasicBeanDescription._properties(BasicBeanDescription.java:164)
	at com.fasterxml.jackson.databind.introspect.BasicBeanDescription.findProperties(BasicBeanDescription.java:239)
	at com.fasterxml.jackson.databind.deser.BasicDeserializerFactory._findCreatorsFromProperties(BasicDeserializerFactory.java:328)
	at com.fasterxml.jackson.databind.deser.BasicDeserializerFactory._constructDefaultValueInstantiator(BasicDeserializerFactory.java:272)
	at com.fasterxml.jackson.databind.deser.BasicDeserializerFactory.findValueInstantiator(BasicDeserializerFactory.java:223)
	at com.fasterxml.jackson.databind.deser.BeanDeserializerFactory.buildBeanDeserializer(BeanDeserializerFactory.java:261)
	... 44 common frames omitted
Caused by: java.lang.NoClassDefFoundError: org/example/task/ProductTask$ProductTaskBuilder
	at java.base/java.lang.Class.getDeclaredMethods0(Native Method)
	at java.base/java.lang.Class.privateGetDeclaredMethods(Class.java:3166)
	at java.base/java.lang.Class.getDeclaredMethods(Class.java:2309)
	at com.fasterxml.jackson.databind.util.ClassUtil.getClassMethods(ClassUtil.java:1252)
	... 59 common frames omitted
Caused by: java.lang.ClassNotFoundException: org.example.task.ProductTask$ProductTaskBuilder
	at java.base/jdk.internal.loader.BuiltinClassLoader.loadClass(BuiltinClassLoader.java:581)
	at java.base/jdk.internal.loader.ClassLoaders$AppClassLoader.loadClass(ClassLoaders.java:178)
	at java.base/java.lang.ClassLoader.loadClass(ClassLoader.java:521)
	... 63 common frames omitted
2023-12-01 16:06:29.824 INFO  ---- [tartedMain] [TaskConsumerApplication:55] logStarting   Starting TaskConsumerApplication using Java 11.0.13 on DESKTOP-MNMB87E with PID 29204 (C:\Users\tkdrb\IdeaProjects\ecommerce\task-consumer\build\classes\java\main started by tkdrb in C:\Users\tkdrb\IdeaProjects\ecommerce\task-consumer)
2023-12-01 16:06:29.827 INFO  ---- [tartedMain] [TaskConsumerApplication:631] logStartupProfileInfo   No active profile set, falling back to 1 default profile: "default"
2023-12-01 16:06:29.894 INFO  ---- [tartedMain] [DevToolsPropertyDefaultsPostProcessor:255] logTo   Devtools property defaults active! Set 'spring.devtools.add-properties' to 'false' to disable
2023-12-01 16:06:29.895 INFO  ---- [tartedMain] [DevToolsPropertyDefaultsPostProcessor:255] logTo   For additional web related logging consider setting the 'logging.level.web' property to 'DEBUG'
2023-12-01 16:06:31.381 INFO  ---- [tartedMain] [GenericScope:283] setSerializationId   BeanFactory id=7d336d03-7948-373b-80b2-3edd326128fe
2023-12-01 16:06:33.190 INFO  ---- [tartedMain] [TomcatWebServer:108] initialize   Tomcat initialized with port(s): 0 (http)
2023-12-01 16:06:33.211 INFO  ---- [tartedMain] [StandardService:173] log   Starting service [Tomcat]
2023-12-01 16:06:33.214 INFO  ---- [tartedMain] [StandardEngine:173] log   Starting Servlet engine: [Apache Tomcat/9.0.76]
2023-12-01 16:06:33.521 INFO  ---- [tartedMain] [[/]:173] log   Initializing Spring embedded WebApplicationContext
2023-12-01 16:06:33.521 INFO  ---- [tartedMain] [ServletWebServerApplicationContext:292] prepareWebApplicationContext   Root WebApplicationContext: initialization completed in 3623 ms
2023-12-01 16:06:34.673 INFO  ---- [tartedMain] [OptionalLiveReloadServer:59] startServer   LiveReload server is running on port 35729
2023-12-01 16:06:36.018 INFO  ---- [tartedMain] [DiscoveryClientOptionalArgsConfiguration:71] restTemplateDiscoveryClientOptionalArgs   Eureka HTTP Client uses RestTemplate.
2023-12-01 16:06:37.448 WARN  ---- [tartedMain] [LoadBalancerCacheAutoConfiguration$LoadBalancerCaffeineWarnLogger:83] logWarning   Spring Cloud LoadBalancer is currently working with the default cache. While this cache implementation is useful for development and tests, it's recommended to use Caffeine cache in production.You can switch to using Caffeine cache, by adding it and org.springframework.cache.caffeine.CaffeineCacheManager to the classpath.
2023-12-01 16:06:37.614 INFO  ---- [tartedMain] [ConsumerConfig:376] logAll   ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-order.group.v1-1
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = order.group.v1
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2023-12-01 16:06:37.807 INFO  ---- [tartedMain] [AppInfoParser:119] <init>   Kafka version: 3.1.2
2023-12-01 16:06:37.810 INFO  ---- [tartedMain] [AppInfoParser:120] <init>   Kafka commitId: f8c67dc3ae0a3265
2023-12-01 16:06:37.811 INFO  ---- [tartedMain] [AppInfoParser:121] <init>   Kafka startTimeMs: 1701414397804
2023-12-01 16:06:37.816 INFO  ---- [tartedMain] [KafkaConsumer:966] subscribe   [Consumer clientId=consumer-order.group.v1-1, groupId=order.group.v1] Subscribed to topic(s): order
2023-12-01 16:06:37.843 INFO  ---- [tartedMain] [ConsumerConfig:376] logAll   ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-task.member.v1-2
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = task.member.v1
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2023-12-01 16:06:37.859 INFO  ---- [tartedMain] [AppInfoParser:119] <init>   Kafka version: 3.1.2
2023-12-01 16:06:37.860 INFO  ---- [tartedMain] [AppInfoParser:120] <init>   Kafka commitId: f8c67dc3ae0a3265
2023-12-01 16:06:37.860 INFO  ---- [tartedMain] [AppInfoParser:121] <init>   Kafka startTimeMs: 1701414397859
2023-12-01 16:06:37.861 INFO  ---- [tartedMain] [KafkaConsumer:966] subscribe   [Consumer clientId=consumer-task.member.v1-2, groupId=task.member.v1] Subscribed to topic(s): task-member
2023-12-01 16:06:37.865 INFO  ---- [tartedMain] [ConsumerConfig:376] logAll   ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-task.product.v1-3
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = task.product.v1
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2023-12-01 16:06:37.878 INFO  ---- [tartedMain] [AppInfoParser:119] <init>   Kafka version: 3.1.2
2023-12-01 16:06:37.878 INFO  ---- [tartedMain] [AppInfoParser:120] <init>   Kafka commitId: f8c67dc3ae0a3265
2023-12-01 16:06:37.878 INFO  ---- [tartedMain] [AppInfoParser:121] <init>   Kafka startTimeMs: 1701414397877
2023-12-01 16:06:37.879 INFO  ---- [tartedMain] [KafkaConsumer:966] subscribe   [Consumer clientId=consumer-task.product.v1-3, groupId=task.product.v1] Subscribed to topic(s): task-product
2023-12-01 16:06:37.896 INFO  ---- [tartedMain] [TomcatWebServer:220] start   Tomcat started on port(s): 59828 (http) with context path ''
2023-12-01 16:06:37.897 INFO  ---- [tartedMain] [EurekaAutoServiceRegistration:144] onApplicationEvent   Updating port to 59828
2023-12-01 16:06:37.902 INFO  ---- [tartedMain] [InstanceInfoFactory:67] create   Setting initial instance status as: STARTING
2023-12-01 16:06:37.965 INFO  ---- [tartedMain] [DiscoveryClient:372] <init>   Initializing Eureka in region us-east-1
2023-12-01 16:06:37.976 INFO  ---- [tartedMain] [ConfigClusterResolver:43] getClusterEndpoints   Resolving eureka endpoints via configuration
2023-12-01 16:06:38.014 INFO  ---- [tartedMain] [DiscoveryClient:1007] fetchRegistry   Disable delta property : false
2023-12-01 16:06:38.015 INFO  ---- [tartedMain] [DiscoveryClient:1008] fetchRegistry   Single vip registry refresh property : null
2023-12-01 16:06:38.015 INFO  ---- [tartedMain] [DiscoveryClient:1009] fetchRegistry   Force full registry fetch : false
2023-12-01 16:06:38.016 INFO  ---- [tartedMain] [DiscoveryClient:1010] fetchRegistry   Application is null : false
2023-12-01 16:06:38.016 INFO  ---- [tartedMain] [DiscoveryClient:1011] fetchRegistry   Registered Applications size is zero : true
2023-12-01 16:06:38.016 INFO  ---- [tartedMain] [DiscoveryClient:1013] fetchRegistry   Application version is -1: true
2023-12-01 16:06:38.016 INFO  ---- [tartedMain] [DiscoveryClient:1097] getAndStoreFullRegistry   Getting all instance registry info from the eureka server
2023-12-01 16:06:38.270 INFO  ---- [er#2-0-C-1] [Metadata:402] updateLatestMetadata   [Consumer clientId=consumer-order.group.v1-1, groupId=order.group.v1] Resetting the last seen epoch of partition order-0 to 0 since the associated topicId changed from null to 8AIo0qkzSIiGJbn1bQxAkw
2023-12-01 16:06:38.270 INFO  ---- [er#0-0-C-1] [Metadata:402] updateLatestMetadata   [Consumer clientId=consumer-task.member.v1-2, groupId=task.member.v1] Resetting the last seen epoch of partition task-member-0 to 9 since the associated topicId changed from null to HvfbkcRhQ3meTIJFgCt9zw
2023-12-01 16:06:38.270 INFO  ---- [er#1-0-C-1] [Metadata:402] updateLatestMetadata   [Consumer clientId=consumer-task.product.v1-3, groupId=task.product.v1] Resetting the last seen epoch of partition task-product-0 to 9 since the associated topicId changed from null to h57hDuqlT3KmUT32pFF5uQ
2023-12-01 16:06:38.275 INFO  ---- [er#0-0-C-1] [Metadata:287] update   [Consumer clientId=consumer-task.member.v1-2, groupId=task.member.v1] Cluster ID: 5_U1uds-SGaR4vItj-jqUw
2023-12-01 16:06:38.275 INFO  ---- [er#1-0-C-1] [Metadata:287] update   [Consumer clientId=consumer-task.product.v1-3, groupId=task.product.v1] Cluster ID: 5_U1uds-SGaR4vItj-jqUw
2023-12-01 16:06:38.275 INFO  ---- [er#2-0-C-1] [Metadata:287] update   [Consumer clientId=consumer-order.group.v1-1, groupId=order.group.v1] Cluster ID: 5_U1uds-SGaR4vItj-jqUw
2023-12-01 16:06:38.277 INFO  ---- [er#1-0-C-1] [ConsumerCoordinator:853] onSuccess   [Consumer clientId=consumer-task.product.v1-3, groupId=task.product.v1] Discovered group coordinator 127.0.0.1:9091 (id: 2147483646 rack: null)
2023-12-01 16:06:38.277 INFO  ---- [er#2-0-C-1] [ConsumerCoordinator:853] onSuccess   [Consumer clientId=consumer-order.group.v1-1, groupId=order.group.v1] Discovered group coordinator 127.0.0.1:9091 (id: 2147483646 rack: null)
2023-12-01 16:06:38.277 INFO  ---- [er#0-0-C-1] [ConsumerCoordinator:853] onSuccess   [Consumer clientId=consumer-task.member.v1-2, groupId=task.member.v1] Discovered group coordinator 127.0.0.1:9093 (id: 2147483644 rack: null)
2023-12-01 16:06:38.283 INFO  ---- [er#0-0-C-1] [ConsumerCoordinator:535] sendJoinGroupRequest   [Consumer clientId=consumer-task.member.v1-2, groupId=task.member.v1] (Re-)joining group
2023-12-01 16:06:38.283 INFO  ---- [er#1-0-C-1] [ConsumerCoordinator:535] sendJoinGroupRequest   [Consumer clientId=consumer-task.product.v1-3, groupId=task.product.v1] (Re-)joining group
2023-12-01 16:06:38.283 INFO  ---- [er#2-0-C-1] [ConsumerCoordinator:535] sendJoinGroupRequest   [Consumer clientId=consumer-order.group.v1-1, groupId=order.group.v1] (Re-)joining group
2023-12-01 16:06:38.317 INFO  ---- [er#1-0-C-1] [ConsumerCoordinator:1000] requestRejoin   [Consumer clientId=consumer-task.product.v1-3, groupId=task.product.v1] Request joining group due to: need to re-join with the given member-id
2023-12-01 16:06:38.317 INFO  ---- [er#2-0-C-1] [ConsumerCoordinator:1000] requestRejoin   [Consumer clientId=consumer-order.group.v1-1, groupId=order.group.v1] Request joining group due to: need to re-join with the given member-id
2023-12-01 16:06:38.318 INFO  ---- [er#2-0-C-1] [ConsumerCoordinator:535] sendJoinGroupRequest   [Consumer clientId=consumer-order.group.v1-1, groupId=order.group.v1] (Re-)joining group
2023-12-01 16:06:38.318 INFO  ---- [er#1-0-C-1] [ConsumerCoordinator:535] sendJoinGroupRequest   [Consumer clientId=consumer-task.product.v1-3, groupId=task.product.v1] (Re-)joining group
2023-12-01 16:06:38.319 INFO  ---- [er#0-0-C-1] [ConsumerCoordinator:1000] requestRejoin   [Consumer clientId=consumer-task.member.v1-2, groupId=task.member.v1] Request joining group due to: need to re-join with the given member-id
2023-12-01 16:06:38.320 INFO  ---- [er#0-0-C-1] [ConsumerCoordinator:535] sendJoinGroupRequest   [Consumer clientId=consumer-task.member.v1-2, groupId=task.member.v1] (Re-)joining group
2023-12-01 16:06:38.458 INFO  ---- [tartedMain] [DiscoveryClient:1106] getAndStoreFullRegistry   The response status is 200
2023-12-01 16:06:38.463 INFO  ---- [tartedMain] [DiscoveryClient:1321] initScheduledTasks   Starting heartbeat executor: renew interval is: 30
2023-12-01 16:06:38.468 INFO  ---- [tartedMain] [InstanceInfoReplicator:60] <init>   InstanceInfoReplicator onDemand update allowed rate per min is 4
2023-12-01 16:06:38.478 INFO  ---- [tartedMain] [DiscoveryClient:492] <init>   Discovery Client initialized at timestamp 1701414398477 with initial instances count: 5
2023-12-01 16:06:38.481 INFO  ---- [tartedMain] [EurekaServiceRegistry:41] register   Registering application TASK-SERVICE with eureka with status UP
2023-12-01 16:06:38.483 INFO  ---- [tartedMain] [DiscoveryClient:1352] notify   Saw local status change event StatusChangeEvent [timestamp=1701414398483, current=UP, previous=STARTING]
2023-12-01 16:06:38.489 INFO  ---- [plicator-0] [DiscoveryClient:873] register   DiscoveryClient_TASK-SERVICE/192.168.0.17:41e429f3252f45d754835a98fb0d526e: registering service...
2023-12-01 16:06:38.587 INFO  ---- [plicator-0] [DiscoveryClient:882] register   DiscoveryClient_TASK-SERVICE/192.168.0.17:41e429f3252f45d754835a98fb0d526e - registration status: 204
2023-12-01 16:06:39.721 INFO  ---- [tartedMain] [TaskConsumerApplication:61] logStarted   Started TaskConsumerApplication in 12.515 seconds (JVM running for 13.597)
2023-12-01 16:06:51.913 INFO  ---- [er#0-0-C-1] [ConsumerCoordinator:595] handle   [Consumer clientId=consumer-task.member.v1-2, groupId=task.member.v1] Successfully joined group with generation Generation{generationId=49, memberId='consumer-task.member.v1-2-c18972ed-c969-4659-9f23-9658fd4b8b88', protocol='range'}
2023-12-01 16:06:51.918 INFO  ---- [er#0-0-C-1] [ConsumerCoordinator:659] performAssignment   [Consumer clientId=consumer-task.member.v1-2, groupId=task.member.v1] Finished assignment for group at generation 49: {consumer-task.member.v1-2-c18972ed-c969-4659-9f23-9658fd4b8b88=Assignment(partitions=[task-member-0])}
2023-12-01 16:06:51.951 INFO  ---- [er#0-0-C-1] [ConsumerCoordinator:761] handle   [Consumer clientId=consumer-task.member.v1-2, groupId=task.member.v1] Successfully synced group in generation Generation{generationId=49, memberId='consumer-task.member.v1-2-c18972ed-c969-4659-9f23-9658fd4b8b88', protocol='range'}
2023-12-01 16:06:51.952 INFO  ---- [er#0-0-C-1] [ConsumerCoordinator:280] invokeOnAssignment   [Consumer clientId=consumer-task.member.v1-2, groupId=task.member.v1] Notifying assignor about the new Assignment(partitions=[task-member-0])
2023-12-01 16:06:51.960 INFO  ---- [er#0-0-C-1] [ConsumerCoordinator:292] invokePartitionsAssigned   [Consumer clientId=consumer-task.member.v1-2, groupId=task.member.v1] Adding newly assigned partitions: task-member-0
2023-12-01 16:06:51.995 INFO  ---- [er#0-0-C-1] [ConsumerCoordinator:851] refreshCommittedOffsetsIfNeeded   [Consumer clientId=consumer-task.member.v1-2, groupId=task.member.v1] Setting offset for partition task-member-0 to the committed offset FetchPosition{offset=5, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[127.0.0.1:9091 (id: 1 rack: null)], epoch=9}}
2023-12-01 16:06:51.998 INFO  ---- [er#0-0-C-1] [KafkaMessageListenerContainer:292] info   task.member.v1: partitions assigned: [task-member-0]
2023-12-01 16:06:52.058 INFO  ---- [er#1-0-C-1] [ConsumerCoordinator:595] handle   [Consumer clientId=consumer-task.product.v1-3, groupId=task.product.v1] Successfully joined group with generation Generation{generationId=49, memberId='consumer-task.product.v1-3-ea4e4b4f-a258-45e9-ab94-3b8a74d85296', protocol='range'}
2023-12-01 16:06:52.059 INFO  ---- [er#1-0-C-1] [ConsumerCoordinator:659] performAssignment   [Consumer clientId=consumer-task.product.v1-3, groupId=task.product.v1] Finished assignment for group at generation 49: {consumer-task.product.v1-3-ea4e4b4f-a258-45e9-ab94-3b8a74d85296=Assignment(partitions=[task-product-0])}
2023-12-01 16:06:52.073 INFO  ---- [er#1-0-C-1] [ConsumerCoordinator:761] handle   [Consumer clientId=consumer-task.product.v1-3, groupId=task.product.v1] Successfully synced group in generation Generation{generationId=49, memberId='consumer-task.product.v1-3-ea4e4b4f-a258-45e9-ab94-3b8a74d85296', protocol='range'}
2023-12-01 16:06:52.074 INFO  ---- [er#1-0-C-1] [ConsumerCoordinator:280] invokeOnAssignment   [Consumer clientId=consumer-task.product.v1-3, groupId=task.product.v1] Notifying assignor about the new Assignment(partitions=[task-product-0])
2023-12-01 16:06:52.074 INFO  ---- [er#1-0-C-1] [ConsumerCoordinator:292] invokePartitionsAssigned   [Consumer clientId=consumer-task.product.v1-3, groupId=task.product.v1] Adding newly assigned partitions: task-product-0
2023-12-01 16:06:52.080 INFO  ---- [er#1-0-C-1] [ConsumerCoordinator:851] refreshCommittedOffsetsIfNeeded   [Consumer clientId=consumer-task.product.v1-3, groupId=task.product.v1] Setting offset for partition task-product-0 to the committed offset FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[127.0.0.1:9091 (id: 1 rack: null)], epoch=9}}
2023-12-01 16:06:52.081 INFO  ---- [er#1-0-C-1] [KafkaMessageListenerContainer:292] info   task.product.v1: partitions assigned: [task-product-0]
2023-12-01 16:06:52.096 INFO  ---- [er#2-0-C-1] [ConsumerCoordinator:595] handle   [Consumer clientId=consumer-order.group.v1-1, groupId=order.group.v1] Successfully joined group with generation Generation{generationId=6, memberId='consumer-order.group.v1-1-66b03d64-1399-4ead-8759-8484036115fe', protocol='range'}
2023-12-01 16:06:52.096 INFO  ---- [er#2-0-C-1] [ConsumerCoordinator:659] performAssignment   [Consumer clientId=consumer-order.group.v1-1, groupId=order.group.v1] Finished assignment for group at generation 6: {consumer-order.group.v1-1-66b03d64-1399-4ead-8759-8484036115fe=Assignment(partitions=[order-0])}
2023-12-01 16:06:52.101 INFO  ---- [er#2-0-C-1] [ConsumerCoordinator:761] handle   [Consumer clientId=consumer-order.group.v1-1, groupId=order.group.v1] Successfully synced group in generation Generation{generationId=6, memberId='consumer-order.group.v1-1-66b03d64-1399-4ead-8759-8484036115fe', protocol='range'}
2023-12-01 16:06:52.101 INFO  ---- [er#2-0-C-1] [ConsumerCoordinator:280] invokeOnAssignment   [Consumer clientId=consumer-order.group.v1-1, groupId=order.group.v1] Notifying assignor about the new Assignment(partitions=[order-0])
2023-12-01 16:06:52.102 INFO  ---- [er#2-0-C-1] [ConsumerCoordinator:292] invokePartitionsAssigned   [Consumer clientId=consumer-order.group.v1-1, groupId=order.group.v1] Adding newly assigned partitions: order-0
2023-12-01 16:06:52.107 INFO  ---- [er#2-0-C-1] [ConsumerCoordinator:851] refreshCommittedOffsetsIfNeeded   [Consumer clientId=consumer-order.group.v1-1, groupId=order.group.v1] Setting offset for partition order-0 to the committed offset FetchPosition{offset=6, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[127.0.0.1:9092 (id: 2 rack: null)], epoch=0}}
2023-12-01 16:06:52.107 INFO  ---- [er#2-0-C-1] [KafkaMessageListenerContainer:292] info   order.group.v1: partitions assigned: [order-0]
2023-12-01 16:06:52.250 INFO  ---- [er#2-0-C-1] [ProducerConfig:376] logAll   ProducerConfig values: 
	acks = -1
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-1
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2023-12-01 16:06:52.273 INFO  ---- [er#2-0-C-1] [KafkaProducer:572] configureTransactionState   [Producer clientId=producer-1] Instantiated an idempotent producer.
2023-12-01 16:06:52.306 INFO  ---- [er#2-0-C-1] [AppInfoParser:119] <init>   Kafka version: 3.1.2
2023-12-01 16:06:52.307 INFO  ---- [er#2-0-C-1] [AppInfoParser:120] <init>   Kafka commitId: f8c67dc3ae0a3265
2023-12-01 16:06:52.307 INFO  ---- [er#2-0-C-1] [AppInfoParser:121] <init>   Kafka startTimeMs: 1701414412306
2023-12-01 16:06:52.332 INFO  ---- [producer-1] [Metadata:402] updateLatestMetadata   [Producer clientId=producer-1] Resetting the last seen epoch of partition member-check-0 to 4 since the associated topicId changed from null to KYr4s4QASse48T8_YcW_QA
2023-12-01 16:06:52.333 INFO  ---- [producer-1] [Metadata:287] update   [Producer clientId=producer-1] Cluster ID: 5_U1uds-SGaR4vItj-jqUw
2023-12-01 16:06:52.334 INFO  ---- [producer-1] [TransactionManager:554] setProducerIdAndEpoch   [Producer clientId=producer-1] ProducerId set to 4006 with epoch 0
2023-12-01 16:06:52.434 INFO  ---- [producer-1] [Metadata:402] updateLatestMetadata   [Producer clientId=producer-1] Resetting the last seen epoch of partition product-check-0 to 2 since the associated topicId changed from null to NcmASD39SLaSfi1cR4a0aw
2023-12-01 16:06:52.876 ERROR ---- [er#1-0-C-1] [OrderSubTaskConsumer:45] ProductTaskListener   taskListener Error message = null
java.lang.NullPointerException: null
	at com.example.taskconsumer.consum.OrderSubTaskConsumer.setCountManager(OrderSubTaskConsumer.java:52)
	at com.example.taskconsumer.consum.OrderSubTaskConsumer.ProductTaskListener(OrderSubTaskConsumer.java:43)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
	at org.springframework.messaging.handler.invocation.InvocableHandlerMethod.doInvoke(InvocableHandlerMethod.java:169)
	at org.springframework.messaging.handler.invocation.InvocableHandlerMethod.invoke(InvocableHandlerMethod.java:119)
	at org.springframework.kafka.listener.adapter.HandlerAdapter.invoke(HandlerAdapter.java:56)
	at org.springframework.kafka.listener.adapter.MessagingMessageListenerAdapter.invokeHandler(MessagingMessageListenerAdapter.java:347)
	at org.springframework.kafka.listener.adapter.RecordMessagingMessageListenerAdapter.onMessage(RecordMessagingMessageListenerAdapter.java:92)
	at org.springframework.kafka.listener.adapter.RecordMessagingMessageListenerAdapter.onMessage(RecordMessagingMessageListenerAdapter.java:53)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeOnMessage(KafkaMessageListenerContainer.java:2670)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeOnMessage(KafkaMessageListenerContainer.java:2650)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeRecordListener(KafkaMessageListenerContainer.java:2577)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeWithRecords(KafkaMessageListenerContainer.java:2457)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeRecordListener(KafkaMessageListenerContainer.java:2335)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeListener(KafkaMessageListenerContainer.java:2006)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeIfHaveRecords(KafkaMessageListenerContainer.java:1375)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.pollAndInvoke(KafkaMessageListenerContainer.java:1366)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.run(KafkaMessageListenerContainer.java:1257)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.lang.Thread.run(Thread.java:834)
2023-12-01 16:08:52.794 INFO  ---- [tartedMain] [TaskConsumerApplication:55] logStarting   Starting TaskConsumerApplication using Java 11.0.13 on DESKTOP-MNMB87E with PID 12180 (C:\Users\tkdrb\IdeaProjects\ecommerce\task-consumer\build\classes\java\main started by tkdrb in C:\Users\tkdrb\IdeaProjects\ecommerce\task-consumer)
2023-12-01 16:08:52.796 INFO  ---- [tartedMain] [TaskConsumerApplication:631] logStartupProfileInfo   No active profile set, falling back to 1 default profile: "default"
2023-12-01 16:08:52.881 INFO  ---- [tartedMain] [DevToolsPropertyDefaultsPostProcessor:255] logTo   Devtools property defaults active! Set 'spring.devtools.add-properties' to 'false' to disable
2023-12-01 16:08:52.881 INFO  ---- [tartedMain] [DevToolsPropertyDefaultsPostProcessor:255] logTo   For additional web related logging consider setting the 'logging.level.web' property to 'DEBUG'
2023-12-01 16:08:55.026 INFO  ---- [tartedMain] [GenericScope:283] setSerializationId   BeanFactory id=7d336d03-7948-373b-80b2-3edd326128fe
2023-12-01 16:09:00.216 INFO  ---- [tartedMain] [TomcatWebServer:108] initialize   Tomcat initialized with port(s): 0 (http)
2023-12-01 16:09:00.234 INFO  ---- [tartedMain] [StandardService:173] log   Starting service [Tomcat]
2023-12-01 16:09:00.236 INFO  ---- [tartedMain] [StandardEngine:173] log   Starting Servlet engine: [Apache Tomcat/9.0.76]
2023-12-01 16:09:00.475 INFO  ---- [tartedMain] [[/]:173] log   Initializing Spring embedded WebApplicationContext
2023-12-01 16:09:00.476 INFO  ---- [tartedMain] [ServletWebServerApplicationContext:292] prepareWebApplicationContext   Root WebApplicationContext: initialization completed in 7594 ms
2023-12-01 16:09:01.567 INFO  ---- [tartedMain] [OptionalLiveReloadServer:59] startServer   LiveReload server is running on port 35729
2023-12-01 16:09:03.135 INFO  ---- [tartedMain] [DiscoveryClientOptionalArgsConfiguration:71] restTemplateDiscoveryClientOptionalArgs   Eureka HTTP Client uses RestTemplate.
2023-12-01 16:09:04.701 WARN  ---- [tartedMain] [LoadBalancerCacheAutoConfiguration$LoadBalancerCaffeineWarnLogger:83] logWarning   Spring Cloud LoadBalancer is currently working with the default cache. While this cache implementation is useful for development and tests, it's recommended to use Caffeine cache in production.You can switch to using Caffeine cache, by adding it and org.springframework.cache.caffeine.CaffeineCacheManager to the classpath.
2023-12-01 16:09:04.822 INFO  ---- [tartedMain] [ConsumerConfig:376] logAll   ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-order.group.v1-1
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = order.group.v1
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2023-12-01 16:09:05.073 INFO  ---- [tartedMain] [AppInfoParser:119] <init>   Kafka version: 3.1.2
2023-12-01 16:09:05.075 INFO  ---- [tartedMain] [AppInfoParser:120] <init>   Kafka commitId: f8c67dc3ae0a3265
2023-12-01 16:09:05.077 INFO  ---- [tartedMain] [AppInfoParser:121] <init>   Kafka startTimeMs: 1701414545071
2023-12-01 16:09:05.082 INFO  ---- [tartedMain] [KafkaConsumer:966] subscribe   [Consumer clientId=consumer-order.group.v1-1, groupId=order.group.v1] Subscribed to topic(s): order
2023-12-01 16:09:05.105 INFO  ---- [tartedMain] [ConsumerConfig:376] logAll   ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-task.member.v1-2
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = task.member.v1
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2023-12-01 16:09:05.120 INFO  ---- [tartedMain] [AppInfoParser:119] <init>   Kafka version: 3.1.2
2023-12-01 16:09:05.121 INFO  ---- [tartedMain] [AppInfoParser:120] <init>   Kafka commitId: f8c67dc3ae0a3265
2023-12-01 16:09:05.121 INFO  ---- [tartedMain] [AppInfoParser:121] <init>   Kafka startTimeMs: 1701414545120
2023-12-01 16:09:05.122 INFO  ---- [tartedMain] [KafkaConsumer:966] subscribe   [Consumer clientId=consumer-task.member.v1-2, groupId=task.member.v1] Subscribed to topic(s): task-member
2023-12-01 16:09:05.127 INFO  ---- [tartedMain] [ConsumerConfig:376] logAll   ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-task.product.v1-3
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = task.product.v1
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2023-12-01 16:09:05.137 INFO  ---- [tartedMain] [AppInfoParser:119] <init>   Kafka version: 3.1.2
2023-12-01 16:09:05.138 INFO  ---- [tartedMain] [AppInfoParser:120] <init>   Kafka commitId: f8c67dc3ae0a3265
2023-12-01 16:09:05.138 INFO  ---- [tartedMain] [AppInfoParser:121] <init>   Kafka startTimeMs: 1701414545137
2023-12-01 16:09:05.138 INFO  ---- [tartedMain] [KafkaConsumer:966] subscribe   [Consumer clientId=consumer-task.product.v1-3, groupId=task.product.v1] Subscribed to topic(s): task-product
2023-12-01 16:09:05.157 INFO  ---- [tartedMain] [TomcatWebServer:220] start   Tomcat started on port(s): 59931 (http) with context path ''
2023-12-01 16:09:05.158 INFO  ---- [tartedMain] [EurekaAutoServiceRegistration:144] onApplicationEvent   Updating port to 59931
2023-12-01 16:09:05.164 INFO  ---- [tartedMain] [InstanceInfoFactory:67] create   Setting initial instance status as: STARTING
2023-12-01 16:09:05.236 INFO  ---- [tartedMain] [DiscoveryClient:372] <init>   Initializing Eureka in region us-east-1
2023-12-01 16:09:05.242 INFO  ---- [tartedMain] [ConfigClusterResolver:43] getClusterEndpoints   Resolving eureka endpoints via configuration
2023-12-01 16:09:05.268 INFO  ---- [tartedMain] [DiscoveryClient:1007] fetchRegistry   Disable delta property : false
2023-12-01 16:09:05.268 INFO  ---- [tartedMain] [DiscoveryClient:1008] fetchRegistry   Single vip registry refresh property : null
2023-12-01 16:09:05.268 INFO  ---- [tartedMain] [DiscoveryClient:1009] fetchRegistry   Force full registry fetch : false
2023-12-01 16:09:05.269 INFO  ---- [tartedMain] [DiscoveryClient:1010] fetchRegistry   Application is null : false
2023-12-01 16:09:05.269 INFO  ---- [tartedMain] [DiscoveryClient:1011] fetchRegistry   Registered Applications size is zero : true
2023-12-01 16:09:05.269 INFO  ---- [tartedMain] [DiscoveryClient:1013] fetchRegistry   Application version is -1: true
2023-12-01 16:09:05.269 INFO  ---- [tartedMain] [DiscoveryClient:1097] getAndStoreFullRegistry   Getting all instance registry info from the eureka server
2023-12-01 16:09:05.577 INFO  ---- [er#1-0-C-1] [Metadata:402] updateLatestMetadata   [Consumer clientId=consumer-task.product.v1-3, groupId=task.product.v1] Resetting the last seen epoch of partition task-product-0 to 9 since the associated topicId changed from null to h57hDuqlT3KmUT32pFF5uQ
2023-12-01 16:09:05.577 INFO  ---- [er#2-0-C-1] [Metadata:402] updateLatestMetadata   [Consumer clientId=consumer-order.group.v1-1, groupId=order.group.v1] Resetting the last seen epoch of partition order-0 to 0 since the associated topicId changed from null to 8AIo0qkzSIiGJbn1bQxAkw
2023-12-01 16:09:05.577 INFO  ---- [er#0-0-C-1] [Metadata:402] updateLatestMetadata   [Consumer clientId=consumer-task.member.v1-2, groupId=task.member.v1] Resetting the last seen epoch of partition task-member-0 to 9 since the associated topicId changed from null to HvfbkcRhQ3meTIJFgCt9zw
2023-12-01 16:09:05.582 INFO  ---- [er#0-0-C-1] [Metadata:287] update   [Consumer clientId=consumer-task.member.v1-2, groupId=task.member.v1] Cluster ID: 5_U1uds-SGaR4vItj-jqUw
2023-12-01 16:09:05.582 INFO  ---- [er#1-0-C-1] [Metadata:287] update   [Consumer clientId=consumer-task.product.v1-3, groupId=task.product.v1] Cluster ID: 5_U1uds-SGaR4vItj-jqUw
2023-12-01 16:09:05.582 INFO  ---- [er#2-0-C-1] [Metadata:287] update   [Consumer clientId=consumer-order.group.v1-1, groupId=order.group.v1] Cluster ID: 5_U1uds-SGaR4vItj-jqUw
2023-12-01 16:09:05.585 INFO  ---- [er#0-0-C-1] [ConsumerCoordinator:853] onSuccess   [Consumer clientId=consumer-task.member.v1-2, groupId=task.member.v1] Discovered group coordinator 127.0.0.1:9093 (id: 2147483644 rack: null)
2023-12-01 16:09:05.585 INFO  ---- [er#2-0-C-1] [ConsumerCoordinator:853] onSuccess   [Consumer clientId=consumer-order.group.v1-1, groupId=order.group.v1] Discovered group coordinator 127.0.0.1:9091 (id: 2147483646 rack: null)
2023-12-01 16:09:05.585 INFO  ---- [er#1-0-C-1] [ConsumerCoordinator:853] onSuccess   [Consumer clientId=consumer-task.product.v1-3, groupId=task.product.v1] Discovered group coordinator 127.0.0.1:9091 (id: 2147483646 rack: null)
2023-12-01 16:09:05.589 INFO  ---- [er#0-0-C-1] [ConsumerCoordinator:535] sendJoinGroupRequest   [Consumer clientId=consumer-task.member.v1-2, groupId=task.member.v1] (Re-)joining group
2023-12-01 16:09:05.589 INFO  ---- [er#1-0-C-1] [ConsumerCoordinator:535] sendJoinGroupRequest   [Consumer clientId=consumer-task.product.v1-3, groupId=task.product.v1] (Re-)joining group
2023-12-01 16:09:05.589 INFO  ---- [er#2-0-C-1] [ConsumerCoordinator:535] sendJoinGroupRequest   [Consumer clientId=consumer-order.group.v1-1, groupId=order.group.v1] (Re-)joining group
2023-12-01 16:09:05.612 INFO  ---- [er#0-0-C-1] [ConsumerCoordinator:1000] requestRejoin   [Consumer clientId=consumer-task.member.v1-2, groupId=task.member.v1] Request joining group due to: need to re-join with the given member-id
2023-12-01 16:09:05.612 INFO  ---- [er#2-0-C-1] [ConsumerCoordinator:1000] requestRejoin   [Consumer clientId=consumer-order.group.v1-1, groupId=order.group.v1] Request joining group due to: need to re-join with the given member-id
2023-12-01 16:09:05.612 INFO  ---- [er#1-0-C-1] [ConsumerCoordinator:1000] requestRejoin   [Consumer clientId=consumer-task.product.v1-3, groupId=task.product.v1] Request joining group due to: need to re-join with the given member-id
2023-12-01 16:09:05.613 INFO  ---- [er#1-0-C-1] [ConsumerCoordinator:535] sendJoinGroupRequest   [Consumer clientId=consumer-task.product.v1-3, groupId=task.product.v1] (Re-)joining group
2023-12-01 16:09:05.613 INFO  ---- [er#0-0-C-1] [ConsumerCoordinator:535] sendJoinGroupRequest   [Consumer clientId=consumer-task.member.v1-2, groupId=task.member.v1] (Re-)joining group
2023-12-01 16:09:05.613 INFO  ---- [er#2-0-C-1] [ConsumerCoordinator:535] sendJoinGroupRequest   [Consumer clientId=consumer-order.group.v1-1, groupId=order.group.v1] (Re-)joining group
2023-12-01 16:09:05.681 INFO  ---- [tartedMain] [DiscoveryClient:1106] getAndStoreFullRegistry   The response status is 200
2023-12-01 16:09:05.688 INFO  ---- [tartedMain] [DiscoveryClient:1321] initScheduledTasks   Starting heartbeat executor: renew interval is: 30
2023-12-01 16:09:05.693 INFO  ---- [tartedMain] [InstanceInfoReplicator:60] <init>   InstanceInfoReplicator onDemand update allowed rate per min is 4
2023-12-01 16:09:05.702 INFO  ---- [tartedMain] [DiscoveryClient:492] <init>   Discovery Client initialized at timestamp 1701414545700 with initial instances count: 6
2023-12-01 16:09:05.704 INFO  ---- [tartedMain] [EurekaServiceRegistry:41] register   Registering application TASK-SERVICE with eureka with status UP
2023-12-01 16:09:05.706 INFO  ---- [tartedMain] [DiscoveryClient:1352] notify   Saw local status change event StatusChangeEvent [timestamp=1701414545706, current=UP, previous=STARTING]
2023-12-01 16:09:05.710 INFO  ---- [plicator-0] [DiscoveryClient:873] register   DiscoveryClient_TASK-SERVICE/192.168.0.17:99352df3843028fd6fb9c827e7d103a1: registering service...
2023-12-01 16:09:05.775 INFO  ---- [plicator-0] [DiscoveryClient:882] register   DiscoveryClient_TASK-SERVICE/192.168.0.17:99352df3843028fd6fb9c827e7d103a1 - registration status: 204
2023-12-01 16:09:06.987 INFO  ---- [tartedMain] [TaskConsumerApplication:61] logStarted   Started TaskConsumerApplication in 17.763 seconds (JVM running for 19.288)
2023-12-01 16:09:07.209 INFO  ---- [er#0-0-C-1] [ConsumerCoordinator:595] handle   [Consumer clientId=consumer-task.member.v1-2, groupId=task.member.v1] Successfully joined group with generation Generation{generationId=50, memberId='consumer-task.member.v1-2-76592cb3-e142-40af-9bea-0117a5f318fa', protocol='range'}
2023-12-01 16:09:07.217 INFO  ---- [er#0-0-C-1] [ConsumerCoordinator:659] performAssignment   [Consumer clientId=consumer-task.member.v1-2, groupId=task.member.v1] Finished assignment for group at generation 50: {consumer-task.member.v1-2-76592cb3-e142-40af-9bea-0117a5f318fa=Assignment(partitions=[task-member-0])}
2023-12-01 16:09:07.244 INFO  ---- [er#0-0-C-1] [ConsumerCoordinator:761] handle   [Consumer clientId=consumer-task.member.v1-2, groupId=task.member.v1] Successfully synced group in generation Generation{generationId=50, memberId='consumer-task.member.v1-2-76592cb3-e142-40af-9bea-0117a5f318fa', protocol='range'}
2023-12-01 16:09:07.246 INFO  ---- [er#0-0-C-1] [ConsumerCoordinator:280] invokeOnAssignment   [Consumer clientId=consumer-task.member.v1-2, groupId=task.member.v1] Notifying assignor about the new Assignment(partitions=[task-member-0])
2023-12-01 16:09:07.254 INFO  ---- [er#0-0-C-1] [ConsumerCoordinator:292] invokePartitionsAssigned   [Consumer clientId=consumer-task.member.v1-2, groupId=task.member.v1] Adding newly assigned partitions: task-member-0
2023-12-01 16:09:07.292 INFO  ---- [er#0-0-C-1] [ConsumerCoordinator:851] refreshCommittedOffsetsIfNeeded   [Consumer clientId=consumer-task.member.v1-2, groupId=task.member.v1] Setting offset for partition task-member-0 to the committed offset FetchPosition{offset=6, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[127.0.0.1:9091 (id: 1 rack: null)], epoch=9}}
2023-12-01 16:09:07.294 INFO  ---- [er#0-0-C-1] [KafkaMessageListenerContainer:292] info   task.member.v1: partitions assigned: [task-member-0]
2023-12-01 16:09:07.298 INFO  ---- [er#1-0-C-1] [ConsumerCoordinator:595] handle   [Consumer clientId=consumer-task.product.v1-3, groupId=task.product.v1] Successfully joined group with generation Generation{generationId=50, memberId='consumer-task.product.v1-3-9d73adea-fb21-49da-a1ab-89309f03d4be', protocol='range'}
2023-12-01 16:09:07.299 INFO  ---- [er#1-0-C-1] [ConsumerCoordinator:659] performAssignment   [Consumer clientId=consumer-task.product.v1-3, groupId=task.product.v1] Finished assignment for group at generation 50: {consumer-task.product.v1-3-9d73adea-fb21-49da-a1ab-89309f03d4be=Assignment(partitions=[task-product-0])}
2023-12-01 16:09:07.308 INFO  ---- [er#1-0-C-1] [ConsumerCoordinator:761] handle   [Consumer clientId=consumer-task.product.v1-3, groupId=task.product.v1] Successfully synced group in generation Generation{generationId=50, memberId='consumer-task.product.v1-3-9d73adea-fb21-49da-a1ab-89309f03d4be', protocol='range'}
2023-12-01 16:09:07.309 INFO  ---- [er#1-0-C-1] [ConsumerCoordinator:280] invokeOnAssignment   [Consumer clientId=consumer-task.product.v1-3, groupId=task.product.v1] Notifying assignor about the new Assignment(partitions=[task-product-0])
2023-12-01 16:09:07.309 INFO  ---- [er#1-0-C-1] [ConsumerCoordinator:292] invokePartitionsAssigned   [Consumer clientId=consumer-task.product.v1-3, groupId=task.product.v1] Adding newly assigned partitions: task-product-0
2023-12-01 16:09:07.319 INFO  ---- [er#1-0-C-1] [ConsumerCoordinator:851] refreshCommittedOffsetsIfNeeded   [Consumer clientId=consumer-task.product.v1-3, groupId=task.product.v1] Setting offset for partition task-product-0 to the committed offset FetchPosition{offset=1, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[127.0.0.1:9091 (id: 1 rack: null)], epoch=9}}
2023-12-01 16:09:07.319 INFO  ---- [er#1-0-C-1] [KafkaMessageListenerContainer:292] info   task.product.v1: partitions assigned: [task-product-0]
2023-12-01 16:09:07.633 INFO  ---- [er#2-0-C-1] [ConsumerCoordinator:595] handle   [Consumer clientId=consumer-order.group.v1-1, groupId=order.group.v1] Successfully joined group with generation Generation{generationId=7, memberId='consumer-order.group.v1-1-5c57387c-fc44-4e9e-833f-31c1268d9630', protocol='range'}
2023-12-01 16:09:07.633 INFO  ---- [er#2-0-C-1] [ConsumerCoordinator:659] performAssignment   [Consumer clientId=consumer-order.group.v1-1, groupId=order.group.v1] Finished assignment for group at generation 7: {consumer-order.group.v1-1-5c57387c-fc44-4e9e-833f-31c1268d9630=Assignment(partitions=[order-0])}
2023-12-01 16:09:07.640 INFO  ---- [er#2-0-C-1] [ConsumerCoordinator:761] handle   [Consumer clientId=consumer-order.group.v1-1, groupId=order.group.v1] Successfully synced group in generation Generation{generationId=7, memberId='consumer-order.group.v1-1-5c57387c-fc44-4e9e-833f-31c1268d9630', protocol='range'}
2023-12-01 16:09:07.641 INFO  ---- [er#2-0-C-1] [ConsumerCoordinator:280] invokeOnAssignment   [Consumer clientId=consumer-order.group.v1-1, groupId=order.group.v1] Notifying assignor about the new Assignment(partitions=[order-0])
2023-12-01 16:09:07.641 INFO  ---- [er#2-0-C-1] [ConsumerCoordinator:292] invokePartitionsAssigned   [Consumer clientId=consumer-order.group.v1-1, groupId=order.group.v1] Adding newly assigned partitions: order-0
2023-12-01 16:09:07.649 INFO  ---- [er#2-0-C-1] [ConsumerCoordinator:851] refreshCommittedOffsetsIfNeeded   [Consumer clientId=consumer-order.group.v1-1, groupId=order.group.v1] Setting offset for partition order-0 to the committed offset FetchPosition{offset=6, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[127.0.0.1:9092 (id: 2 rack: null)], epoch=0}}
2023-12-01 16:09:07.650 INFO  ---- [er#2-0-C-1] [KafkaMessageListenerContainer:292] info   order.group.v1: partitions assigned: [order-0]
2023-12-01 16:09:07.753 INFO  ---- [er#2-0-C-1] [ProducerConfig:376] logAll   ProducerConfig values: 
	acks = -1
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-1
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2023-12-01 16:09:07.766 INFO  ---- [er#2-0-C-1] [KafkaProducer:572] configureTransactionState   [Producer clientId=producer-1] Instantiated an idempotent producer.
2023-12-01 16:09:07.783 INFO  ---- [er#2-0-C-1] [AppInfoParser:119] <init>   Kafka version: 3.1.2
2023-12-01 16:09:07.783 INFO  ---- [er#2-0-C-1] [AppInfoParser:120] <init>   Kafka commitId: f8c67dc3ae0a3265
2023-12-01 16:09:07.784 INFO  ---- [er#2-0-C-1] [AppInfoParser:121] <init>   Kafka startTimeMs: 1701414547783
2023-12-01 16:09:07.795 INFO  ---- [producer-1] [Metadata:402] updateLatestMetadata   [Producer clientId=producer-1] Resetting the last seen epoch of partition member-check-0 to 4 since the associated topicId changed from null to KYr4s4QASse48T8_YcW_QA
2023-12-01 16:09:07.795 INFO  ---- [producer-1] [Metadata:287] update   [Producer clientId=producer-1] Cluster ID: 5_U1uds-SGaR4vItj-jqUw
2023-12-01 16:09:07.797 INFO  ---- [producer-1] [TransactionManager:554] setProducerIdAndEpoch   [Producer clientId=producer-1] ProducerId set to 4008 with epoch 0
2023-12-01 16:09:14.788 INFO  ---- [producer-1] [Metadata:402] updateLatestMetadata   [Producer clientId=producer-1] Resetting the last seen epoch of partition product-check-0 to 2 since the associated topicId changed from null to NcmASD39SLaSfi1cR4a0aw
2023-12-01 16:09:46.517 INFO  ---- [tartedMain] [TaskConsumerApplication:55] logStarting   Starting TaskConsumerApplication using Java 11.0.13 on DESKTOP-MNMB87E with PID 34456 (C:\Users\tkdrb\IdeaProjects\ecommerce\task-consumer\build\classes\java\main started by tkdrb in C:\Users\tkdrb\IdeaProjects\ecommerce\task-consumer)
2023-12-01 16:09:46.520 INFO  ---- [tartedMain] [TaskConsumerApplication:631] logStartupProfileInfo   No active profile set, falling back to 1 default profile: "default"
2023-12-01 16:09:46.605 INFO  ---- [tartedMain] [DevToolsPropertyDefaultsPostProcessor:255] logTo   Devtools property defaults active! Set 'spring.devtools.add-properties' to 'false' to disable
2023-12-01 16:09:46.605 INFO  ---- [tartedMain] [DevToolsPropertyDefaultsPostProcessor:255] logTo   For additional web related logging consider setting the 'logging.level.web' property to 'DEBUG'
2023-12-01 16:09:48.501 INFO  ---- [tartedMain] [GenericScope:283] setSerializationId   BeanFactory id=7d336d03-7948-373b-80b2-3edd326128fe
2023-12-01 16:09:50.840 INFO  ---- [tartedMain] [TomcatWebServer:108] initialize   Tomcat initialized with port(s): 0 (http)
2023-12-01 16:09:50.869 INFO  ---- [tartedMain] [StandardService:173] log   Starting service [Tomcat]
2023-12-01 16:09:50.871 INFO  ---- [tartedMain] [StandardEngine:173] log   Starting Servlet engine: [Apache Tomcat/9.0.76]
2023-12-01 16:09:51.286 INFO  ---- [tartedMain] [[/]:173] log   Initializing Spring embedded WebApplicationContext
2023-12-01 16:09:51.287 INFO  ---- [tartedMain] [ServletWebServerApplicationContext:292] prepareWebApplicationContext   Root WebApplicationContext: initialization completed in 4681 ms
2023-12-01 16:09:52.557 INFO  ---- [tartedMain] [OptionalLiveReloadServer:59] startServer   LiveReload server is running on port 35729
2023-12-01 16:09:54.461 INFO  ---- [tartedMain] [DiscoveryClientOptionalArgsConfiguration:71] restTemplateDiscoveryClientOptionalArgs   Eureka HTTP Client uses RestTemplate.
2023-12-01 16:09:56.283 WARN  ---- [tartedMain] [LoadBalancerCacheAutoConfiguration$LoadBalancerCaffeineWarnLogger:83] logWarning   Spring Cloud LoadBalancer is currently working with the default cache. While this cache implementation is useful for development and tests, it's recommended to use Caffeine cache in production.You can switch to using Caffeine cache, by adding it and org.springframework.cache.caffeine.CaffeineCacheManager to the classpath.
2023-12-01 16:09:56.410 INFO  ---- [tartedMain] [ConsumerConfig:376] logAll   ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-order.group.v1-1
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = order.group.v1
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2023-12-01 16:09:56.590 INFO  ---- [tartedMain] [AppInfoParser:119] <init>   Kafka version: 3.1.2
2023-12-01 16:09:56.592 INFO  ---- [tartedMain] [AppInfoParser:120] <init>   Kafka commitId: f8c67dc3ae0a3265
2023-12-01 16:09:56.592 INFO  ---- [tartedMain] [AppInfoParser:121] <init>   Kafka startTimeMs: 1701414596588
2023-12-01 16:09:56.597 INFO  ---- [tartedMain] [KafkaConsumer:966] subscribe   [Consumer clientId=consumer-order.group.v1-1, groupId=order.group.v1] Subscribed to topic(s): order
2023-12-01 16:09:56.615 INFO  ---- [tartedMain] [ConsumerConfig:376] logAll   ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-task.member.v1-2
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = task.member.v1
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2023-12-01 16:09:56.624 INFO  ---- [tartedMain] [AppInfoParser:119] <init>   Kafka version: 3.1.2
2023-12-01 16:09:56.625 INFO  ---- [tartedMain] [AppInfoParser:120] <init>   Kafka commitId: f8c67dc3ae0a3265
2023-12-01 16:09:56.625 INFO  ---- [tartedMain] [AppInfoParser:121] <init>   Kafka startTimeMs: 1701414596624
2023-12-01 16:09:56.625 INFO  ---- [tartedMain] [KafkaConsumer:966] subscribe   [Consumer clientId=consumer-task.member.v1-2, groupId=task.member.v1] Subscribed to topic(s): task-member
2023-12-01 16:09:56.629 INFO  ---- [tartedMain] [ConsumerConfig:376] logAll   ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-task.product.v1-3
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = task.product.v1
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2023-12-01 16:09:56.638 INFO  ---- [tartedMain] [AppInfoParser:119] <init>   Kafka version: 3.1.2
2023-12-01 16:09:56.638 INFO  ---- [tartedMain] [AppInfoParser:120] <init>   Kafka commitId: f8c67dc3ae0a3265
2023-12-01 16:09:56.638 INFO  ---- [tartedMain] [AppInfoParser:121] <init>   Kafka startTimeMs: 1701414596638
2023-12-01 16:09:56.639 INFO  ---- [tartedMain] [KafkaConsumer:966] subscribe   [Consumer clientId=consumer-task.product.v1-3, groupId=task.product.v1] Subscribed to topic(s): task-product
2023-12-01 16:09:56.656 INFO  ---- [tartedMain] [TomcatWebServer:220] start   Tomcat started on port(s): 59974 (http) with context path ''
2023-12-01 16:09:56.657 INFO  ---- [tartedMain] [EurekaAutoServiceRegistration:144] onApplicationEvent   Updating port to 59974
2023-12-01 16:09:56.664 INFO  ---- [tartedMain] [InstanceInfoFactory:67] create   Setting initial instance status as: STARTING
2023-12-01 16:09:56.719 INFO  ---- [tartedMain] [DiscoveryClient:372] <init>   Initializing Eureka in region us-east-1
2023-12-01 16:09:56.727 INFO  ---- [tartedMain] [ConfigClusterResolver:43] getClusterEndpoints   Resolving eureka endpoints via configuration
2023-12-01 16:09:56.762 INFO  ---- [tartedMain] [DiscoveryClient:1007] fetchRegistry   Disable delta property : false
2023-12-01 16:09:56.763 INFO  ---- [tartedMain] [DiscoveryClient:1008] fetchRegistry   Single vip registry refresh property : null
2023-12-01 16:09:56.763 INFO  ---- [tartedMain] [DiscoveryClient:1009] fetchRegistry   Force full registry fetch : false
2023-12-01 16:09:56.763 INFO  ---- [tartedMain] [DiscoveryClient:1010] fetchRegistry   Application is null : false
2023-12-01 16:09:56.763 INFO  ---- [tartedMain] [DiscoveryClient:1011] fetchRegistry   Registered Applications size is zero : true
2023-12-01 16:09:56.764 INFO  ---- [tartedMain] [DiscoveryClient:1013] fetchRegistry   Application version is -1: true
2023-12-01 16:09:56.764 INFO  ---- [tartedMain] [DiscoveryClient:1097] getAndStoreFullRegistry   Getting all instance registry info from the eureka server
2023-12-01 16:09:57.124 INFO  ---- [er#0-0-C-1] [Metadata:402] updateLatestMetadata   [Consumer clientId=consumer-task.member.v1-2, groupId=task.member.v1] Resetting the last seen epoch of partition task-member-0 to 9 since the associated topicId changed from null to HvfbkcRhQ3meTIJFgCt9zw
2023-12-01 16:09:57.124 INFO  ---- [er#1-0-C-1] [Metadata:402] updateLatestMetadata   [Consumer clientId=consumer-task.product.v1-3, groupId=task.product.v1] Resetting the last seen epoch of partition task-product-0 to 9 since the associated topicId changed from null to h57hDuqlT3KmUT32pFF5uQ
2023-12-01 16:09:57.124 INFO  ---- [er#2-0-C-1] [Metadata:402] updateLatestMetadata   [Consumer clientId=consumer-order.group.v1-1, groupId=order.group.v1] Resetting the last seen epoch of partition order-0 to 0 since the associated topicId changed from null to 8AIo0qkzSIiGJbn1bQxAkw
2023-12-01 16:09:57.129 INFO  ---- [er#2-0-C-1] [Metadata:287] update   [Consumer clientId=consumer-order.group.v1-1, groupId=order.group.v1] Cluster ID: 5_U1uds-SGaR4vItj-jqUw
2023-12-01 16:09:57.129 INFO  ---- [er#1-0-C-1] [Metadata:287] update   [Consumer clientId=consumer-task.product.v1-3, groupId=task.product.v1] Cluster ID: 5_U1uds-SGaR4vItj-jqUw
2023-12-01 16:09:57.129 INFO  ---- [er#0-0-C-1] [Metadata:287] update   [Consumer clientId=consumer-task.member.v1-2, groupId=task.member.v1] Cluster ID: 5_U1uds-SGaR4vItj-jqUw
2023-12-01 16:09:57.130 INFO  ---- [er#0-0-C-1] [ConsumerCoordinator:853] onSuccess   [Consumer clientId=consumer-task.member.v1-2, groupId=task.member.v1] Discovered group coordinator 127.0.0.1:9093 (id: 2147483644 rack: null)
2023-12-01 16:09:57.130 INFO  ---- [er#1-0-C-1] [ConsumerCoordinator:853] onSuccess   [Consumer clientId=consumer-task.product.v1-3, groupId=task.product.v1] Discovered group coordinator 127.0.0.1:9091 (id: 2147483646 rack: null)
2023-12-01 16:09:57.130 INFO  ---- [er#2-0-C-1] [ConsumerCoordinator:853] onSuccess   [Consumer clientId=consumer-order.group.v1-1, groupId=order.group.v1] Discovered group coordinator 127.0.0.1:9091 (id: 2147483646 rack: null)
2023-12-01 16:09:57.136 INFO  ---- [er#1-0-C-1] [ConsumerCoordinator:535] sendJoinGroupRequest   [Consumer clientId=consumer-task.product.v1-3, groupId=task.product.v1] (Re-)joining group
2023-12-01 16:09:57.136 INFO  ---- [er#2-0-C-1] [ConsumerCoordinator:535] sendJoinGroupRequest   [Consumer clientId=consumer-order.group.v1-1, groupId=order.group.v1] (Re-)joining group
2023-12-01 16:09:57.136 INFO  ---- [er#0-0-C-1] [ConsumerCoordinator:535] sendJoinGroupRequest   [Consumer clientId=consumer-task.member.v1-2, groupId=task.member.v1] (Re-)joining group
2023-12-01 16:09:57.174 INFO  ---- [er#0-0-C-1] [ConsumerCoordinator:1000] requestRejoin   [Consumer clientId=consumer-task.member.v1-2, groupId=task.member.v1] Request joining group due to: need to re-join with the given member-id
2023-12-01 16:09:57.174 INFO  ---- [er#2-0-C-1] [ConsumerCoordinator:1000] requestRejoin   [Consumer clientId=consumer-order.group.v1-1, groupId=order.group.v1] Request joining group due to: need to re-join with the given member-id
2023-12-01 16:09:57.174 INFO  ---- [er#1-0-C-1] [ConsumerCoordinator:1000] requestRejoin   [Consumer clientId=consumer-task.product.v1-3, groupId=task.product.v1] Request joining group due to: need to re-join with the given member-id
2023-12-01 16:09:57.175 INFO  ---- [er#0-0-C-1] [ConsumerCoordinator:535] sendJoinGroupRequest   [Consumer clientId=consumer-task.member.v1-2, groupId=task.member.v1] (Re-)joining group
2023-12-01 16:09:57.175 INFO  ---- [er#1-0-C-1] [ConsumerCoordinator:535] sendJoinGroupRequest   [Consumer clientId=consumer-task.product.v1-3, groupId=task.product.v1] (Re-)joining group
2023-12-01 16:09:57.175 INFO  ---- [er#2-0-C-1] [ConsumerCoordinator:535] sendJoinGroupRequest   [Consumer clientId=consumer-order.group.v1-1, groupId=order.group.v1] (Re-)joining group
2023-12-01 16:09:57.223 INFO  ---- [tartedMain] [DiscoveryClient:1106] getAndStoreFullRegistry   The response status is 200
2023-12-01 16:09:57.227 INFO  ---- [tartedMain] [DiscoveryClient:1321] initScheduledTasks   Starting heartbeat executor: renew interval is: 30
2023-12-01 16:09:57.231 INFO  ---- [tartedMain] [InstanceInfoReplicator:60] <init>   InstanceInfoReplicator onDemand update allowed rate per min is 4
2023-12-01 16:09:57.237 INFO  ---- [tartedMain] [DiscoveryClient:492] <init>   Discovery Client initialized at timestamp 1701414597236 with initial instances count: 6
2023-12-01 16:09:57.239 INFO  ---- [tartedMain] [EurekaServiceRegistry:41] register   Registering application TASK-SERVICE with eureka with status UP
2023-12-01 16:09:57.241 INFO  ---- [tartedMain] [DiscoveryClient:1352] notify   Saw local status change event StatusChangeEvent [timestamp=1701414597241, current=UP, previous=STARTING]
2023-12-01 16:09:57.244 INFO  ---- [plicator-0] [DiscoveryClient:873] register   DiscoveryClient_TASK-SERVICE/192.168.0.17:904486aa0885800a3131468b756e40c4: registering service...
2023-12-01 16:09:57.300 INFO  ---- [plicator-0] [DiscoveryClient:882] register   DiscoveryClient_TASK-SERVICE/192.168.0.17:904486aa0885800a3131468b756e40c4 - registration status: 204
2023-12-01 16:09:58.617 INFO  ---- [tartedMain] [TaskConsumerApplication:61] logStarted   Started TaskConsumerApplication in 14.699 seconds (JVM running for 15.721)
2023-12-01 16:10:05.805 INFO  ---- [er#1-0-C-1] [ConsumerCoordinator:595] handle   [Consumer clientId=consumer-task.product.v1-3, groupId=task.product.v1] Successfully joined group with generation Generation{generationId=51, memberId='consumer-task.product.v1-3-2c71d953-ba02-48d7-b05e-5d690b113233', protocol='range'}
2023-12-01 16:10:05.805 INFO  ---- [er#0-0-C-1] [ConsumerCoordinator:595] handle   [Consumer clientId=consumer-task.member.v1-2, groupId=task.member.v1] Successfully joined group with generation Generation{generationId=51, memberId='consumer-task.member.v1-2-60a1b485-1bac-4d1a-95b6-c6c8dd4575aa', protocol='range'}
2023-12-01 16:10:05.813 INFO  ---- [er#0-0-C-1] [ConsumerCoordinator:659] performAssignment   [Consumer clientId=consumer-task.member.v1-2, groupId=task.member.v1] Finished assignment for group at generation 51: {consumer-task.member.v1-2-60a1b485-1bac-4d1a-95b6-c6c8dd4575aa=Assignment(partitions=[task-member-0])}
2023-12-01 16:10:05.813 INFO  ---- [er#1-0-C-1] [ConsumerCoordinator:659] performAssignment   [Consumer clientId=consumer-task.product.v1-3, groupId=task.product.v1] Finished assignment for group at generation 51: {consumer-task.product.v1-3-2c71d953-ba02-48d7-b05e-5d690b113233=Assignment(partitions=[task-product-0])}
2023-12-01 16:10:05.838 INFO  ---- [er#0-0-C-1] [ConsumerCoordinator:761] handle   [Consumer clientId=consumer-task.member.v1-2, groupId=task.member.v1] Successfully synced group in generation Generation{generationId=51, memberId='consumer-task.member.v1-2-60a1b485-1bac-4d1a-95b6-c6c8dd4575aa', protocol='range'}
2023-12-01 16:10:05.838 INFO  ---- [er#1-0-C-1] [ConsumerCoordinator:761] handle   [Consumer clientId=consumer-task.product.v1-3, groupId=task.product.v1] Successfully synced group in generation Generation{generationId=51, memberId='consumer-task.product.v1-3-2c71d953-ba02-48d7-b05e-5d690b113233', protocol='range'}
2023-12-01 16:10:05.840 INFO  ---- [er#1-0-C-1] [ConsumerCoordinator:280] invokeOnAssignment   [Consumer clientId=consumer-task.product.v1-3, groupId=task.product.v1] Notifying assignor about the new Assignment(partitions=[task-product-0])
2023-12-01 16:10:05.840 INFO  ---- [er#0-0-C-1] [ConsumerCoordinator:280] invokeOnAssignment   [Consumer clientId=consumer-task.member.v1-2, groupId=task.member.v1] Notifying assignor about the new Assignment(partitions=[task-member-0])
2023-12-01 16:10:05.850 INFO  ---- [er#0-0-C-1] [ConsumerCoordinator:292] invokePartitionsAssigned   [Consumer clientId=consumer-task.member.v1-2, groupId=task.member.v1] Adding newly assigned partitions: task-member-0
2023-12-01 16:10:05.850 INFO  ---- [er#1-0-C-1] [ConsumerCoordinator:292] invokePartitionsAssigned   [Consumer clientId=consumer-task.product.v1-3, groupId=task.product.v1] Adding newly assigned partitions: task-product-0
2023-12-01 16:10:05.890 INFO  ---- [er#0-0-C-1] [ConsumerCoordinator:851] refreshCommittedOffsetsIfNeeded   [Consumer clientId=consumer-task.member.v1-2, groupId=task.member.v1] Setting offset for partition task-member-0 to the committed offset FetchPosition{offset=7, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[127.0.0.1:9091 (id: 1 rack: null)], epoch=9}}
2023-12-01 16:10:05.891 INFO  ---- [er#1-0-C-1] [ConsumerCoordinator:851] refreshCommittedOffsetsIfNeeded   [Consumer clientId=consumer-task.product.v1-3, groupId=task.product.v1] Setting offset for partition task-product-0 to the committed offset FetchPosition{offset=1, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[127.0.0.1:9091 (id: 1 rack: null)], epoch=9}}
2023-12-01 16:10:05.893 INFO  ---- [er#0-0-C-1] [KafkaMessageListenerContainer:292] info   task.member.v1: partitions assigned: [task-member-0]
2023-12-01 16:10:05.893 INFO  ---- [er#1-0-C-1] [KafkaMessageListenerContainer:292] info   task.product.v1: partitions assigned: [task-product-0]
2023-12-01 16:10:05.911 INFO  ---- [er#2-0-C-1] [ConsumerCoordinator:595] handle   [Consumer clientId=consumer-order.group.v1-1, groupId=order.group.v1] Successfully joined group with generation Generation{generationId=8, memberId='consumer-order.group.v1-1-a4e086a4-397e-4156-98db-04079e449101', protocol='range'}
2023-12-01 16:10:05.912 INFO  ---- [er#2-0-C-1] [ConsumerCoordinator:659] performAssignment   [Consumer clientId=consumer-order.group.v1-1, groupId=order.group.v1] Finished assignment for group at generation 8: {consumer-order.group.v1-1-a4e086a4-397e-4156-98db-04079e449101=Assignment(partitions=[order-0])}
2023-12-01 16:10:05.920 INFO  ---- [er#2-0-C-1] [ConsumerCoordinator:761] handle   [Consumer clientId=consumer-order.group.v1-1, groupId=order.group.v1] Successfully synced group in generation Generation{generationId=8, memberId='consumer-order.group.v1-1-a4e086a4-397e-4156-98db-04079e449101', protocol='range'}
2023-12-01 16:10:05.921 INFO  ---- [er#2-0-C-1] [ConsumerCoordinator:280] invokeOnAssignment   [Consumer clientId=consumer-order.group.v1-1, groupId=order.group.v1] Notifying assignor about the new Assignment(partitions=[order-0])
2023-12-01 16:10:05.922 INFO  ---- [er#2-0-C-1] [ConsumerCoordinator:292] invokePartitionsAssigned   [Consumer clientId=consumer-order.group.v1-1, groupId=order.group.v1] Adding newly assigned partitions: order-0
2023-12-01 16:10:05.928 INFO  ---- [er#2-0-C-1] [ConsumerCoordinator:851] refreshCommittedOffsetsIfNeeded   [Consumer clientId=consumer-order.group.v1-1, groupId=order.group.v1] Setting offset for partition order-0 to the committed offset FetchPosition{offset=6, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[127.0.0.1:9092 (id: 2 rack: null)], epoch=0}}
2023-12-01 16:10:05.929 INFO  ---- [er#2-0-C-1] [KafkaMessageListenerContainer:292] info   order.group.v1: partitions assigned: [order-0]
2023-12-01 16:10:06.015 INFO  ---- [er#2-0-C-1] [ProducerConfig:376] logAll   ProducerConfig values: 
	acks = -1
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-1
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2023-12-01 16:10:06.027 INFO  ---- [er#2-0-C-1] [KafkaProducer:572] configureTransactionState   [Producer clientId=producer-1] Instantiated an idempotent producer.
2023-12-01 16:10:06.052 INFO  ---- [er#2-0-C-1] [AppInfoParser:119] <init>   Kafka version: 3.1.2
2023-12-01 16:10:06.053 INFO  ---- [er#2-0-C-1] [AppInfoParser:120] <init>   Kafka commitId: f8c67dc3ae0a3265
2023-12-01 16:10:06.053 INFO  ---- [er#2-0-C-1] [AppInfoParser:121] <init>   Kafka startTimeMs: 1701414606052
2023-12-01 16:10:06.067 INFO  ---- [producer-1] [Metadata:402] updateLatestMetadata   [Producer clientId=producer-1] Resetting the last seen epoch of partition member-check-0 to 4 since the associated topicId changed from null to KYr4s4QASse48T8_YcW_QA
2023-12-01 16:10:06.067 INFO  ---- [producer-1] [Metadata:287] update   [Producer clientId=producer-1] Cluster ID: 5_U1uds-SGaR4vItj-jqUw
2023-12-01 16:10:06.068 INFO  ---- [producer-1] [TransactionManager:554] setProducerIdAndEpoch   [Producer clientId=producer-1] ProducerId set to 4009 with epoch 0
2023-12-01 16:10:56.389 INFO  ---- [product.v1] [ConsumerCoordinator:916] markCoordinatorUnknown   [Consumer clientId=consumer-task.product.v1-3, groupId=task.product.v1] Group coordinator 127.0.0.1:9091 (id: 2147483646 rack: null) is unavailable or invalid due to cause: session timed out without receiving a heartbeat response.isDisconnected: false. Rediscovery will be attempted.
2023-12-01 16:10:56.386 INFO  ---- [.member.v1] [NetworkClient:797] handleTimedOutRequests   [Consumer clientId=consumer-task.member.v1-2, groupId=task.member.v1] Disconnecting from node 1 due to request timeout.
2023-12-01 16:10:56.389 INFO  ---- [r.group.v1] [ConsumerCoordinator:916] markCoordinatorUnknown   [Consumer clientId=consumer-order.group.v1-1, groupId=order.group.v1] Group coordinator 127.0.0.1:9091 (id: 2147483646 rack: null) is unavailable or invalid due to cause: session timed out without receiving a heartbeat response.isDisconnected: false. Rediscovery will be attempted.
2023-12-01 16:10:56.395 INFO  ---- [product.v1] [ConsumerCoordinator:929] markCoordinatorUnknown   [Consumer clientId=consumer-task.product.v1-3, groupId=task.product.v1] Requesting disconnect from last known coordinator 127.0.0.1:9091 (id: 2147483646 rack: null)
2023-12-01 16:10:56.395 INFO  ---- [r.group.v1] [ConsumerCoordinator:929] markCoordinatorUnknown   [Consumer clientId=consumer-order.group.v1-1, groupId=order.group.v1] Requesting disconnect from last known coordinator 127.0.0.1:9091 (id: 2147483646 rack: null)
2023-12-01 16:10:56.398 INFO  ---- [product.v1] [NetworkClient:324] disconnect   [Consumer clientId=consumer-task.product.v1-3, groupId=task.product.v1] Client requested disconnect from node 2147483646
2023-12-01 16:10:56.398 INFO  ---- [.member.v1] [NetworkClient:341] cancelInFlightRequests   [Consumer clientId=consumer-task.member.v1-2, groupId=task.member.v1] Cancelled in-flight FETCH request with correlation id 11 due to node 1 being disconnected (elapsed time since creation: 50265ms, elapsed time since send: 50264ms, request timeout: 30000ms)
2023-12-01 16:10:56.398 INFO  ---- [r.group.v1] [NetworkClient:324] disconnect   [Consumer clientId=consumer-order.group.v1-1, groupId=order.group.v1] Client requested disconnect from node 2147483646
2023-12-01 16:10:56.399 INFO  ---- [producer-1] [Metadata:402] updateLatestMetadata   [Producer clientId=producer-1] Resetting the last seen epoch of partition product-check-0 to 2 since the associated topicId changed from null to NcmASD39SLaSfi1cR4a0aw
2023-12-01 16:10:56.399 INFO  ---- [product.v1] [NetworkClient:341] cancelInFlightRequests   [Consumer clientId=consumer-task.product.v1-3, groupId=task.product.v1] Cancelled in-flight HEARTBEAT request with correlation id 11 due to node 2147483646 being disconnected (elapsed time since creation: 12044ms, elapsed time since send: 15ms, request timeout: 30000ms)
2023-12-01 16:10:56.400 INFO  ---- [r.group.v1] [NetworkClient:341] cancelInFlightRequests   [Consumer clientId=consumer-order.group.v1-1, groupId=order.group.v1] Cancelled in-flight HEARTBEAT request with correlation id 12 due to node 2147483646 being disconnected (elapsed time since creation: 12044ms, elapsed time since send: 26ms, request timeout: 30000ms)
2023-12-01 16:10:56.404 INFO  ---- [er#1-0-C-1] [NetworkClient:819] handleTimedOutConnections   [Consumer clientId=consumer-task.product.v1-3, groupId=task.product.v1] Disconnecting from node 2 due to socket connection setup timeout. The timeout value is 10583 ms.
2023-12-01 16:10:56.413 INFO  ---- [.member.v1] [FetchSessionHandler:602] handleError   [Consumer clientId=consumer-task.member.v1-2, groupId=task.member.v1] Error sending fetch request (sessionId=991321467, epoch=1) to node 1:
org.apache.kafka.common.errors.DisconnectException: null
2023-12-01 16:10:56.415 INFO  ---- [.member.v1] [ConsumerCoordinator:916] markCoordinatorUnknown   [Consumer clientId=consumer-task.member.v1-2, groupId=task.member.v1] Group coordinator 127.0.0.1:9093 (id: 2147483644 rack: null) is unavailable or invalid due to cause: session timed out without receiving a heartbeat response.isDisconnected: false. Rediscovery will be attempted.
2023-12-01 16:10:56.415 INFO  ---- [.member.v1] [ConsumerCoordinator:929] markCoordinatorUnknown   [Consumer clientId=consumer-task.member.v1-2, groupId=task.member.v1] Requesting disconnect from last known coordinator 127.0.0.1:9093 (id: 2147483644 rack: null)
2023-12-01 16:10:56.415 INFO  ---- [.member.v1] [NetworkClient:324] disconnect   [Consumer clientId=consumer-task.member.v1-2, groupId=task.member.v1] Client requested disconnect from node 2147483644
2023-12-01 16:10:56.418 INFO  ---- [.member.v1] [NetworkClient:341] cancelInFlightRequests   [Consumer clientId=consumer-task.member.v1-2, groupId=task.member.v1] Cancelled in-flight HEARTBEAT request with correlation id 12 due to node 2147483644 being disconnected (elapsed time since creation: 12063ms, elapsed time since send: 45ms, request timeout: 30000ms)
2023-12-01 16:10:56.420 INFO  ---- [er#1-0-C-1] [ConsumerCoordinator:853] onSuccess   [Consumer clientId=consumer-task.product.v1-3, groupId=task.product.v1] Discovered group coordinator 127.0.0.1:9091 (id: 2147483646 rack: null)
2023-12-01 16:10:56.430 INFO  ---- [er#1-0-C-1] [ConsumerCoordinator:853] onSuccess   [Consumer clientId=consumer-task.product.v1-3, groupId=task.product.v1] Discovered group coordinator 127.0.0.1:9091 (id: 2147483646 rack: null)
2023-12-01 16:10:56.431 INFO  ---- [er#1-0-C-1] [ConsumerCoordinator:916] markCoordinatorUnknown   [Consumer clientId=consumer-task.product.v1-3, groupId=task.product.v1] Group coordinator 127.0.0.1:9091 (id: 2147483646 rack: null) is unavailable or invalid due to cause: coordinator unavailable.isDisconnected: false. Rediscovery will be attempted.
2023-12-01 16:10:56.432 INFO  ---- [er#1-0-C-1] [ConsumerCoordinator:929] markCoordinatorUnknown   [Consumer clientId=consumer-task.product.v1-3, groupId=task.product.v1] Requesting disconnect from last known coordinator 127.0.0.1:9091 (id: 2147483646 rack: null)
2023-12-01 16:10:56.434 INFO  ---- [er#0-0-C-1] [ConsumerCoordinator:853] onSuccess   [Consumer clientId=consumer-task.member.v1-2, groupId=task.member.v1] Discovered group coordinator 127.0.0.1:9093 (id: 2147483644 rack: null)
2023-12-01 16:10:56.436 INFO  ---- [er#0-0-C-1] [ConsumerCoordinator:853] onSuccess   [Consumer clientId=consumer-task.member.v1-2, groupId=task.member.v1] Discovered group coordinator 127.0.0.1:9093 (id: 2147483644 rack: null)
2023-12-01 16:10:56.437 INFO  ---- [er#0-0-C-1] [ConsumerCoordinator:916] markCoordinatorUnknown   [Consumer clientId=consumer-task.member.v1-2, groupId=task.member.v1] Group coordinator 127.0.0.1:9093 (id: 2147483644 rack: null) is unavailable or invalid due to cause: coordinator unavailable.isDisconnected: false. Rediscovery will be attempted.
2023-12-01 16:10:56.437 INFO  ---- [er#0-0-C-1] [ConsumerCoordinator:929] markCoordinatorUnknown   [Consumer clientId=consumer-task.member.v1-2, groupId=task.member.v1] Requesting disconnect from last known coordinator 127.0.0.1:9093 (id: 2147483644 rack: null)
2023-12-01 16:10:56.547 INFO  ---- [er#0-0-C-1] [ConsumerCoordinator:853] onSuccess   [Consumer clientId=consumer-task.member.v1-2, groupId=task.member.v1] Discovered group coordinator 127.0.0.1:9093 (id: 2147483644 rack: null)
2023-12-01 16:10:56.547 INFO  ---- [er#1-0-C-1] [ConsumerCoordinator:853] onSuccess   [Consumer clientId=consumer-task.product.v1-3, groupId=task.product.v1] Discovered group coordinator 127.0.0.1:9091 (id: 2147483646 rack: null)
2023-12-01 16:10:56.561 INFO  ---- [er#1-0-C-1] [ConsumerCoordinator:1153] handle   [Consumer clientId=consumer-task.product.v1-3, groupId=task.product.v1] Attempt to heartbeat with Generation{generationId=51, memberId='consumer-task.product.v1-3-2c71d953-ba02-48d7-b05e-5d690b113233', protocol='range'} and group instance id Optional.empty failed due to UNKNOWN_MEMBER_ID, resetting generation
2023-12-01 16:10:56.561 INFO  ---- [er#1-0-C-1] [ConsumerCoordinator:972] resetStateAndGeneration   [Consumer clientId=consumer-task.product.v1-3, groupId=task.product.v1] Resetting generation due to: encountered UNKNOWN_MEMBER_ID from HEARTBEAT response
2023-12-01 16:10:56.562 INFO  ---- [er#1-0-C-1] [ConsumerCoordinator:1000] requestRejoin   [Consumer clientId=consumer-task.product.v1-3, groupId=task.product.v1] Request joining group due to: encountered UNKNOWN_MEMBER_ID from HEARTBEAT response
2023-12-01 16:10:56.562 INFO  ---- [er#1-0-C-1] [ConsumerCoordinator:724] onJoinPrepare   [Consumer clientId=consumer-task.product.v1-3, groupId=task.product.v1] Giving away all assigned partitions as lost since generation has been reset,indicating that consumer is no longer part of the group
2023-12-01 16:10:56.562 INFO  ---- [er#1-0-C-1] [ConsumerCoordinator:330] invokePartitionsLost   [Consumer clientId=consumer-task.product.v1-3, groupId=task.product.v1] Lost previously assigned partitions task-product-0
2023-12-01 16:10:56.563 INFO  ---- [er#0-0-C-1] [ConsumerCoordinator:1153] handle   [Consumer clientId=consumer-task.member.v1-2, groupId=task.member.v1] Attempt to heartbeat with Generation{generationId=51, memberId='consumer-task.member.v1-2-60a1b485-1bac-4d1a-95b6-c6c8dd4575aa', protocol='range'} and group instance id Optional.empty failed due to UNKNOWN_MEMBER_ID, resetting generation
2023-12-01 16:10:56.563 INFO  ---- [er#0-0-C-1] [ConsumerCoordinator:972] resetStateAndGeneration   [Consumer clientId=consumer-task.member.v1-2, groupId=task.member.v1] Resetting generation due to: encountered UNKNOWN_MEMBER_ID from HEARTBEAT response
2023-12-01 16:10:56.563 INFO  ---- [er#0-0-C-1] [ConsumerCoordinator:1000] requestRejoin   [Consumer clientId=consumer-task.member.v1-2, groupId=task.member.v1] Request joining group due to: encountered UNKNOWN_MEMBER_ID from HEARTBEAT response
2023-12-01 16:10:56.563 INFO  ---- [er#1-0-C-1] [KafkaMessageListenerContainer:292] info   task.product.v1: partitions lost: [task-product-0]
2023-12-01 16:10:56.564 INFO  ---- [er#1-0-C-1] [KafkaMessageListenerContainer:292] info   task.product.v1: partitions revoked: [task-product-0]
2023-12-01 16:10:56.564 INFO  ---- [er#1-0-C-1] [ConsumerCoordinator:535] sendJoinGroupRequest   [Consumer clientId=consumer-task.product.v1-3, groupId=task.product.v1] (Re-)joining group
2023-12-01 16:10:56.568 ERROR ---- [er#0-0-C-1] [ConsumerCoordinator:1231] handle   [Consumer clientId=consumer-task.member.v1-2, groupId=task.member.v1] Offset commit failed on partition task-member-0 at offset 8: The coordinator is not aware of this member.
2023-12-01 16:10:56.569 INFO  ---- [er#0-0-C-1] [ConsumerCoordinator:1291] handle   [Consumer clientId=consumer-task.member.v1-2, groupId=task.member.v1] OffsetCommit failed with Generation{generationId=51, memberId='consumer-task.member.v1-2-60a1b485-1bac-4d1a-95b6-c6c8dd4575aa', protocol='range'}: The coordinator is not aware of this member.
2023-12-01 16:10:56.569 INFO  ---- [er#0-0-C-1] [ConsumerCoordinator:972] resetStateAndGeneration   [Consumer clientId=consumer-task.member.v1-2, groupId=task.member.v1] Resetting generation due to: encountered UNKNOWN_MEMBER_ID from OFFSET_COMMIT response
2023-12-01 16:10:56.569 INFO  ---- [er#0-0-C-1] [ConsumerCoordinator:1000] requestRejoin   [Consumer clientId=consumer-task.member.v1-2, groupId=task.member.v1] Request joining group due to: encountered UNKNOWN_MEMBER_ID from OFFSET_COMMIT response
2023-12-01 16:10:56.569 INFO  ---- [er#1-0-C-1] [ConsumerCoordinator:1000] requestRejoin   [Consumer clientId=consumer-task.product.v1-3, groupId=task.product.v1] Request joining group due to: need to re-join with the given member-id
2023-12-01 16:10:56.570 INFO  ---- [er#1-0-C-1] [ConsumerCoordinator:535] sendJoinGroupRequest   [Consumer clientId=consumer-task.product.v1-3, groupId=task.product.v1] (Re-)joining group
2023-12-01 16:10:56.582 ERROR ---- [er#0-0-C-1] [KafkaMessageListenerContainer:149] error   Consumer exception
java.lang.IllegalStateException: This error handler cannot process 'org.apache.kafka.clients.consumer.CommitFailedException's; no record information is available
	at org.springframework.kafka.listener.DefaultErrorHandler.handleOtherException(DefaultErrorHandler.java:157)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.handleConsumerException(KafkaMessageListenerContainer.java:1815)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.run(KafkaMessageListenerContainer.java:1303)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.lang.Thread.run(Thread.java:834)
Caused by: org.apache.kafka.clients.consumer.CommitFailedException: Commit cannot be completed since the group has already rebalanced and assigned the partitions to another member. This means that the time between subsequent calls to poll() was longer than the configured max.poll.interval.ms, which typically implies that the poll loop is spending too much time message processing. You can address this either by increasing max.poll.interval.ms or by reducing the maximum size of batches returned in poll() with max.poll.records.
	at org.apache.kafka.clients.consumer.internals.ConsumerCoordinator$OffsetCommitResponseHandler.handle(ConsumerCoordinator.java:1303)
	at org.apache.kafka.clients.consumer.internals.ConsumerCoordinator$OffsetCommitResponseHandler.handle(ConsumerCoordinator.java:1204)
	at org.apache.kafka.clients.consumer.internals.AbstractCoordinator$CoordinatorResponseHandler.onSuccess(AbstractCoordinator.java:1196)
	at org.apache.kafka.clients.consumer.internals.AbstractCoordinator$CoordinatorResponseHandler.onSuccess(AbstractCoordinator.java:1171)
	at org.apache.kafka.clients.consumer.internals.RequestFuture$1.onSuccess(RequestFuture.java:206)
	at org.apache.kafka.clients.consumer.internals.RequestFuture.fireSuccess(RequestFuture.java:169)
	at org.apache.kafka.clients.consumer.internals.RequestFuture.complete(RequestFuture.java:129)
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient$RequestFutureCompletionHandler.fireCompletion(ConsumerNetworkClient.java:602)
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.firePendingCompletedRequests(ConsumerNetworkClient.java:412)
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:297)
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:236)
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:215)
	at org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.commitOffsetsSync(ConsumerCoordinator.java:1046)
	at org.apache.kafka.clients.consumer.KafkaConsumer.commitSync(KafkaConsumer.java:1492)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doCommitSync(KafkaMessageListenerContainer.java:3065)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.commitSync(KafkaMessageListenerContainer.java:3060)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.commitIfNecessary(KafkaMessageListenerContainer.java:3046)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.processCommits(KafkaMessageListenerContainer.java:2838)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.pollAndInvoke(KafkaMessageListenerContainer.java:1331)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.run(KafkaMessageListenerContainer.java:1257)
	... 3 common frames omitted
2023-12-01 16:10:56.582 INFO  ---- [er#0-0-C-1] [ConsumerCoordinator:724] onJoinPrepare   [Consumer clientId=consumer-task.member.v1-2, groupId=task.member.v1] Giving away all assigned partitions as lost since generation has been reset,indicating that consumer is no longer part of the group
2023-12-01 16:10:56.583 INFO  ---- [er#0-0-C-1] [ConsumerCoordinator:330] invokePartitionsLost   [Consumer clientId=consumer-task.member.v1-2, groupId=task.member.v1] Lost previously assigned partitions task-member-0
2023-12-01 16:10:56.583 INFO  ---- [er#0-0-C-1] [KafkaMessageListenerContainer:292] info   task.member.v1: partitions lost: [task-member-0]
2023-12-01 16:10:56.583 INFO  ---- [er#0-0-C-1] [KafkaMessageListenerContainer:292] info   task.member.v1: partitions revoked: [task-member-0]
2023-12-01 16:10:56.583 INFO  ---- [er#0-0-C-1] [ConsumerCoordinator:535] sendJoinGroupRequest   [Consumer clientId=consumer-task.member.v1-2, groupId=task.member.v1] (Re-)joining group
2023-12-01 16:10:56.587 INFO  ---- [er#0-0-C-1] [ConsumerCoordinator:1000] requestRejoin   [Consumer clientId=consumer-task.member.v1-2, groupId=task.member.v1] Request joining group due to: need to re-join with the given member-id
2023-12-01 16:10:56.588 INFO  ---- [er#0-0-C-1] [ConsumerCoordinator:535] sendJoinGroupRequest   [Consumer clientId=consumer-task.member.v1-2, groupId=task.member.v1] (Re-)joining group
2023-12-01 16:10:56.620 INFO  ---- [r.group.v1] [ConsumerCoordinator:853] onSuccess   [Consumer clientId=consumer-order.group.v1-1, groupId=order.group.v1] Discovered group coordinator 127.0.0.1:9091 (id: 2147483646 rack: null)
2023-12-01 16:10:56.727 INFO  ---- [r.group.v1] [ConsumerCoordinator:853] onSuccess   [Consumer clientId=consumer-order.group.v1-1, groupId=order.group.v1] Discovered group coordinator 127.0.0.1:9091 (id: 2147483646 rack: null)
2023-12-01 16:10:57.267 INFO  ---- [r.group.v1] [ConsumerCoordinator:1153] handle   [Consumer clientId=consumer-order.group.v1-1, groupId=order.group.v1] Attempt to heartbeat with Generation{generationId=8, memberId='consumer-order.group.v1-1-a4e086a4-397e-4156-98db-04079e449101', protocol='range'} and group instance id Optional.empty failed due to UNKNOWN_MEMBER_ID, resetting generation
2023-12-01 16:10:57.267 INFO  ---- [r.group.v1] [ConsumerCoordinator:972] resetStateAndGeneration   [Consumer clientId=consumer-order.group.v1-1, groupId=order.group.v1] Resetting generation due to: encountered UNKNOWN_MEMBER_ID from HEARTBEAT response
2023-12-01 16:10:57.267 INFO  ---- [r.group.v1] [ConsumerCoordinator:1000] requestRejoin   [Consumer clientId=consumer-order.group.v1-1, groupId=order.group.v1] Request joining group due to: encountered UNKNOWN_MEMBER_ID from HEARTBEAT response
2023-12-01 16:10:59.592 INFO  ---- [er#1-0-C-1] [ConsumerCoordinator:595] handle   [Consumer clientId=consumer-task.product.v1-3, groupId=task.product.v1] Successfully joined group with generation Generation{generationId=53, memberId='consumer-task.product.v1-3-d63c9662-150e-43f9-8894-79ee8965a913', protocol='range'}
2023-12-01 16:10:59.594 INFO  ---- [er#1-0-C-1] [ConsumerCoordinator:659] performAssignment   [Consumer clientId=consumer-task.product.v1-3, groupId=task.product.v1] Finished assignment for group at generation 53: {consumer-task.product.v1-3-d63c9662-150e-43f9-8894-79ee8965a913=Assignment(partitions=[task-product-0])}
2023-12-01 16:10:59.601 INFO  ---- [er#0-0-C-1] [ConsumerCoordinator:595] handle   [Consumer clientId=consumer-task.member.v1-2, groupId=task.member.v1] Successfully joined group with generation Generation{generationId=53, memberId='consumer-task.member.v1-2-eecbf7ca-349c-47f9-b5fa-569de295cd4b', protocol='range'}
2023-12-01 16:10:59.602 INFO  ---- [er#0-0-C-1] [ConsumerCoordinator:659] performAssignment   [Consumer clientId=consumer-task.member.v1-2, groupId=task.member.v1] Finished assignment for group at generation 53: {consumer-task.member.v1-2-eecbf7ca-349c-47f9-b5fa-569de295cd4b=Assignment(partitions=[task-member-0])}
2023-12-01 16:10:59.603 INFO  ---- [er#1-0-C-1] [ConsumerCoordinator:761] handle   [Consumer clientId=consumer-task.product.v1-3, groupId=task.product.v1] Successfully synced group in generation Generation{generationId=53, memberId='consumer-task.product.v1-3-d63c9662-150e-43f9-8894-79ee8965a913', protocol='range'}
2023-12-01 16:10:59.604 INFO  ---- [er#1-0-C-1] [ConsumerCoordinator:280] invokeOnAssignment   [Consumer clientId=consumer-task.product.v1-3, groupId=task.product.v1] Notifying assignor about the new Assignment(partitions=[task-product-0])
2023-12-01 16:10:59.604 INFO  ---- [er#1-0-C-1] [ConsumerCoordinator:292] invokePartitionsAssigned   [Consumer clientId=consumer-task.product.v1-3, groupId=task.product.v1] Adding newly assigned partitions: task-product-0
2023-12-01 16:10:59.610 INFO  ---- [er#0-0-C-1] [ConsumerCoordinator:761] handle   [Consumer clientId=consumer-task.member.v1-2, groupId=task.member.v1] Successfully synced group in generation Generation{generationId=53, memberId='consumer-task.member.v1-2-eecbf7ca-349c-47f9-b5fa-569de295cd4b', protocol='range'}
2023-12-01 16:10:59.611 INFO  ---- [er#0-0-C-1] [ConsumerCoordinator:280] invokeOnAssignment   [Consumer clientId=consumer-task.member.v1-2, groupId=task.member.v1] Notifying assignor about the new Assignment(partitions=[task-member-0])
2023-12-01 16:10:59.612 INFO  ---- [er#0-0-C-1] [ConsumerCoordinator:292] invokePartitionsAssigned   [Consumer clientId=consumer-task.member.v1-2, groupId=task.member.v1] Adding newly assigned partitions: task-member-0
2023-12-01 16:10:59.615 INFO  ---- [er#1-0-C-1] [ConsumerCoordinator:851] refreshCommittedOffsetsIfNeeded   [Consumer clientId=consumer-task.product.v1-3, groupId=task.product.v1] Setting offset for partition task-product-0 to the committed offset FetchPosition{offset=1, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[127.0.0.1:9091 (id: 1 rack: null)], epoch=9}}
2023-12-01 16:10:59.616 INFO  ---- [er#1-0-C-1] [KafkaMessageListenerContainer:292] info   task.product.v1: partitions assigned: [task-product-0]
2023-12-01 16:10:59.622 INFO  ---- [er#0-0-C-1] [ConsumerCoordinator:851] refreshCommittedOffsetsIfNeeded   [Consumer clientId=consumer-task.member.v1-2, groupId=task.member.v1] Setting offset for partition task-member-0 to the committed offset FetchPosition{offset=7, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[127.0.0.1:9091 (id: 1 rack: null)], epoch=9}}
2023-12-01 16:10:59.623 INFO  ---- [er#0-0-C-1] [KafkaMessageListenerContainer:292] info   task.member.v1: partitions assigned: [task-member-0]
2023-12-01 16:13:50.416 INFO  ---- [tartedMain] [TaskConsumerApplication:55] logStarting   Starting TaskConsumerApplication using Java 11.0.13 on DESKTOP-MNMB87E with PID 30588 (C:\Users\tkdrb\IdeaProjects\ecommerce\task-consumer\build\classes\java\main started by tkdrb in C:\Users\tkdrb\IdeaProjects\ecommerce\task-consumer)
2023-12-01 16:13:50.417 INFO  ---- [tartedMain] [TaskConsumerApplication:631] logStartupProfileInfo   No active profile set, falling back to 1 default profile: "default"
2023-12-01 16:13:50.460 INFO  ---- [tartedMain] [DevToolsPropertyDefaultsPostProcessor:255] logTo   Devtools property defaults active! Set 'spring.devtools.add-properties' to 'false' to disable
2023-12-01 16:13:50.461 INFO  ---- [tartedMain] [DevToolsPropertyDefaultsPostProcessor:255] logTo   For additional web related logging consider setting the 'logging.level.web' property to 'DEBUG'
2023-12-01 16:13:51.307 INFO  ---- [tartedMain] [GenericScope:283] setSerializationId   BeanFactory id=7d336d03-7948-373b-80b2-3edd326128fe
2023-12-01 16:13:52.357 INFO  ---- [tartedMain] [TomcatWebServer:108] initialize   Tomcat initialized with port(s): 0 (http)
2023-12-01 16:13:52.368 INFO  ---- [tartedMain] [StandardService:173] log   Starting service [Tomcat]
2023-12-01 16:13:52.369 INFO  ---- [tartedMain] [StandardEngine:173] log   Starting Servlet engine: [Apache Tomcat/9.0.76]
2023-12-01 16:13:52.571 INFO  ---- [tartedMain] [[/]:173] log   Initializing Spring embedded WebApplicationContext
2023-12-01 16:13:52.572 INFO  ---- [tartedMain] [ServletWebServerApplicationContext:292] prepareWebApplicationContext   Root WebApplicationContext: initialization completed in 2111 ms
2023-12-01 16:13:53.092 INFO  ---- [tartedMain] [OptionalLiveReloadServer:59] startServer   LiveReload server is running on port 35729
2023-12-01 16:13:53.793 INFO  ---- [tartedMain] [DiscoveryClientOptionalArgsConfiguration:71] restTemplateDiscoveryClientOptionalArgs   Eureka HTTP Client uses RestTemplate.
2023-12-01 16:13:54.485 WARN  ---- [tartedMain] [LoadBalancerCacheAutoConfiguration$LoadBalancerCaffeineWarnLogger:83] logWarning   Spring Cloud LoadBalancer is currently working with the default cache. While this cache implementation is useful for development and tests, it's recommended to use Caffeine cache in production.You can switch to using Caffeine cache, by adding it and org.springframework.cache.caffeine.CaffeineCacheManager to the classpath.
2023-12-01 16:13:54.590 INFO  ---- [tartedMain] [ConsumerConfig:376] logAll   ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-order.group.v1-1
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = order.group.v1
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2023-12-01 16:13:54.691 INFO  ---- [tartedMain] [AppInfoParser:119] <init>   Kafka version: 3.1.2
2023-12-01 16:13:54.692 INFO  ---- [tartedMain] [AppInfoParser:120] <init>   Kafka commitId: f8c67dc3ae0a3265
2023-12-01 16:13:54.693 INFO  ---- [tartedMain] [AppInfoParser:121] <init>   Kafka startTimeMs: 1701414834689
2023-12-01 16:13:54.696 INFO  ---- [tartedMain] [KafkaConsumer:966] subscribe   [Consumer clientId=consumer-order.group.v1-1, groupId=order.group.v1] Subscribed to topic(s): order
2023-12-01 16:13:54.707 INFO  ---- [tartedMain] [ConsumerConfig:376] logAll   ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-task.product.v1-2
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = task.product.v1
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2023-12-01 16:13:54.715 INFO  ---- [tartedMain] [AppInfoParser:119] <init>   Kafka version: 3.1.2
2023-12-01 16:13:54.715 INFO  ---- [tartedMain] [AppInfoParser:120] <init>   Kafka commitId: f8c67dc3ae0a3265
2023-12-01 16:13:54.715 INFO  ---- [tartedMain] [AppInfoParser:121] <init>   Kafka startTimeMs: 1701414834715
2023-12-01 16:13:54.716 INFO  ---- [tartedMain] [KafkaConsumer:966] subscribe   [Consumer clientId=consumer-task.product.v1-2, groupId=task.product.v1] Subscribed to topic(s): task-product
2023-12-01 16:13:54.718 INFO  ---- [tartedMain] [ConsumerConfig:376] logAll   ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-task.member.v1-3
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = task.member.v1
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2023-12-01 16:13:54.723 INFO  ---- [tartedMain] [AppInfoParser:119] <init>   Kafka version: 3.1.2
2023-12-01 16:13:54.723 INFO  ---- [tartedMain] [AppInfoParser:120] <init>   Kafka commitId: f8c67dc3ae0a3265
2023-12-01 16:13:54.723 INFO  ---- [tartedMain] [AppInfoParser:121] <init>   Kafka startTimeMs: 1701414834723
2023-12-01 16:13:54.724 INFO  ---- [tartedMain] [KafkaConsumer:966] subscribe   [Consumer clientId=consumer-task.member.v1-3, groupId=task.member.v1] Subscribed to topic(s): task-member
2023-12-01 16:13:54.737 INFO  ---- [tartedMain] [TomcatWebServer:220] start   Tomcat started on port(s): 60102 (http) with context path ''
2023-12-01 16:13:54.738 INFO  ---- [tartedMain] [EurekaAutoServiceRegistration:144] onApplicationEvent   Updating port to 60102
2023-12-01 16:13:54.743 INFO  ---- [tartedMain] [InstanceInfoFactory:67] create   Setting initial instance status as: STARTING
2023-12-01 16:13:54.783 INFO  ---- [tartedMain] [DiscoveryClient:372] <init>   Initializing Eureka in region us-east-1
2023-12-01 16:13:54.788 INFO  ---- [tartedMain] [ConfigClusterResolver:43] getClusterEndpoints   Resolving eureka endpoints via configuration
2023-12-01 16:13:54.815 INFO  ---- [tartedMain] [DiscoveryClient:1007] fetchRegistry   Disable delta property : false
2023-12-01 16:13:54.816 INFO  ---- [tartedMain] [DiscoveryClient:1008] fetchRegistry   Single vip registry refresh property : null
2023-12-01 16:13:54.816 INFO  ---- [tartedMain] [DiscoveryClient:1009] fetchRegistry   Force full registry fetch : false
2023-12-01 16:13:54.816 INFO  ---- [tartedMain] [DiscoveryClient:1010] fetchRegistry   Application is null : false
2023-12-01 16:13:54.816 INFO  ---- [tartedMain] [DiscoveryClient:1011] fetchRegistry   Registered Applications size is zero : true
2023-12-01 16:13:54.816 INFO  ---- [tartedMain] [DiscoveryClient:1013] fetchRegistry   Application version is -1: true
2023-12-01 16:13:54.816 INFO  ---- [tartedMain] [DiscoveryClient:1097] getAndStoreFullRegistry   Getting all instance registry info from the eureka server
2023-12-01 16:13:55.078 INFO  ---- [er#2-0-C-1] [Metadata:402] updateLatestMetadata   [Consumer clientId=consumer-order.group.v1-1, groupId=order.group.v1] Resetting the last seen epoch of partition order-0 to 0 since the associated topicId changed from null to 8AIo0qkzSIiGJbn1bQxAkw
2023-12-01 16:13:55.078 INFO  ---- [er#1-0-C-1] [Metadata:402] updateLatestMetadata   [Consumer clientId=consumer-task.member.v1-3, groupId=task.member.v1] Resetting the last seen epoch of partition task-member-0 to 9 since the associated topicId changed from null to HvfbkcRhQ3meTIJFgCt9zw
2023-12-01 16:13:55.079 INFO  ---- [er#0-0-C-1] [Metadata:402] updateLatestMetadata   [Consumer clientId=consumer-task.product.v1-2, groupId=task.product.v1] Resetting the last seen epoch of partition task-product-0 to 9 since the associated topicId changed from null to h57hDuqlT3KmUT32pFF5uQ
2023-12-01 16:13:55.084 INFO  ---- [er#0-0-C-1] [Metadata:287] update   [Consumer clientId=consumer-task.product.v1-2, groupId=task.product.v1] Cluster ID: 5_U1uds-SGaR4vItj-jqUw
2023-12-01 16:13:55.084 INFO  ---- [er#1-0-C-1] [Metadata:287] update   [Consumer clientId=consumer-task.member.v1-3, groupId=task.member.v1] Cluster ID: 5_U1uds-SGaR4vItj-jqUw
2023-12-01 16:13:55.084 INFO  ---- [er#2-0-C-1] [Metadata:287] update   [Consumer clientId=consumer-order.group.v1-1, groupId=order.group.v1] Cluster ID: 5_U1uds-SGaR4vItj-jqUw
2023-12-01 16:13:55.086 INFO  ---- [er#1-0-C-1] [ConsumerCoordinator:853] onSuccess   [Consumer clientId=consumer-task.member.v1-3, groupId=task.member.v1] Discovered group coordinator 127.0.0.1:9093 (id: 2147483644 rack: null)
2023-12-01 16:13:55.086 INFO  ---- [er#2-0-C-1] [ConsumerCoordinator:853] onSuccess   [Consumer clientId=consumer-order.group.v1-1, groupId=order.group.v1] Discovered group coordinator 127.0.0.1:9091 (id: 2147483646 rack: null)
2023-12-01 16:13:55.086 INFO  ---- [er#0-0-C-1] [ConsumerCoordinator:853] onSuccess   [Consumer clientId=consumer-task.product.v1-2, groupId=task.product.v1] Discovered group coordinator 127.0.0.1:9091 (id: 2147483646 rack: null)
2023-12-01 16:13:55.092 INFO  ---- [er#0-0-C-1] [ConsumerCoordinator:535] sendJoinGroupRequest   [Consumer clientId=consumer-task.product.v1-2, groupId=task.product.v1] (Re-)joining group
2023-12-01 16:13:55.092 INFO  ---- [er#2-0-C-1] [ConsumerCoordinator:535] sendJoinGroupRequest   [Consumer clientId=consumer-order.group.v1-1, groupId=order.group.v1] (Re-)joining group
2023-12-01 16:13:55.092 INFO  ---- [er#1-0-C-1] [ConsumerCoordinator:535] sendJoinGroupRequest   [Consumer clientId=consumer-task.member.v1-3, groupId=task.member.v1] (Re-)joining group
2023-12-01 16:13:55.110 INFO  ---- [tartedMain] [DiscoveryClient:1106] getAndStoreFullRegistry   The response status is 200
2023-12-01 16:13:55.114 INFO  ---- [er#0-0-C-1] [ConsumerCoordinator:1000] requestRejoin   [Consumer clientId=consumer-task.product.v1-2, groupId=task.product.v1] Request joining group due to: need to re-join with the given member-id
2023-12-01 16:13:55.114 INFO  ---- [er#2-0-C-1] [ConsumerCoordinator:1000] requestRejoin   [Consumer clientId=consumer-order.group.v1-1, groupId=order.group.v1] Request joining group due to: need to re-join with the given member-id
2023-12-01 16:13:55.114 INFO  ---- [tartedMain] [DiscoveryClient:1321] initScheduledTasks   Starting heartbeat executor: renew interval is: 30
2023-12-01 16:13:55.114 INFO  ---- [er#1-0-C-1] [ConsumerCoordinator:1000] requestRejoin   [Consumer clientId=consumer-task.member.v1-3, groupId=task.member.v1] Request joining group due to: need to re-join with the given member-id
2023-12-01 16:13:55.115 INFO  ---- [er#0-0-C-1] [ConsumerCoordinator:535] sendJoinGroupRequest   [Consumer clientId=consumer-task.product.v1-2, groupId=task.product.v1] (Re-)joining group
2023-12-01 16:13:55.115 INFO  ---- [er#2-0-C-1] [ConsumerCoordinator:535] sendJoinGroupRequest   [Consumer clientId=consumer-order.group.v1-1, groupId=order.group.v1] (Re-)joining group
2023-12-01 16:13:55.115 INFO  ---- [er#1-0-C-1] [ConsumerCoordinator:535] sendJoinGroupRequest   [Consumer clientId=consumer-task.member.v1-3, groupId=task.member.v1] (Re-)joining group
2023-12-01 16:13:55.118 INFO  ---- [tartedMain] [InstanceInfoReplicator:60] <init>   InstanceInfoReplicator onDemand update allowed rate per min is 4
2023-12-01 16:13:55.122 INFO  ---- [tartedMain] [DiscoveryClient:492] <init>   Discovery Client initialized at timestamp 1701414835121 with initial instances count: 5
2023-12-01 16:13:55.124 INFO  ---- [tartedMain] [EurekaServiceRegistry:41] register   Registering application TASK-SERVICE with eureka with status UP
2023-12-01 16:13:55.124 INFO  ---- [tartedMain] [DiscoveryClient:1352] notify   Saw local status change event StatusChangeEvent [timestamp=1701414835124, current=UP, previous=STARTING]
2023-12-01 16:13:55.126 INFO  ---- [plicator-0] [DiscoveryClient:873] register   DiscoveryClient_TASK-SERVICE/192.168.0.17:27b5e5b507fc0b274a0081a5d47bd40b: registering service...
2023-12-01 16:13:55.163 INFO  ---- [plicator-0] [DiscoveryClient:882] register   DiscoveryClient_TASK-SERVICE/192.168.0.17:27b5e5b507fc0b274a0081a5d47bd40b - registration status: 204
2023-12-01 16:13:55.896 INFO  ---- [tartedMain] [TaskConsumerApplication:61] logStarted   Started TaskConsumerApplication in 7.355 seconds (JVM running for 8.063)
2023-12-01 16:13:58.122 INFO  ---- [er#2-0-C-1] [ConsumerCoordinator:595] handle   [Consumer clientId=consumer-order.group.v1-1, groupId=order.group.v1] Successfully joined group with generation Generation{generationId=10, memberId='consumer-order.group.v1-1-97065130-27de-4b52-90e9-8ec165c830b5', protocol='range'}
2023-12-01 16:13:58.125 INFO  ---- [er#2-0-C-1] [ConsumerCoordinator:659] performAssignment   [Consumer clientId=consumer-order.group.v1-1, groupId=order.group.v1] Finished assignment for group at generation 10: {consumer-order.group.v1-1-97065130-27de-4b52-90e9-8ec165c830b5=Assignment(partitions=[order-0])}
2023-12-01 16:13:58.139 INFO  ---- [er#2-0-C-1] [ConsumerCoordinator:761] handle   [Consumer clientId=consumer-order.group.v1-1, groupId=order.group.v1] Successfully synced group in generation Generation{generationId=10, memberId='consumer-order.group.v1-1-97065130-27de-4b52-90e9-8ec165c830b5', protocol='range'}
2023-12-01 16:13:58.139 INFO  ---- [er#2-0-C-1] [ConsumerCoordinator:280] invokeOnAssignment   [Consumer clientId=consumer-order.group.v1-1, groupId=order.group.v1] Notifying assignor about the new Assignment(partitions=[order-0])
2023-12-01 16:13:58.142 INFO  ---- [er#2-0-C-1] [ConsumerCoordinator:292] invokePartitionsAssigned   [Consumer clientId=consumer-order.group.v1-1, groupId=order.group.v1] Adding newly assigned partitions: order-0
2023-12-01 16:13:58.154 INFO  ---- [er#2-0-C-1] [ConsumerCoordinator:851] refreshCommittedOffsetsIfNeeded   [Consumer clientId=consumer-order.group.v1-1, groupId=order.group.v1] Setting offset for partition order-0 to the committed offset FetchPosition{offset=6, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[127.0.0.1:9092 (id: 2 rack: null)], epoch=0}}
2023-12-01 16:13:58.155 INFO  ---- [er#2-0-C-1] [KafkaMessageListenerContainer:292] info   order.group.v1: partitions assigned: [order-0]
2023-12-01 16:13:58.216 INFO  ---- [er#2-0-C-1] [ProducerConfig:376] logAll   ProducerConfig values: 
	acks = -1
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-1
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2023-12-01 16:13:58.222 INFO  ---- [er#2-0-C-1] [KafkaProducer:572] configureTransactionState   [Producer clientId=producer-1] Instantiated an idempotent producer.
2023-12-01 16:13:58.231 INFO  ---- [er#2-0-C-1] [AppInfoParser:119] <init>   Kafka version: 3.1.2
2023-12-01 16:13:58.231 INFO  ---- [er#2-0-C-1] [AppInfoParser:120] <init>   Kafka commitId: f8c67dc3ae0a3265
2023-12-01 16:13:58.231 INFO  ---- [er#2-0-C-1] [AppInfoParser:121] <init>   Kafka startTimeMs: 1701414838231
2023-12-01 16:13:58.241 INFO  ---- [producer-1] [Metadata:402] updateLatestMetadata   [Producer clientId=producer-1] Resetting the last seen epoch of partition member-check-0 to 4 since the associated topicId changed from null to KYr4s4QASse48T8_YcW_QA
2023-12-01 16:13:58.242 INFO  ---- [producer-1] [Metadata:287] update   [Producer clientId=producer-1] Cluster ID: 5_U1uds-SGaR4vItj-jqUw
2023-12-01 16:13:58.242 INFO  ---- [producer-1] [TransactionManager:554] setProducerIdAndEpoch   [Producer clientId=producer-1] ProducerId set to 4010 with epoch 0
2023-12-01 16:14:08.825 INFO  ---- [er#0-0-C-1] [ConsumerCoordinator:595] handle   [Consumer clientId=consumer-task.product.v1-2, groupId=task.product.v1] Successfully joined group with generation Generation{generationId=54, memberId='consumer-task.product.v1-2-de69fccd-9e81-4163-8961-5b058a0cd8ba', protocol='range'}
2023-12-01 16:14:08.825 INFO  ---- [er#1-0-C-1] [ConsumerCoordinator:595] handle   [Consumer clientId=consumer-task.member.v1-3, groupId=task.member.v1] Successfully joined group with generation Generation{generationId=54, memberId='consumer-task.member.v1-3-b0806876-4def-4852-bc67-372404ddaeb8', protocol='range'}
2023-12-01 16:14:08.826 INFO  ---- [er#1-0-C-1] [ConsumerCoordinator:659] performAssignment   [Consumer clientId=consumer-task.member.v1-3, groupId=task.member.v1] Finished assignment for group at generation 54: {consumer-task.member.v1-3-b0806876-4def-4852-bc67-372404ddaeb8=Assignment(partitions=[task-member-0])}
2023-12-01 16:14:08.826 INFO  ---- [er#0-0-C-1] [ConsumerCoordinator:659] performAssignment   [Consumer clientId=consumer-task.product.v1-2, groupId=task.product.v1] Finished assignment for group at generation 54: {consumer-task.product.v1-2-de69fccd-9e81-4163-8961-5b058a0cd8ba=Assignment(partitions=[task-product-0])}
2023-12-01 16:14:08.831 INFO  ---- [er#1-0-C-1] [ConsumerCoordinator:761] handle   [Consumer clientId=consumer-task.member.v1-3, groupId=task.member.v1] Successfully synced group in generation Generation{generationId=54, memberId='consumer-task.member.v1-3-b0806876-4def-4852-bc67-372404ddaeb8', protocol='range'}
2023-12-01 16:14:08.831 INFO  ---- [er#0-0-C-1] [ConsumerCoordinator:761] handle   [Consumer clientId=consumer-task.product.v1-2, groupId=task.product.v1] Successfully synced group in generation Generation{generationId=54, memberId='consumer-task.product.v1-2-de69fccd-9e81-4163-8961-5b058a0cd8ba', protocol='range'}
2023-12-01 16:14:08.832 INFO  ---- [er#1-0-C-1] [ConsumerCoordinator:280] invokeOnAssignment   [Consumer clientId=consumer-task.member.v1-3, groupId=task.member.v1] Notifying assignor about the new Assignment(partitions=[task-member-0])
2023-12-01 16:14:08.832 INFO  ---- [er#0-0-C-1] [ConsumerCoordinator:280] invokeOnAssignment   [Consumer clientId=consumer-task.product.v1-2, groupId=task.product.v1] Notifying assignor about the new Assignment(partitions=[task-product-0])
2023-12-01 16:14:08.832 INFO  ---- [er#1-0-C-1] [ConsumerCoordinator:292] invokePartitionsAssigned   [Consumer clientId=consumer-task.member.v1-3, groupId=task.member.v1] Adding newly assigned partitions: task-member-0
2023-12-01 16:14:08.832 INFO  ---- [er#0-0-C-1] [ConsumerCoordinator:292] invokePartitionsAssigned   [Consumer clientId=consumer-task.product.v1-2, groupId=task.product.v1] Adding newly assigned partitions: task-product-0
2023-12-01 16:14:08.836 INFO  ---- [er#0-0-C-1] [ConsumerCoordinator:851] refreshCommittedOffsetsIfNeeded   [Consumer clientId=consumer-task.product.v1-2, groupId=task.product.v1] Setting offset for partition task-product-0 to the committed offset FetchPosition{offset=1, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[127.0.0.1:9091 (id: 1 rack: null)], epoch=9}}
2023-12-01 16:14:08.836 INFO  ---- [er#1-0-C-1] [ConsumerCoordinator:851] refreshCommittedOffsetsIfNeeded   [Consumer clientId=consumer-task.member.v1-3, groupId=task.member.v1] Setting offset for partition task-member-0 to the committed offset FetchPosition{offset=8, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[127.0.0.1:9091 (id: 1 rack: null)], epoch=9}}
2023-12-01 16:14:08.837 INFO  ---- [er#0-0-C-1] [KafkaMessageListenerContainer:292] info   task.product.v1: partitions assigned: [task-product-0]
2023-12-01 16:14:08.837 INFO  ---- [er#1-0-C-1] [KafkaMessageListenerContainer:292] info   task.member.v1: partitions assigned: [task-member-0]
2023-12-01 16:14:08.851 INFO  ---- [producer-1] [Metadata:402] updateLatestMetadata   [Producer clientId=producer-1] Resetting the last seen epoch of partition product-check-0 to 2 since the associated topicId changed from null to NcmASD39SLaSfi1cR4a0aw
2023-12-01 16:18:54.830 INFO  ---- [executor-0] [ConfigClusterResolver:43] getClusterEndpoints   Resolving eureka endpoints via configuration
2023-12-01 16:18:58.257 WARN  ---- [r.group.v1] [ConsumerCoordinator:1408] run   [Consumer clientId=consumer-order.group.v1-1, groupId=order.group.v1] consumer poll timeout has expired. This means the time between subsequent calls to poll() was longer than the configured max.poll.interval.ms, which typically implies that the poll loop is spending too much time processing messages. You can address this either by increasing max.poll.interval.ms or by reducing the maximum size of batches returned in poll() with max.poll.records.
2023-12-01 16:18:58.258 INFO  ---- [r.group.v1] [ConsumerCoordinator:1060] maybeLeaveGroup   [Consumer clientId=consumer-order.group.v1-1, groupId=order.group.v1] Member consumer-order.group.v1-1-97065130-27de-4b52-90e9-8ec165c830b5 sending LeaveGroup request to coordinator 127.0.0.1:9091 (id: 2147483646 rack: null) due to consumer poll timeout has expired.
2023-12-01 16:18:58.261 INFO  ---- [r.group.v1] [ConsumerCoordinator:972] resetStateAndGeneration   [Consumer clientId=consumer-order.group.v1-1, groupId=order.group.v1] Resetting generation due to: consumer pro-actively leaving the group
2023-12-01 16:18:58.261 INFO  ---- [r.group.v1] [ConsumerCoordinator:1000] requestRejoin   [Consumer clientId=consumer-order.group.v1-1, groupId=order.group.v1] Request joining group due to: consumer pro-actively leaving the group
2023-12-01 16:23:15.642 INFO  ---- [tartedMain] [TaskConsumerApplication:55] logStarting   Starting TaskConsumerApplication using Java 11.0.13 on DESKTOP-MNMB87E with PID 20804 (C:\Users\tkdrb\IdeaProjects\ecommerce\task-consumer\build\classes\java\main started by tkdrb in C:\Users\tkdrb\IdeaProjects\ecommerce\task-consumer)
2023-12-01 16:23:15.645 INFO  ---- [tartedMain] [TaskConsumerApplication:631] logStartupProfileInfo   No active profile set, falling back to 1 default profile: "default"
2023-12-01 16:23:15.707 INFO  ---- [tartedMain] [DevToolsPropertyDefaultsPostProcessor:255] logTo   Devtools property defaults active! Set 'spring.devtools.add-properties' to 'false' to disable
2023-12-01 16:23:15.709 INFO  ---- [tartedMain] [DevToolsPropertyDefaultsPostProcessor:255] logTo   For additional web related logging consider setting the 'logging.level.web' property to 'DEBUG'
2023-12-01 16:23:17.194 INFO  ---- [tartedMain] [GenericScope:283] setSerializationId   BeanFactory id=7d336d03-7948-373b-80b2-3edd326128fe
2023-12-01 16:23:18.544 INFO  ---- [tartedMain] [TomcatWebServer:108] initialize   Tomcat initialized with port(s): 0 (http)
2023-12-01 16:23:18.555 INFO  ---- [tartedMain] [StandardService:173] log   Starting service [Tomcat]
2023-12-01 16:23:18.556 INFO  ---- [tartedMain] [StandardEngine:173] log   Starting Servlet engine: [Apache Tomcat/9.0.76]
2023-12-01 16:23:18.766 INFO  ---- [tartedMain] [[/]:173] log   Initializing Spring embedded WebApplicationContext
2023-12-01 16:23:18.766 INFO  ---- [tartedMain] [ServletWebServerApplicationContext:292] prepareWebApplicationContext   Root WebApplicationContext: initialization completed in 3054 ms
2023-12-01 16:23:19.374 WARN  ---- [tartedMain] [OptionalLiveReloadServer:62] startServer   Unable to start LiveReload server
2023-12-01 16:23:20.208 INFO  ---- [tartedMain] [DiscoveryClientOptionalArgsConfiguration:71] restTemplateDiscoveryClientOptionalArgs   Eureka HTTP Client uses RestTemplate.
2023-12-01 16:23:21.860 WARN  ---- [tartedMain] [LoadBalancerCacheAutoConfiguration$LoadBalancerCaffeineWarnLogger:83] logWarning   Spring Cloud LoadBalancer is currently working with the default cache. While this cache implementation is useful for development and tests, it's recommended to use Caffeine cache in production.You can switch to using Caffeine cache, by adding it and org.springframework.cache.caffeine.CaffeineCacheManager to the classpath.
2023-12-01 16:23:21.994 INFO  ---- [tartedMain] [ConsumerConfig:376] logAll   ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-order.group.v1-1
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = order.group.v1
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2023-12-01 16:23:22.285 INFO  ---- [tartedMain] [AppInfoParser:119] <init>   Kafka version: 3.1.2
2023-12-01 16:23:22.290 INFO  ---- [tartedMain] [AppInfoParser:120] <init>   Kafka commitId: f8c67dc3ae0a3265
2023-12-01 16:23:22.293 INFO  ---- [tartedMain] [AppInfoParser:121] <init>   Kafka startTimeMs: 1701415402281
2023-12-01 16:23:22.301 INFO  ---- [tartedMain] [KafkaConsumer:966] subscribe   [Consumer clientId=consumer-order.group.v1-1, groupId=order.group.v1] Subscribed to topic(s): order
2023-12-01 16:23:22.340 INFO  ---- [tartedMain] [ConsumerConfig:376] logAll   ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-task.product.v1-2
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = task.product.v1
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2023-12-01 16:23:22.355 INFO  ---- [tartedMain] [AppInfoParser:119] <init>   Kafka version: 3.1.2
2023-12-01 16:23:22.357 INFO  ---- [tartedMain] [AppInfoParser:120] <init>   Kafka commitId: f8c67dc3ae0a3265
2023-12-01 16:23:22.358 INFO  ---- [tartedMain] [AppInfoParser:121] <init>   Kafka startTimeMs: 1701415402355
2023-12-01 16:23:22.359 INFO  ---- [tartedMain] [KafkaConsumer:966] subscribe   [Consumer clientId=consumer-task.product.v1-2, groupId=task.product.v1] Subscribed to topic(s): task-product
2023-12-01 16:23:22.391 INFO  ---- [tartedMain] [ConsumerConfig:376] logAll   ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-task.member.v1-3
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = task.member.v1
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2023-12-01 16:23:22.406 INFO  ---- [tartedMain] [AppInfoParser:119] <init>   Kafka version: 3.1.2
2023-12-01 16:23:22.407 INFO  ---- [tartedMain] [AppInfoParser:120] <init>   Kafka commitId: f8c67dc3ae0a3265
2023-12-01 16:23:22.407 INFO  ---- [tartedMain] [AppInfoParser:121] <init>   Kafka startTimeMs: 1701415402406
2023-12-01 16:23:22.407 INFO  ---- [tartedMain] [KafkaConsumer:966] subscribe   [Consumer clientId=consumer-task.member.v1-3, groupId=task.member.v1] Subscribed to topic(s): task-member
2023-12-01 16:23:22.429 INFO  ---- [tartedMain] [TomcatWebServer:220] start   Tomcat started on port(s): 60478 (http) with context path ''
2023-12-01 16:23:22.431 INFO  ---- [tartedMain] [EurekaAutoServiceRegistration:144] onApplicationEvent   Updating port to 60478
2023-12-01 16:23:22.438 INFO  ---- [tartedMain] [InstanceInfoFactory:67] create   Setting initial instance status as: STARTING
2023-12-01 16:23:22.515 INFO  ---- [tartedMain] [DiscoveryClient:372] <init>   Initializing Eureka in region us-east-1
2023-12-01 16:23:22.523 INFO  ---- [tartedMain] [ConfigClusterResolver:43] getClusterEndpoints   Resolving eureka endpoints via configuration
2023-12-01 16:23:22.552 INFO  ---- [tartedMain] [DiscoveryClient:1007] fetchRegistry   Disable delta property : false
2023-12-01 16:23:22.552 INFO  ---- [tartedMain] [DiscoveryClient:1008] fetchRegistry   Single vip registry refresh property : null
2023-12-01 16:23:22.553 INFO  ---- [tartedMain] [DiscoveryClient:1009] fetchRegistry   Force full registry fetch : false
2023-12-01 16:23:22.553 INFO  ---- [tartedMain] [DiscoveryClient:1010] fetchRegistry   Application is null : false
2023-12-01 16:23:22.553 INFO  ---- [tartedMain] [DiscoveryClient:1011] fetchRegistry   Registered Applications size is zero : true
2023-12-01 16:23:22.553 INFO  ---- [tartedMain] [DiscoveryClient:1013] fetchRegistry   Application version is -1: true
2023-12-01 16:23:22.553 INFO  ---- [tartedMain] [DiscoveryClient:1097] getAndStoreFullRegistry   Getting all instance registry info from the eureka server
2023-12-01 16:23:22.908 INFO  ---- [er#1-0-C-1] [Metadata:402] updateLatestMetadata   [Consumer clientId=consumer-task.member.v1-3, groupId=task.member.v1] Resetting the last seen epoch of partition task-member-0 to 9 since the associated topicId changed from null to HvfbkcRhQ3meTIJFgCt9zw
2023-12-01 16:23:22.908 INFO  ---- [er#0-0-C-1] [Metadata:402] updateLatestMetadata   [Consumer clientId=consumer-task.product.v1-2, groupId=task.product.v1] Resetting the last seen epoch of partition task-product-0 to 9 since the associated topicId changed from null to h57hDuqlT3KmUT32pFF5uQ
2023-12-01 16:23:22.908 INFO  ---- [er#2-0-C-1] [Metadata:402] updateLatestMetadata   [Consumer clientId=consumer-order.group.v1-1, groupId=order.group.v1] Resetting the last seen epoch of partition order-0 to 0 since the associated topicId changed from null to 8AIo0qkzSIiGJbn1bQxAkw
2023-12-01 16:23:22.913 INFO  ---- [er#0-0-C-1] [Metadata:287] update   [Consumer clientId=consumer-task.product.v1-2, groupId=task.product.v1] Cluster ID: 5_U1uds-SGaR4vItj-jqUw
2023-12-01 16:23:22.913 INFO  ---- [er#1-0-C-1] [Metadata:287] update   [Consumer clientId=consumer-task.member.v1-3, groupId=task.member.v1] Cluster ID: 5_U1uds-SGaR4vItj-jqUw
2023-12-01 16:23:22.913 INFO  ---- [er#2-0-C-1] [Metadata:287] update   [Consumer clientId=consumer-order.group.v1-1, groupId=order.group.v1] Cluster ID: 5_U1uds-SGaR4vItj-jqUw
2023-12-01 16:23:22.915 INFO  ---- [er#2-0-C-1] [ConsumerCoordinator:853] onSuccess   [Consumer clientId=consumer-order.group.v1-1, groupId=order.group.v1] Discovered group coordinator 127.0.0.1:9091 (id: 2147483646 rack: null)
2023-12-01 16:23:22.915 INFO  ---- [er#1-0-C-1] [ConsumerCoordinator:853] onSuccess   [Consumer clientId=consumer-task.member.v1-3, groupId=task.member.v1] Discovered group coordinator 127.0.0.1:9093 (id: 2147483644 rack: null)
2023-12-01 16:23:22.915 INFO  ---- [er#0-0-C-1] [ConsumerCoordinator:853] onSuccess   [Consumer clientId=consumer-task.product.v1-2, groupId=task.product.v1] Discovered group coordinator 127.0.0.1:9091 (id: 2147483646 rack: null)
2023-12-01 16:23:22.918 INFO  ---- [er#1-0-C-1] [ConsumerCoordinator:535] sendJoinGroupRequest   [Consumer clientId=consumer-task.member.v1-3, groupId=task.member.v1] (Re-)joining group
2023-12-01 16:23:22.918 INFO  ---- [er#0-0-C-1] [ConsumerCoordinator:535] sendJoinGroupRequest   [Consumer clientId=consumer-task.product.v1-2, groupId=task.product.v1] (Re-)joining group
2023-12-01 16:23:22.918 INFO  ---- [er#2-0-C-1] [ConsumerCoordinator:535] sendJoinGroupRequest   [Consumer clientId=consumer-order.group.v1-1, groupId=order.group.v1] (Re-)joining group
2023-12-01 16:23:22.953 INFO  ---- [tartedMain] [DiscoveryClient:1106] getAndStoreFullRegistry   The response status is 200
2023-12-01 16:23:22.959 INFO  ---- [tartedMain] [DiscoveryClient:1321] initScheduledTasks   Starting heartbeat executor: renew interval is: 30
2023-12-01 16:23:22.967 INFO  ---- [tartedMain] [InstanceInfoReplicator:60] <init>   InstanceInfoReplicator onDemand update allowed rate per min is 4
2023-12-01 16:23:22.967 INFO  ---- [er#1-0-C-1] [ConsumerCoordinator:1000] requestRejoin   [Consumer clientId=consumer-task.member.v1-3, groupId=task.member.v1] Request joining group due to: need to re-join with the given member-id
2023-12-01 16:23:22.967 INFO  ---- [er#2-0-C-1] [ConsumerCoordinator:1000] requestRejoin   [Consumer clientId=consumer-order.group.v1-1, groupId=order.group.v1] Request joining group due to: need to re-join with the given member-id
2023-12-01 16:23:22.967 INFO  ---- [er#1-0-C-1] [ConsumerCoordinator:535] sendJoinGroupRequest   [Consumer clientId=consumer-task.member.v1-3, groupId=task.member.v1] (Re-)joining group
2023-12-01 16:23:22.968 INFO  ---- [er#2-0-C-1] [ConsumerCoordinator:535] sendJoinGroupRequest   [Consumer clientId=consumer-order.group.v1-1, groupId=order.group.v1] (Re-)joining group
2023-12-01 16:23:22.975 INFO  ---- [er#0-0-C-1] [ConsumerCoordinator:1000] requestRejoin   [Consumer clientId=consumer-task.product.v1-2, groupId=task.product.v1] Request joining group due to: need to re-join with the given member-id
2023-12-01 16:23:22.975 INFO  ---- [er#0-0-C-1] [ConsumerCoordinator:535] sendJoinGroupRequest   [Consumer clientId=consumer-task.product.v1-2, groupId=task.product.v1] (Re-)joining group
2023-12-01 16:23:22.995 INFO  ---- [tartedMain] [DiscoveryClient:492] <init>   Discovery Client initialized at timestamp 1701415402976 with initial instances count: 5
2023-12-01 16:23:23.004 INFO  ---- [tartedMain] [EurekaServiceRegistry:41] register   Registering application TASK-SERVICE with eureka with status UP
2023-12-01 16:23:23.006 INFO  ---- [tartedMain] [DiscoveryClient:1352] notify   Saw local status change event StatusChangeEvent [timestamp=1701415403006, current=UP, previous=STARTING]
2023-12-01 16:23:23.061 INFO  ---- [plicator-0] [DiscoveryClient:873] register   DiscoveryClient_TASK-SERVICE/192.168.0.17:ad9fa6d403dd902dc60d0ebe2fc63a38: registering service...
2023-12-01 16:23:23.164 INFO  ---- [plicator-0] [DiscoveryClient:882] register   DiscoveryClient_TASK-SERVICE/192.168.0.17:ad9fa6d403dd902dc60d0ebe2fc63a38 - registration status: 204
2023-12-01 16:23:25.714 INFO  ---- [tartedMain] [TaskConsumerApplication:61] logStarted   Started TaskConsumerApplication in 12.504 seconds (JVM running for 13.366)
2023-12-01 16:23:25.979 INFO  ---- [er#2-0-C-1] [ConsumerCoordinator:595] handle   [Consumer clientId=consumer-order.group.v1-1, groupId=order.group.v1] Successfully joined group with generation Generation{generationId=12, memberId='consumer-order.group.v1-1-8bdc3e9e-33e2-4a8e-bab6-24c5ec77e21b', protocol='range'}
2023-12-01 16:23:25.982 INFO  ---- [er#2-0-C-1] [ConsumerCoordinator:659] performAssignment   [Consumer clientId=consumer-order.group.v1-1, groupId=order.group.v1] Finished assignment for group at generation 12: {consumer-order.group.v1-1-8bdc3e9e-33e2-4a8e-bab6-24c5ec77e21b=Assignment(partitions=[order-0])}
2023-12-01 16:23:25.996 INFO  ---- [er#2-0-C-1] [ConsumerCoordinator:761] handle   [Consumer clientId=consumer-order.group.v1-1, groupId=order.group.v1] Successfully synced group in generation Generation{generationId=12, memberId='consumer-order.group.v1-1-8bdc3e9e-33e2-4a8e-bab6-24c5ec77e21b', protocol='range'}
2023-12-01 16:23:25.997 INFO  ---- [er#2-0-C-1] [ConsumerCoordinator:280] invokeOnAssignment   [Consumer clientId=consumer-order.group.v1-1, groupId=order.group.v1] Notifying assignor about the new Assignment(partitions=[order-0])
2023-12-01 16:23:25.999 INFO  ---- [er#2-0-C-1] [ConsumerCoordinator:292] invokePartitionsAssigned   [Consumer clientId=consumer-order.group.v1-1, groupId=order.group.v1] Adding newly assigned partitions: order-0
2023-12-01 16:23:26.015 INFO  ---- [er#2-0-C-1] [ConsumerCoordinator:851] refreshCommittedOffsetsIfNeeded   [Consumer clientId=consumer-order.group.v1-1, groupId=order.group.v1] Setting offset for partition order-0 to the committed offset FetchPosition{offset=6, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[127.0.0.1:9092 (id: 2 rack: null)], epoch=0}}
2023-12-01 16:23:26.016 INFO  ---- [er#2-0-C-1] [KafkaMessageListenerContainer:292] info   order.group.v1: partitions assigned: [order-0]
2023-12-01 16:23:26.062 INFO  ---- [er#1-0-C-1] [ConsumerCoordinator:595] handle   [Consumer clientId=consumer-task.member.v1-3, groupId=task.member.v1] Successfully joined group with generation Generation{generationId=56, memberId='consumer-task.member.v1-3-6e863f0d-7e67-4d84-8870-3dd06ffbe45d', protocol='range'}
2023-12-01 16:23:26.062 INFO  ---- [er#1-0-C-1] [ConsumerCoordinator:659] performAssignment   [Consumer clientId=consumer-task.member.v1-3, groupId=task.member.v1] Finished assignment for group at generation 56: {consumer-task.member.v1-3-6e863f0d-7e67-4d84-8870-3dd06ffbe45d=Assignment(partitions=[task-member-0])}
2023-12-01 16:23:26.071 INFO  ---- [er#0-0-C-1] [ConsumerCoordinator:595] handle   [Consumer clientId=consumer-task.product.v1-2, groupId=task.product.v1] Successfully joined group with generation Generation{generationId=56, memberId='consumer-task.product.v1-2-a3e3a672-2cb8-4c68-9842-5f10756f50a3', protocol='range'}
2023-12-01 16:23:26.072 INFO  ---- [er#0-0-C-1] [ConsumerCoordinator:659] performAssignment   [Consumer clientId=consumer-task.product.v1-2, groupId=task.product.v1] Finished assignment for group at generation 56: {consumer-task.product.v1-2-a3e3a672-2cb8-4c68-9842-5f10756f50a3=Assignment(partitions=[task-product-0])}
2023-12-01 16:23:26.073 INFO  ---- [er#1-0-C-1] [ConsumerCoordinator:761] handle   [Consumer clientId=consumer-task.member.v1-3, groupId=task.member.v1] Successfully synced group in generation Generation{generationId=56, memberId='consumer-task.member.v1-3-6e863f0d-7e67-4d84-8870-3dd06ffbe45d', protocol='range'}
2023-12-01 16:23:26.074 INFO  ---- [er#1-0-C-1] [ConsumerCoordinator:280] invokeOnAssignment   [Consumer clientId=consumer-task.member.v1-3, groupId=task.member.v1] Notifying assignor about the new Assignment(partitions=[task-member-0])
2023-12-01 16:23:26.074 INFO  ---- [er#1-0-C-1] [ConsumerCoordinator:292] invokePartitionsAssigned   [Consumer clientId=consumer-task.member.v1-3, groupId=task.member.v1] Adding newly assigned partitions: task-member-0
2023-12-01 16:23:26.078 INFO  ---- [er#0-0-C-1] [ConsumerCoordinator:761] handle   [Consumer clientId=consumer-task.product.v1-2, groupId=task.product.v1] Successfully synced group in generation Generation{generationId=56, memberId='consumer-task.product.v1-2-a3e3a672-2cb8-4c68-9842-5f10756f50a3', protocol='range'}
2023-12-01 16:23:26.078 INFO  ---- [er#0-0-C-1] [ConsumerCoordinator:280] invokeOnAssignment   [Consumer clientId=consumer-task.product.v1-2, groupId=task.product.v1] Notifying assignor about the new Assignment(partitions=[task-product-0])
2023-12-01 16:23:26.078 INFO  ---- [er#0-0-C-1] [ConsumerCoordinator:292] invokePartitionsAssigned   [Consumer clientId=consumer-task.product.v1-2, groupId=task.product.v1] Adding newly assigned partitions: task-product-0
2023-12-01 16:23:26.081 INFO  ---- [er#1-0-C-1] [ConsumerCoordinator:851] refreshCommittedOffsetsIfNeeded   [Consumer clientId=consumer-task.member.v1-3, groupId=task.member.v1] Setting offset for partition task-member-0 to the committed offset FetchPosition{offset=9, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[127.0.0.1:9091 (id: 1 rack: null)], epoch=9}}
2023-12-01 16:23:26.081 INFO  ---- [er#1-0-C-1] [KafkaMessageListenerContainer:292] info   task.member.v1: partitions assigned: [task-member-0]
2023-12-01 16:23:26.087 INFO  ---- [er#0-0-C-1] [ConsumerCoordinator:851] refreshCommittedOffsetsIfNeeded   [Consumer clientId=consumer-task.product.v1-2, groupId=task.product.v1] Setting offset for partition task-product-0 to the committed offset FetchPosition{offset=1, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[127.0.0.1:9091 (id: 1 rack: null)], epoch=9}}
2023-12-01 16:23:26.087 INFO  ---- [er#0-0-C-1] [KafkaMessageListenerContainer:292] info   task.product.v1: partitions assigned: [task-product-0]
2023-12-01 16:23:26.106 INFO  ---- [er#2-0-C-1] [ProducerConfig:376] logAll   ProducerConfig values: 
	acks = -1
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-1
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2023-12-01 16:23:26.115 INFO  ---- [er#2-0-C-1] [KafkaProducer:572] configureTransactionState   [Producer clientId=producer-1] Instantiated an idempotent producer.
2023-12-01 16:23:26.130 INFO  ---- [er#2-0-C-1] [AppInfoParser:119] <init>   Kafka version: 3.1.2
2023-12-01 16:23:26.130 INFO  ---- [er#2-0-C-1] [AppInfoParser:120] <init>   Kafka commitId: f8c67dc3ae0a3265
2023-12-01 16:23:26.131 INFO  ---- [er#2-0-C-1] [AppInfoParser:121] <init>   Kafka startTimeMs: 1701415406130
2023-12-01 16:23:26.141 INFO  ---- [producer-1] [Metadata:402] updateLatestMetadata   [Producer clientId=producer-1] Resetting the last seen epoch of partition member-check-0 to 4 since the associated topicId changed from null to KYr4s4QASse48T8_YcW_QA
2023-12-01 16:23:26.142 INFO  ---- [producer-1] [Metadata:287] update   [Producer clientId=producer-1] Cluster ID: 5_U1uds-SGaR4vItj-jqUw
2023-12-01 16:23:26.143 INFO  ---- [producer-1] [TransactionManager:554] setProducerIdAndEpoch   [Producer clientId=producer-1] ProducerId set to 4012 with epoch 0
2023-12-01 16:23:31.213 INFO  ---- [producer-1] [Metadata:402] updateLatestMetadata   [Producer clientId=producer-1] Resetting the last seen epoch of partition product-check-0 to 0 since the associated topicId changed from null to s3iB_sksQs-tjMNRl3uQ2Q
2023-12-01 16:23:31.532 ERROR ---- [er#0-0-C-1] [OrderSubTaskConsumer:46] ProductTaskListener   taskListener Error message = {"taskId":"4c83c210-7850-4988-ae64-9a7e84033638","subTaskName":"validProductTask : 상품 유효성 검사","status":"FAIL","type":"PRODUCT","productId":269,"colorId":1,"quantity":3,"sizeId":271}
java.lang.NullPointerException: null
	at com.example.taskconsumer.consum.OrderSubTaskConsumer.setCountManager(OrderSubTaskConsumer.java:61)
	at com.example.taskconsumer.consum.OrderSubTaskConsumer.ProductTaskListener(OrderSubTaskConsumer.java:44)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
	at org.springframework.messaging.handler.invocation.InvocableHandlerMethod.doInvoke(InvocableHandlerMethod.java:169)
	at org.springframework.messaging.handler.invocation.InvocableHandlerMethod.invoke(InvocableHandlerMethod.java:119)
	at org.springframework.kafka.listener.adapter.HandlerAdapter.invoke(HandlerAdapter.java:56)
	at org.springframework.kafka.listener.adapter.MessagingMessageListenerAdapter.invokeHandler(MessagingMessageListenerAdapter.java:347)
	at org.springframework.kafka.listener.adapter.RecordMessagingMessageListenerAdapter.onMessage(RecordMessagingMessageListenerAdapter.java:92)
	at org.springframework.kafka.listener.adapter.RecordMessagingMessageListenerAdapter.onMessage(RecordMessagingMessageListenerAdapter.java:53)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeOnMessage(KafkaMessageListenerContainer.java:2670)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeOnMessage(KafkaMessageListenerContainer.java:2650)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeRecordListener(KafkaMessageListenerContainer.java:2577)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeWithRecords(KafkaMessageListenerContainer.java:2457)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeRecordListener(KafkaMessageListenerContainer.java:2335)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeListener(KafkaMessageListenerContainer.java:2006)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeIfHaveRecords(KafkaMessageListenerContainer.java:1375)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.pollAndInvoke(KafkaMessageListenerContainer.java:1366)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.run(KafkaMessageListenerContainer.java:1257)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.lang.Thread.run(Thread.java:834)
2023-12-01 16:24:03.108 WARN  ---- [er#0-0-C-1] [Fetcher:1353] initializeCompletedFetch   [Consumer clientId=consumer-task.product.v1-2, groupId=task.product.v1] Received unknown topic or partition error in fetch for partition task-product-0
2023-12-01 16:24:03.133 WARN  ---- [er#0-0-C-1] [NetworkClient:1103] handleSuccessfulResponse   [Consumer clientId=consumer-task.product.v1-2, groupId=task.product.v1] Error while fetching metadata with correlation id 98 : {task-product=LEADER_NOT_AVAILABLE}
2023-12-01 16:24:03.134 INFO  ---- [er#0-0-C-1] [ConsumerCoordinator:1000] requestRejoin   [Consumer clientId=consumer-task.product.v1-2, groupId=task.product.v1] Request joining group due to: cached metadata has changed from (version2: {task-product=1}) at the beginning of the rebalance to (version3: {})
2023-12-01 16:24:03.135 INFO  ---- [er#0-0-C-1] [ConsumerCoordinator:311] invokePartitionsRevoked   [Consumer clientId=consumer-task.product.v1-2, groupId=task.product.v1] Revoke previously assigned partitions task-product-0
2023-12-01 16:24:03.136 INFO  ---- [er#0-0-C-1] [KafkaMessageListenerContainer:292] info   task.product.v1: partitions revoked: [task-product-0]
2023-12-01 16:24:03.137 INFO  ---- [er#0-0-C-1] [ConsumerCoordinator:535] sendJoinGroupRequest   [Consumer clientId=consumer-task.product.v1-2, groupId=task.product.v1] (Re-)joining group
2023-12-01 16:24:03.142 INFO  ---- [er#0-0-C-1] [ConsumerCoordinator:595] handle   [Consumer clientId=consumer-task.product.v1-2, groupId=task.product.v1] Successfully joined group with generation Generation{generationId=57, memberId='consumer-task.product.v1-2-a3e3a672-2cb8-4c68-9842-5f10756f50a3', protocol='range'}
2023-12-01 16:24:03.259 WARN  ---- [er#0-0-C-1] [NetworkClient:1103] handleSuccessfulResponse   [Consumer clientId=consumer-task.product.v1-2, groupId=task.product.v1] Error while fetching metadata with correlation id 100 : {task-product=LEADER_NOT_AVAILABLE}
2023-12-01 16:24:03.259 INFO  ---- [er#0-0-C-1] [ConsumerCoordinator:659] performAssignment   [Consumer clientId=consumer-task.product.v1-2, groupId=task.product.v1] Finished assignment for group at generation 57: {consumer-task.product.v1-2-a3e3a672-2cb8-4c68-9842-5f10756f50a3=Assignment(partitions=[])}
2023-12-01 16:24:03.265 INFO  ---- [er#0-0-C-1] [ConsumerCoordinator:761] handle   [Consumer clientId=consumer-task.product.v1-2, groupId=task.product.v1] Successfully synced group in generation Generation{generationId=57, memberId='consumer-task.product.v1-2-a3e3a672-2cb8-4c68-9842-5f10756f50a3', protocol='range'}
2023-12-01 16:24:03.266 INFO  ---- [er#0-0-C-1] [ConsumerCoordinator:280] invokeOnAssignment   [Consumer clientId=consumer-task.product.v1-2, groupId=task.product.v1] Notifying assignor about the new Assignment(partitions=[])
2023-12-01 16:24:03.266 INFO  ---- [er#0-0-C-1] [ConsumerCoordinator:292] invokePartitionsAssigned   [Consumer clientId=consumer-task.product.v1-2, groupId=task.product.v1] Adding newly assigned partitions: 
2023-12-01 16:24:03.266 INFO  ---- [er#0-0-C-1] [KafkaMessageListenerContainer:292] info   task.product.v1: partitions assigned: []
2023-12-01 16:24:03.376 INFO  ---- [er#0-0-C-1] [Metadata:402] updateLatestMetadata   [Consumer clientId=consumer-task.product.v1-2, groupId=task.product.v1] Resetting the last seen epoch of partition task-product-0 to 0 since the associated topicId changed from null to u4d-oRkEQLKvVCjQ80qpEA
2023-12-01 16:24:03.376 INFO  ---- [er#0-0-C-1] [ConsumerCoordinator:1000] requestRejoin   [Consumer clientId=consumer-task.product.v1-2, groupId=task.product.v1] Request joining group due to: cached metadata has changed from (version4: {}) at the beginning of the rebalance to (version5: {task-product=1})
2023-12-01 16:24:03.377 INFO  ---- [er#0-0-C-1] [ConsumerCoordinator:311] invokePartitionsRevoked   [Consumer clientId=consumer-task.product.v1-2, groupId=task.product.v1] Revoke previously assigned partitions 
2023-12-01 16:24:03.377 INFO  ---- [er#0-0-C-1] [KafkaMessageListenerContainer:292] info   task.product.v1: partitions revoked: []
2023-12-01 16:24:03.377 INFO  ---- [er#0-0-C-1] [ConsumerCoordinator:535] sendJoinGroupRequest   [Consumer clientId=consumer-task.product.v1-2, groupId=task.product.v1] (Re-)joining group
2023-12-01 16:24:03.382 INFO  ---- [er#0-0-C-1] [ConsumerCoordinator:595] handle   [Consumer clientId=consumer-task.product.v1-2, groupId=task.product.v1] Successfully joined group with generation Generation{generationId=58, memberId='consumer-task.product.v1-2-a3e3a672-2cb8-4c68-9842-5f10756f50a3', protocol='range'}
2023-12-01 16:24:03.382 INFO  ---- [er#0-0-C-1] [ConsumerCoordinator:659] performAssignment   [Consumer clientId=consumer-task.product.v1-2, groupId=task.product.v1] Finished assignment for group at generation 58: {consumer-task.product.v1-2-a3e3a672-2cb8-4c68-9842-5f10756f50a3=Assignment(partitions=[task-product-0])}
2023-12-01 16:24:03.385 INFO  ---- [er#0-0-C-1] [ConsumerCoordinator:761] handle   [Consumer clientId=consumer-task.product.v1-2, groupId=task.product.v1] Successfully synced group in generation Generation{generationId=58, memberId='consumer-task.product.v1-2-a3e3a672-2cb8-4c68-9842-5f10756f50a3', protocol='range'}
2023-12-01 16:24:03.385 INFO  ---- [er#0-0-C-1] [ConsumerCoordinator:280] invokeOnAssignment   [Consumer clientId=consumer-task.product.v1-2, groupId=task.product.v1] Notifying assignor about the new Assignment(partitions=[task-product-0])
2023-12-01 16:24:03.386 INFO  ---- [er#0-0-C-1] [ConsumerCoordinator:292] invokePartitionsAssigned   [Consumer clientId=consumer-task.product.v1-2, groupId=task.product.v1] Adding newly assigned partitions: task-product-0
2023-12-01 16:24:03.388 INFO  ---- [er#0-0-C-1] [ConsumerCoordinator:1405] handle   [Consumer clientId=consumer-task.product.v1-2, groupId=task.product.v1] Found no committed offset for partition task-product-0
2023-12-01 16:24:03.390 INFO  ---- [er#0-0-C-1] [ConsumerCoordinator:1405] handle   [Consumer clientId=consumer-task.product.v1-2, groupId=task.product.v1] Found no committed offset for partition task-product-0
2023-12-01 16:24:03.400 INFO  ---- [er#0-0-C-1] [SubscriptionState:398] maybeSeekUnvalidated   [Consumer clientId=consumer-task.product.v1-2, groupId=task.product.v1] Resetting offset for partition task-product-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[127.0.0.1:9091 (id: 1 rack: null)], epoch=0}}.
2023-12-01 16:24:03.405 INFO  ---- [er#0-0-C-1] [KafkaMessageListenerContainer:292] info   task.product.v1: partitions assigned: [task-product-0]
2023-12-01 16:27:44.269 INFO  ---- [tartedMain] [TaskConsumerApplication:55] logStarting   Starting TaskConsumerApplication using Java 11.0.13 on DESKTOP-MNMB87E with PID 23668 (C:\Users\tkdrb\IdeaProjects\ecommerce\task-consumer\build\classes\java\main started by tkdrb in C:\Users\tkdrb\IdeaProjects\ecommerce\task-consumer)
2023-12-01 16:27:44.271 INFO  ---- [tartedMain] [TaskConsumerApplication:631] logStartupProfileInfo   No active profile set, falling back to 1 default profile: "default"
2023-12-01 16:27:44.326 INFO  ---- [tartedMain] [DevToolsPropertyDefaultsPostProcessor:255] logTo   Devtools property defaults active! Set 'spring.devtools.add-properties' to 'false' to disable
2023-12-01 16:27:44.326 INFO  ---- [tartedMain] [DevToolsPropertyDefaultsPostProcessor:255] logTo   For additional web related logging consider setting the 'logging.level.web' property to 'DEBUG'
2023-12-01 16:27:45.123 INFO  ---- [tartedMain] [GenericScope:283] setSerializationId   BeanFactory id=7d336d03-7948-373b-80b2-3edd326128fe
2023-12-01 16:27:46.299 INFO  ---- [tartedMain] [TomcatWebServer:108] initialize   Tomcat initialized with port(s): 0 (http)
2023-12-01 16:27:46.320 INFO  ---- [tartedMain] [StandardService:173] log   Starting service [Tomcat]
2023-12-01 16:27:46.321 INFO  ---- [tartedMain] [StandardEngine:173] log   Starting Servlet engine: [Apache Tomcat/9.0.76]
2023-12-01 16:27:46.541 INFO  ---- [tartedMain] [[/]:173] log   Initializing Spring embedded WebApplicationContext
2023-12-01 16:27:46.541 INFO  ---- [tartedMain] [ServletWebServerApplicationContext:292] prepareWebApplicationContext   Root WebApplicationContext: initialization completed in 2214 ms
2023-12-01 16:27:47.199 INFO  ---- [tartedMain] [OptionalLiveReloadServer:59] startServer   LiveReload server is running on port 35729
2023-12-01 16:27:48.087 INFO  ---- [tartedMain] [DiscoveryClientOptionalArgsConfiguration:71] restTemplateDiscoveryClientOptionalArgs   Eureka HTTP Client uses RestTemplate.
2023-12-01 16:27:49.021 WARN  ---- [tartedMain] [LoadBalancerCacheAutoConfiguration$LoadBalancerCaffeineWarnLogger:83] logWarning   Spring Cloud LoadBalancer is currently working with the default cache. While this cache implementation is useful for development and tests, it's recommended to use Caffeine cache in production.You can switch to using Caffeine cache, by adding it and org.springframework.cache.caffeine.CaffeineCacheManager to the classpath.
2023-12-01 16:27:49.116 INFO  ---- [tartedMain] [ConsumerConfig:376] logAll   ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-order.group.v1-1
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = order.group.v1
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2023-12-01 16:27:49.465 INFO  ---- [tartedMain] [AppInfoParser:119] <init>   Kafka version: 3.1.2
2023-12-01 16:27:49.467 INFO  ---- [tartedMain] [AppInfoParser:120] <init>   Kafka commitId: f8c67dc3ae0a3265
2023-12-01 16:27:49.467 INFO  ---- [tartedMain] [AppInfoParser:121] <init>   Kafka startTimeMs: 1701415669461
2023-12-01 16:27:49.472 INFO  ---- [tartedMain] [KafkaConsumer:966] subscribe   [Consumer clientId=consumer-order.group.v1-1, groupId=order.group.v1] Subscribed to topic(s): order
2023-12-01 16:27:49.540 INFO  ---- [tartedMain] [ConsumerConfig:376] logAll   ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-task.member.v1-2
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = task.member.v1
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2023-12-01 16:27:49.549 INFO  ---- [tartedMain] [AppInfoParser:119] <init>   Kafka version: 3.1.2
2023-12-01 16:27:49.550 INFO  ---- [tartedMain] [AppInfoParser:120] <init>   Kafka commitId: f8c67dc3ae0a3265
2023-12-01 16:27:49.550 INFO  ---- [tartedMain] [AppInfoParser:121] <init>   Kafka startTimeMs: 1701415669549
2023-12-01 16:27:49.551 INFO  ---- [tartedMain] [KafkaConsumer:966] subscribe   [Consumer clientId=consumer-task.member.v1-2, groupId=task.member.v1] Subscribed to topic(s): task-member
2023-12-01 16:27:49.608 INFO  ---- [tartedMain] [ConsumerConfig:376] logAll   ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-task.product.v1-3
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = task.product.v1
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2023-12-01 16:27:49.617 INFO  ---- [tartedMain] [AppInfoParser:119] <init>   Kafka version: 3.1.2
2023-12-01 16:27:49.618 INFO  ---- [tartedMain] [AppInfoParser:120] <init>   Kafka commitId: f8c67dc3ae0a3265
2023-12-01 16:27:49.618 INFO  ---- [tartedMain] [AppInfoParser:121] <init>   Kafka startTimeMs: 1701415669617
2023-12-01 16:27:49.618 INFO  ---- [tartedMain] [KafkaConsumer:966] subscribe   [Consumer clientId=consumer-task.product.v1-3, groupId=task.product.v1] Subscribed to topic(s): task-product
2023-12-01 16:27:49.652 INFO  ---- [tartedMain] [TomcatWebServer:220] start   Tomcat started on port(s): 60622 (http) with context path ''
2023-12-01 16:27:49.655 INFO  ---- [tartedMain] [EurekaAutoServiceRegistration:144] onApplicationEvent   Updating port to 60622
2023-12-01 16:27:49.682 INFO  ---- [tartedMain] [InstanceInfoFactory:67] create   Setting initial instance status as: STARTING
2023-12-01 16:27:49.766 INFO  ---- [tartedMain] [DiscoveryClient:372] <init>   Initializing Eureka in region us-east-1
2023-12-01 16:27:49.776 INFO  ---- [tartedMain] [ConfigClusterResolver:43] getClusterEndpoints   Resolving eureka endpoints via configuration
2023-12-01 16:27:49.824 INFO  ---- [tartedMain] [DiscoveryClient:1007] fetchRegistry   Disable delta property : false
2023-12-01 16:27:49.825 INFO  ---- [tartedMain] [DiscoveryClient:1008] fetchRegistry   Single vip registry refresh property : null
2023-12-01 16:27:49.825 INFO  ---- [tartedMain] [DiscoveryClient:1009] fetchRegistry   Force full registry fetch : false
2023-12-01 16:27:49.825 INFO  ---- [tartedMain] [DiscoveryClient:1010] fetchRegistry   Application is null : false
2023-12-01 16:27:49.826 INFO  ---- [tartedMain] [DiscoveryClient:1011] fetchRegistry   Registered Applications size is zero : true
2023-12-01 16:27:49.826 INFO  ---- [tartedMain] [DiscoveryClient:1013] fetchRegistry   Application version is -1: true
2023-12-01 16:27:49.826 INFO  ---- [tartedMain] [DiscoveryClient:1097] getAndStoreFullRegistry   Getting all instance registry info from the eureka server
2023-12-01 16:27:50.116 INFO  ---- [er#2-0-C-1] [Metadata:402] updateLatestMetadata   [Consumer clientId=consumer-order.group.v1-1, groupId=order.group.v1] Resetting the last seen epoch of partition order-0 to 0 since the associated topicId changed from null to 8AIo0qkzSIiGJbn1bQxAkw
2023-12-01 16:27:50.116 INFO  ---- [er#0-0-C-1] [Metadata:402] updateLatestMetadata   [Consumer clientId=consumer-task.member.v1-2, groupId=task.member.v1] Resetting the last seen epoch of partition task-member-0 to 9 since the associated topicId changed from null to HvfbkcRhQ3meTIJFgCt9zw
2023-12-01 16:27:50.116 INFO  ---- [er#1-0-C-1] [Metadata:402] updateLatestMetadata   [Consumer clientId=consumer-task.product.v1-3, groupId=task.product.v1] Resetting the last seen epoch of partition task-product-0 to 0 since the associated topicId changed from null to u4d-oRkEQLKvVCjQ80qpEA
2023-12-01 16:27:50.120 INFO  ---- [er#2-0-C-1] [Metadata:287] update   [Consumer clientId=consumer-order.group.v1-1, groupId=order.group.v1] Cluster ID: 5_U1uds-SGaR4vItj-jqUw
2023-12-01 16:27:50.120 INFO  ---- [er#1-0-C-1] [Metadata:287] update   [Consumer clientId=consumer-task.product.v1-3, groupId=task.product.v1] Cluster ID: 5_U1uds-SGaR4vItj-jqUw
2023-12-01 16:27:50.120 INFO  ---- [er#0-0-C-1] [Metadata:287] update   [Consumer clientId=consumer-task.member.v1-2, groupId=task.member.v1] Cluster ID: 5_U1uds-SGaR4vItj-jqUw
2023-12-01 16:27:50.122 INFO  ---- [er#2-0-C-1] [ConsumerCoordinator:853] onSuccess   [Consumer clientId=consumer-order.group.v1-1, groupId=order.group.v1] Discovered group coordinator 127.0.0.1:9091 (id: 2147483646 rack: null)
2023-12-01 16:27:50.122 INFO  ---- [er#0-0-C-1] [ConsumerCoordinator:853] onSuccess   [Consumer clientId=consumer-task.member.v1-2, groupId=task.member.v1] Discovered group coordinator 127.0.0.1:9093 (id: 2147483644 rack: null)
2023-12-01 16:27:50.122 INFO  ---- [er#1-0-C-1] [ConsumerCoordinator:853] onSuccess   [Consumer clientId=consumer-task.product.v1-3, groupId=task.product.v1] Discovered group coordinator 127.0.0.1:9091 (id: 2147483646 rack: null)
2023-12-01 16:27:50.126 INFO  ---- [er#0-0-C-1] [ConsumerCoordinator:535] sendJoinGroupRequest   [Consumer clientId=consumer-task.member.v1-2, groupId=task.member.v1] (Re-)joining group
2023-12-01 16:27:50.126 INFO  ---- [er#1-0-C-1] [ConsumerCoordinator:535] sendJoinGroupRequest   [Consumer clientId=consumer-task.product.v1-3, groupId=task.product.v1] (Re-)joining group
2023-12-01 16:27:50.126 INFO  ---- [er#2-0-C-1] [ConsumerCoordinator:535] sendJoinGroupRequest   [Consumer clientId=consumer-order.group.v1-1, groupId=order.group.v1] (Re-)joining group
2023-12-01 16:27:50.149 INFO  ---- [er#1-0-C-1] [ConsumerCoordinator:1000] requestRejoin   [Consumer clientId=consumer-task.product.v1-3, groupId=task.product.v1] Request joining group due to: need to re-join with the given member-id
2023-12-01 16:27:50.149 INFO  ---- [er#0-0-C-1] [ConsumerCoordinator:1000] requestRejoin   [Consumer clientId=consumer-task.member.v1-2, groupId=task.member.v1] Request joining group due to: need to re-join with the given member-id
2023-12-01 16:27:50.149 INFO  ---- [er#2-0-C-1] [ConsumerCoordinator:1000] requestRejoin   [Consumer clientId=consumer-order.group.v1-1, groupId=order.group.v1] Request joining group due to: need to re-join with the given member-id
2023-12-01 16:27:50.150 INFO  ---- [er#2-0-C-1] [ConsumerCoordinator:535] sendJoinGroupRequest   [Consumer clientId=consumer-order.group.v1-1, groupId=order.group.v1] (Re-)joining group
2023-12-01 16:27:50.150 INFO  ---- [er#0-0-C-1] [ConsumerCoordinator:535] sendJoinGroupRequest   [Consumer clientId=consumer-task.member.v1-2, groupId=task.member.v1] (Re-)joining group
2023-12-01 16:27:50.150 INFO  ---- [er#1-0-C-1] [ConsumerCoordinator:535] sendJoinGroupRequest   [Consumer clientId=consumer-task.product.v1-3, groupId=task.product.v1] (Re-)joining group
2023-12-01 16:27:50.214 INFO  ---- [tartedMain] [DiscoveryClient:1106] getAndStoreFullRegistry   The response status is 200
2023-12-01 16:27:50.217 INFO  ---- [tartedMain] [DiscoveryClient:1321] initScheduledTasks   Starting heartbeat executor: renew interval is: 30
2023-12-01 16:27:50.221 INFO  ---- [tartedMain] [InstanceInfoReplicator:60] <init>   InstanceInfoReplicator onDemand update allowed rate per min is 4
2023-12-01 16:27:50.229 INFO  ---- [tartedMain] [DiscoveryClient:492] <init>   Discovery Client initialized at timestamp 1701415670227 with initial instances count: 5
2023-12-01 16:27:50.231 INFO  ---- [tartedMain] [EurekaServiceRegistry:41] register   Registering application TASK-SERVICE with eureka with status UP
2023-12-01 16:27:50.233 INFO  ---- [tartedMain] [DiscoveryClient:1352] notify   Saw local status change event StatusChangeEvent [timestamp=1701415670233, current=UP, previous=STARTING]
2023-12-01 16:27:50.240 INFO  ---- [plicator-0] [DiscoveryClient:873] register   DiscoveryClient_TASK-SERVICE/192.168.0.17:36b1cf321a631ba30f3bdb264d35dcf6: registering service...
2023-12-01 16:27:50.316 INFO  ---- [plicator-0] [DiscoveryClient:882] register   DiscoveryClient_TASK-SERVICE/192.168.0.17:36b1cf321a631ba30f3bdb264d35dcf6 - registration status: 204
2023-12-01 16:27:51.590 INFO  ---- [tartedMain] [TaskConsumerApplication:61] logStarted   Started TaskConsumerApplication in 8.426 seconds (JVM running for 9.036)
2023-12-01 16:27:53.155 INFO  ---- [er#1-0-C-1] [ConsumerCoordinator:595] handle   [Consumer clientId=consumer-task.product.v1-3, groupId=task.product.v1] Successfully joined group with generation Generation{generationId=60, memberId='consumer-task.product.v1-3-992c556b-f5df-4e34-a2fb-740733f73b1a', protocol='range'}
2023-12-01 16:27:53.155 INFO  ---- [er#0-0-C-1] [ConsumerCoordinator:595] handle   [Consumer clientId=consumer-task.member.v1-2, groupId=task.member.v1] Successfully joined group with generation Generation{generationId=58, memberId='consumer-task.member.v1-2-991e9a61-204e-44a2-b89d-1c66c2b2e91f', protocol='range'}
2023-12-01 16:27:53.155 INFO  ---- [er#2-0-C-1] [ConsumerCoordinator:595] handle   [Consumer clientId=consumer-order.group.v1-1, groupId=order.group.v1] Successfully joined group with generation Generation{generationId=14, memberId='consumer-order.group.v1-1-b2077cbc-ce44-42fa-b612-8f1b79bff16a', protocol='range'}
2023-12-01 16:27:53.160 INFO  ---- [er#1-0-C-1] [ConsumerCoordinator:659] performAssignment   [Consumer clientId=consumer-task.product.v1-3, groupId=task.product.v1] Finished assignment for group at generation 60: {consumer-task.product.v1-3-992c556b-f5df-4e34-a2fb-740733f73b1a=Assignment(partitions=[task-product-0])}
2023-12-01 16:27:53.160 INFO  ---- [er#0-0-C-1] [ConsumerCoordinator:659] performAssignment   [Consumer clientId=consumer-task.member.v1-2, groupId=task.member.v1] Finished assignment for group at generation 58: {consumer-task.member.v1-2-991e9a61-204e-44a2-b89d-1c66c2b2e91f=Assignment(partitions=[task-member-0])}
2023-12-01 16:27:53.160 INFO  ---- [er#2-0-C-1] [ConsumerCoordinator:659] performAssignment   [Consumer clientId=consumer-order.group.v1-1, groupId=order.group.v1] Finished assignment for group at generation 14: {consumer-order.group.v1-1-b2077cbc-ce44-42fa-b612-8f1b79bff16a=Assignment(partitions=[order-0])}
2023-12-01 16:27:53.174 INFO  ---- [er#1-0-C-1] [ConsumerCoordinator:761] handle   [Consumer clientId=consumer-task.product.v1-3, groupId=task.product.v1] Successfully synced group in generation Generation{generationId=60, memberId='consumer-task.product.v1-3-992c556b-f5df-4e34-a2fb-740733f73b1a', protocol='range'}
2023-12-01 16:27:53.174 INFO  ---- [er#2-0-C-1] [ConsumerCoordinator:761] handle   [Consumer clientId=consumer-order.group.v1-1, groupId=order.group.v1] Successfully synced group in generation Generation{generationId=14, memberId='consumer-order.group.v1-1-b2077cbc-ce44-42fa-b612-8f1b79bff16a', protocol='range'}
2023-12-01 16:27:53.174 INFO  ---- [er#0-0-C-1] [ConsumerCoordinator:761] handle   [Consumer clientId=consumer-task.member.v1-2, groupId=task.member.v1] Successfully synced group in generation Generation{generationId=58, memberId='consumer-task.member.v1-2-991e9a61-204e-44a2-b89d-1c66c2b2e91f', protocol='range'}
2023-12-01 16:27:53.175 INFO  ---- [er#1-0-C-1] [ConsumerCoordinator:280] invokeOnAssignment   [Consumer clientId=consumer-task.product.v1-3, groupId=task.product.v1] Notifying assignor about the new Assignment(partitions=[task-product-0])
2023-12-01 16:27:53.175 INFO  ---- [er#0-0-C-1] [ConsumerCoordinator:280] invokeOnAssignment   [Consumer clientId=consumer-task.member.v1-2, groupId=task.member.v1] Notifying assignor about the new Assignment(partitions=[task-member-0])
2023-12-01 16:27:53.175 INFO  ---- [er#2-0-C-1] [ConsumerCoordinator:280] invokeOnAssignment   [Consumer clientId=consumer-order.group.v1-1, groupId=order.group.v1] Notifying assignor about the new Assignment(partitions=[order-0])
2023-12-01 16:27:53.179 INFO  ---- [er#1-0-C-1] [ConsumerCoordinator:292] invokePartitionsAssigned   [Consumer clientId=consumer-task.product.v1-3, groupId=task.product.v1] Adding newly assigned partitions: task-product-0
2023-12-01 16:27:53.179 INFO  ---- [er#0-0-C-1] [ConsumerCoordinator:292] invokePartitionsAssigned   [Consumer clientId=consumer-task.member.v1-2, groupId=task.member.v1] Adding newly assigned partitions: task-member-0
2023-12-01 16:27:53.179 INFO  ---- [er#2-0-C-1] [ConsumerCoordinator:292] invokePartitionsAssigned   [Consumer clientId=consumer-order.group.v1-1, groupId=order.group.v1] Adding newly assigned partitions: order-0
2023-12-01 16:27:53.202 INFO  ---- [er#1-0-C-1] [ConsumerCoordinator:851] refreshCommittedOffsetsIfNeeded   [Consumer clientId=consumer-task.product.v1-3, groupId=task.product.v1] Setting offset for partition task-product-0 to the committed offset FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[127.0.0.1:9091 (id: 1 rack: null)], epoch=0}}
2023-12-01 16:27:53.202 INFO  ---- [er#2-0-C-1] [ConsumerCoordinator:851] refreshCommittedOffsetsIfNeeded   [Consumer clientId=consumer-order.group.v1-1, groupId=order.group.v1] Setting offset for partition order-0 to the committed offset FetchPosition{offset=6, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[127.0.0.1:9092 (id: 2 rack: null)], epoch=0}}
2023-12-01 16:27:53.202 INFO  ---- [er#0-0-C-1] [ConsumerCoordinator:851] refreshCommittedOffsetsIfNeeded   [Consumer clientId=consumer-task.member.v1-2, groupId=task.member.v1] Setting offset for partition task-member-0 to the committed offset FetchPosition{offset=10, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[127.0.0.1:9091 (id: 1 rack: null)], epoch=9}}
2023-12-01 16:27:53.203 INFO  ---- [er#0-0-C-1] [KafkaMessageListenerContainer:292] info   task.member.v1: partitions assigned: [task-member-0]
2023-12-01 16:27:53.203 INFO  ---- [er#2-0-C-1] [KafkaMessageListenerContainer:292] info   order.group.v1: partitions assigned: [order-0]
2023-12-01 16:27:53.203 INFO  ---- [er#1-0-C-1] [KafkaMessageListenerContainer:292] info   task.product.v1: partitions assigned: [task-product-0]
2023-12-01 16:27:53.307 INFO  ---- [er#2-0-C-1] [ProducerConfig:376] logAll   ProducerConfig values: 
	acks = -1
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-1
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2023-12-01 16:27:53.317 INFO  ---- [er#2-0-C-1] [KafkaProducer:572] configureTransactionState   [Producer clientId=producer-1] Instantiated an idempotent producer.
2023-12-01 16:27:53.333 INFO  ---- [er#2-0-C-1] [AppInfoParser:119] <init>   Kafka version: 3.1.2
2023-12-01 16:27:53.333 INFO  ---- [er#2-0-C-1] [AppInfoParser:120] <init>   Kafka commitId: f8c67dc3ae0a3265
2023-12-01 16:27:53.334 INFO  ---- [er#2-0-C-1] [AppInfoParser:121] <init>   Kafka startTimeMs: 1701415673333
2023-12-01 16:27:53.359 INFO  ---- [producer-1] [Metadata:402] updateLatestMetadata   [Producer clientId=producer-1] Resetting the last seen epoch of partition member-check-0 to 4 since the associated topicId changed from null to KYr4s4QASse48T8_YcW_QA
2023-12-01 16:27:53.359 INFO  ---- [producer-1] [Metadata:287] update   [Producer clientId=producer-1] Cluster ID: 5_U1uds-SGaR4vItj-jqUw
2023-12-01 16:27:53.371 INFO  ---- [producer-1] [TransactionManager:554] setProducerIdAndEpoch   [Producer clientId=producer-1] ProducerId set to 4016 with epoch 0
2023-12-01 16:28:31.641 INFO  ---- [producer-1] [Metadata:402] updateLatestMetadata   [Producer clientId=producer-1] Resetting the last seen epoch of partition product-check-0 to 0 since the associated topicId changed from null to s3iB_sksQs-tjMNRl3uQ2Q
2023-12-01 16:28:31.806 ERROR ---- [er#1-0-C-1] [OrderSubTaskConsumer:46] ProductTaskListener   taskListener Error message = {"taskId":"4c83c210-7850-4988-ae64-9a7e84033638","subTaskName":"validProductTask : 상품 유효성 검사","status":"FAIL","type":"PRODUCT","productId":269,"colorId":1,"quantity":3,"sizeId":271}
java.lang.NullPointerException: null
	at com.example.taskconsumer.consum.OrderSubTaskConsumer.setCountManager(OrderSubTaskConsumer.java:61)
	at com.example.taskconsumer.consum.OrderSubTaskConsumer.ProductTaskListener(OrderSubTaskConsumer.java:44)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
	at org.springframework.messaging.handler.invocation.InvocableHandlerMethod.doInvoke(InvocableHandlerMethod.java:169)
	at org.springframework.messaging.handler.invocation.InvocableHandlerMethod.invoke(InvocableHandlerMethod.java:119)
	at org.springframework.kafka.listener.adapter.HandlerAdapter.invoke(HandlerAdapter.java:56)
	at org.springframework.kafka.listener.adapter.MessagingMessageListenerAdapter.invokeHandler(MessagingMessageListenerAdapter.java:347)
	at org.springframework.kafka.listener.adapter.RecordMessagingMessageListenerAdapter.onMessage(RecordMessagingMessageListenerAdapter.java:92)
	at org.springframework.kafka.listener.adapter.RecordMessagingMessageListenerAdapter.onMessage(RecordMessagingMessageListenerAdapter.java:53)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeOnMessage(KafkaMessageListenerContainer.java:2670)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeOnMessage(KafkaMessageListenerContainer.java:2650)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeRecordListener(KafkaMessageListenerContainer.java:2577)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeWithRecords(KafkaMessageListenerContainer.java:2457)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeRecordListener(KafkaMessageListenerContainer.java:2335)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeListener(KafkaMessageListenerContainer.java:2006)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeIfHaveRecords(KafkaMessageListenerContainer.java:1375)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.pollAndInvoke(KafkaMessageListenerContainer.java:1366)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.run(KafkaMessageListenerContainer.java:1257)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.lang.Thread.run(Thread.java:834)
2023-12-01 16:29:36.344 WARN  ---- [er#1-0-C-1] [Fetcher:1353] initializeCompletedFetch   [Consumer clientId=consumer-task.product.v1-3, groupId=task.product.v1] Received unknown topic or partition error in fetch for partition task-product-0
2023-12-01 16:29:36.352 WARN  ---- [er#1-0-C-1] [NetworkClient:1103] handleSuccessfulResponse   [Consumer clientId=consumer-task.product.v1-3, groupId=task.product.v1] Error while fetching metadata with correlation id 251 : {task-product=LEADER_NOT_AVAILABLE}
2023-12-01 16:29:36.354 INFO  ---- [er#1-0-C-1] [ConsumerCoordinator:1000] requestRejoin   [Consumer clientId=consumer-task.product.v1-3, groupId=task.product.v1] Request joining group due to: cached metadata has changed from (version2: {task-product=1}) at the beginning of the rebalance to (version3: {})
2023-12-01 16:29:36.356 INFO  ---- [er#1-0-C-1] [ConsumerCoordinator:311] invokePartitionsRevoked   [Consumer clientId=consumer-task.product.v1-3, groupId=task.product.v1] Revoke previously assigned partitions task-product-0
2023-12-01 16:29:36.357 INFO  ---- [er#1-0-C-1] [KafkaMessageListenerContainer:292] info   task.product.v1: partitions revoked: [task-product-0]
2023-12-01 16:29:36.357 INFO  ---- [er#1-0-C-1] [ConsumerCoordinator:535] sendJoinGroupRequest   [Consumer clientId=consumer-task.product.v1-3, groupId=task.product.v1] (Re-)joining group
2023-12-01 16:29:36.363 INFO  ---- [er#1-0-C-1] [ConsumerCoordinator:595] handle   [Consumer clientId=consumer-task.product.v1-3, groupId=task.product.v1] Successfully joined group with generation Generation{generationId=61, memberId='consumer-task.product.v1-3-992c556b-f5df-4e34-a2fb-740733f73b1a', protocol='range'}
2023-12-01 16:29:36.478 WARN  ---- [er#1-0-C-1] [NetworkClient:1103] handleSuccessfulResponse   [Consumer clientId=consumer-task.product.v1-3, groupId=task.product.v1] Error while fetching metadata with correlation id 253 : {task-product=LEADER_NOT_AVAILABLE}
2023-12-01 16:29:36.479 INFO  ---- [er#1-0-C-1] [ConsumerCoordinator:659] performAssignment   [Consumer clientId=consumer-task.product.v1-3, groupId=task.product.v1] Finished assignment for group at generation 61: {consumer-task.product.v1-3-992c556b-f5df-4e34-a2fb-740733f73b1a=Assignment(partitions=[])}
2023-12-01 16:29:36.488 INFO  ---- [er#1-0-C-1] [ConsumerCoordinator:761] handle   [Consumer clientId=consumer-task.product.v1-3, groupId=task.product.v1] Successfully synced group in generation Generation{generationId=61, memberId='consumer-task.product.v1-3-992c556b-f5df-4e34-a2fb-740733f73b1a', protocol='range'}
2023-12-01 16:29:36.489 INFO  ---- [er#1-0-C-1] [ConsumerCoordinator:280] invokeOnAssignment   [Consumer clientId=consumer-task.product.v1-3, groupId=task.product.v1] Notifying assignor about the new Assignment(partitions=[])
2023-12-01 16:29:36.489 INFO  ---- [er#1-0-C-1] [ConsumerCoordinator:292] invokePartitionsAssigned   [Consumer clientId=consumer-task.product.v1-3, groupId=task.product.v1] Adding newly assigned partitions: 
2023-12-01 16:29:36.489 INFO  ---- [er#1-0-C-1] [KafkaMessageListenerContainer:292] info   task.product.v1: partitions assigned: []
2023-12-01 16:29:36.595 INFO  ---- [er#1-0-C-1] [Metadata:402] updateLatestMetadata   [Consumer clientId=consumer-task.product.v1-3, groupId=task.product.v1] Resetting the last seen epoch of partition task-product-0 to 0 since the associated topicId changed from null to T-WbK4e2RBadoGDNie-IOw
2023-12-01 16:29:36.597 INFO  ---- [er#1-0-C-1] [ConsumerCoordinator:1000] requestRejoin   [Consumer clientId=consumer-task.product.v1-3, groupId=task.product.v1] Request joining group due to: cached metadata has changed from (version4: {}) at the beginning of the rebalance to (version5: {task-product=1})
2023-12-01 16:29:36.598 INFO  ---- [er#1-0-C-1] [ConsumerCoordinator:311] invokePartitionsRevoked   [Consumer clientId=consumer-task.product.v1-3, groupId=task.product.v1] Revoke previously assigned partitions 
2023-12-01 16:29:36.598 INFO  ---- [er#1-0-C-1] [KafkaMessageListenerContainer:292] info   task.product.v1: partitions revoked: []
2023-12-01 16:29:36.598 INFO  ---- [er#1-0-C-1] [ConsumerCoordinator:535] sendJoinGroupRequest   [Consumer clientId=consumer-task.product.v1-3, groupId=task.product.v1] (Re-)joining group
2023-12-01 16:29:36.603 INFO  ---- [er#1-0-C-1] [ConsumerCoordinator:595] handle   [Consumer clientId=consumer-task.product.v1-3, groupId=task.product.v1] Successfully joined group with generation Generation{generationId=62, memberId='consumer-task.product.v1-3-992c556b-f5df-4e34-a2fb-740733f73b1a', protocol='range'}
2023-12-01 16:29:36.604 INFO  ---- [er#1-0-C-1] [ConsumerCoordinator:659] performAssignment   [Consumer clientId=consumer-task.product.v1-3, groupId=task.product.v1] Finished assignment for group at generation 62: {consumer-task.product.v1-3-992c556b-f5df-4e34-a2fb-740733f73b1a=Assignment(partitions=[task-product-0])}
2023-12-01 16:29:36.608 INFO  ---- [er#1-0-C-1] [ConsumerCoordinator:761] handle   [Consumer clientId=consumer-task.product.v1-3, groupId=task.product.v1] Successfully synced group in generation Generation{generationId=62, memberId='consumer-task.product.v1-3-992c556b-f5df-4e34-a2fb-740733f73b1a', protocol='range'}
2023-12-01 16:29:36.609 INFO  ---- [er#1-0-C-1] [ConsumerCoordinator:280] invokeOnAssignment   [Consumer clientId=consumer-task.product.v1-3, groupId=task.product.v1] Notifying assignor about the new Assignment(partitions=[task-product-0])
2023-12-01 16:29:36.609 INFO  ---- [er#1-0-C-1] [ConsumerCoordinator:292] invokePartitionsAssigned   [Consumer clientId=consumer-task.product.v1-3, groupId=task.product.v1] Adding newly assigned partitions: task-product-0
2023-12-01 16:29:36.612 INFO  ---- [er#1-0-C-1] [ConsumerCoordinator:1405] handle   [Consumer clientId=consumer-task.product.v1-3, groupId=task.product.v1] Found no committed offset for partition task-product-0
2023-12-01 16:29:36.614 INFO  ---- [er#1-0-C-1] [ConsumerCoordinator:1405] handle   [Consumer clientId=consumer-task.product.v1-3, groupId=task.product.v1] Found no committed offset for partition task-product-0
2023-12-01 16:29:36.625 INFO  ---- [er#1-0-C-1] [SubscriptionState:398] maybeSeekUnvalidated   [Consumer clientId=consumer-task.product.v1-3, groupId=task.product.v1] Resetting offset for partition task-product-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[127.0.0.1:9091 (id: 1 rack: null)], epoch=0}}.
2023-12-01 16:29:36.629 INFO  ---- [er#1-0-C-1] [KafkaMessageListenerContainer:292] info   task.product.v1: partitions assigned: [task-product-0]
2023-12-01 16:29:52.822 WARN  ---- [er#1-0-C-1] [Fetcher:1353] initializeCompletedFetch   [Consumer clientId=consumer-task.product.v1-3, groupId=task.product.v1] Received unknown topic or partition error in fetch for partition task-product-0
2023-12-01 16:29:52.828 WARN  ---- [er#1-0-C-1] [NetworkClient:1103] handleSuccessfulResponse   [Consumer clientId=consumer-task.product.v1-3, groupId=task.product.v1] Error while fetching metadata with correlation id 301 : {task-product=LEADER_NOT_AVAILABLE}
2023-12-01 16:29:52.829 INFO  ---- [er#1-0-C-1] [ConsumerCoordinator:1000] requestRejoin   [Consumer clientId=consumer-task.product.v1-3, groupId=task.product.v1] Request joining group due to: cached metadata has changed from (version5: {task-product=1}) at the beginning of the rebalance to (version6: {})
2023-12-01 16:29:52.830 INFO  ---- [er#1-0-C-1] [ConsumerCoordinator:311] invokePartitionsRevoked   [Consumer clientId=consumer-task.product.v1-3, groupId=task.product.v1] Revoke previously assigned partitions task-product-0
2023-12-01 16:29:52.831 INFO  ---- [er#1-0-C-1] [KafkaMessageListenerContainer:292] info   task.product.v1: partitions revoked: [task-product-0]
2023-12-01 16:29:52.831 INFO  ---- [er#1-0-C-1] [ConsumerCoordinator:535] sendJoinGroupRequest   [Consumer clientId=consumer-task.product.v1-3, groupId=task.product.v1] (Re-)joining group
2023-12-01 16:29:52.837 INFO  ---- [er#1-0-C-1] [ConsumerCoordinator:595] handle   [Consumer clientId=consumer-task.product.v1-3, groupId=task.product.v1] Successfully joined group with generation Generation{generationId=63, memberId='consumer-task.product.v1-3-992c556b-f5df-4e34-a2fb-740733f73b1a', protocol='range'}
2023-12-01 16:29:52.952 WARN  ---- [er#1-0-C-1] [NetworkClient:1103] handleSuccessfulResponse   [Consumer clientId=consumer-task.product.v1-3, groupId=task.product.v1] Error while fetching metadata with correlation id 303 : {task-product=LEADER_NOT_AVAILABLE}
2023-12-01 16:29:52.953 INFO  ---- [er#1-0-C-1] [ConsumerCoordinator:659] performAssignment   [Consumer clientId=consumer-task.product.v1-3, groupId=task.product.v1] Finished assignment for group at generation 63: {consumer-task.product.v1-3-992c556b-f5df-4e34-a2fb-740733f73b1a=Assignment(partitions=[])}
2023-12-01 16:29:52.959 INFO  ---- [er#1-0-C-1] [ConsumerCoordinator:761] handle   [Consumer clientId=consumer-task.product.v1-3, groupId=task.product.v1] Successfully synced group in generation Generation{generationId=63, memberId='consumer-task.product.v1-3-992c556b-f5df-4e34-a2fb-740733f73b1a', protocol='range'}
2023-12-01 16:29:52.959 INFO  ---- [er#1-0-C-1] [ConsumerCoordinator:280] invokeOnAssignment   [Consumer clientId=consumer-task.product.v1-3, groupId=task.product.v1] Notifying assignor about the new Assignment(partitions=[])
2023-12-01 16:29:52.960 INFO  ---- [er#1-0-C-1] [ConsumerCoordinator:292] invokePartitionsAssigned   [Consumer clientId=consumer-task.product.v1-3, groupId=task.product.v1] Adding newly assigned partitions: 
2023-12-01 16:29:52.960 INFO  ---- [er#1-0-C-1] [KafkaMessageListenerContainer:292] info   task.product.v1: partitions assigned: []
2023-12-01 16:29:53.061 INFO  ---- [er#1-0-C-1] [Metadata:402] updateLatestMetadata   [Consumer clientId=consumer-task.product.v1-3, groupId=task.product.v1] Resetting the last seen epoch of partition task-product-0 to 0 since the associated topicId changed from null to TAUf9LHxSDOR-6F1IE3QDw
2023-12-01 16:29:53.062 INFO  ---- [er#1-0-C-1] [ConsumerCoordinator:1000] requestRejoin   [Consumer clientId=consumer-task.product.v1-3, groupId=task.product.v1] Request joining group due to: cached metadata has changed from (version7: {}) at the beginning of the rebalance to (version8: {task-product=1})
2023-12-01 16:29:53.062 INFO  ---- [er#1-0-C-1] [ConsumerCoordinator:311] invokePartitionsRevoked   [Consumer clientId=consumer-task.product.v1-3, groupId=task.product.v1] Revoke previously assigned partitions 
2023-12-01 16:29:53.063 INFO  ---- [er#1-0-C-1] [KafkaMessageListenerContainer:292] info   task.product.v1: partitions revoked: []
2023-12-01 16:29:53.063 INFO  ---- [er#1-0-C-1] [ConsumerCoordinator:535] sendJoinGroupRequest   [Consumer clientId=consumer-task.product.v1-3, groupId=task.product.v1] (Re-)joining group
2023-12-01 16:29:53.068 INFO  ---- [er#1-0-C-1] [ConsumerCoordinator:595] handle   [Consumer clientId=consumer-task.product.v1-3, groupId=task.product.v1] Successfully joined group with generation Generation{generationId=64, memberId='consumer-task.product.v1-3-992c556b-f5df-4e34-a2fb-740733f73b1a', protocol='range'}
2023-12-01 16:29:53.068 INFO  ---- [er#1-0-C-1] [ConsumerCoordinator:659] performAssignment   [Consumer clientId=consumer-task.product.v1-3, groupId=task.product.v1] Finished assignment for group at generation 64: {consumer-task.product.v1-3-992c556b-f5df-4e34-a2fb-740733f73b1a=Assignment(partitions=[task-product-0])}
2023-12-01 16:29:53.071 INFO  ---- [er#1-0-C-1] [ConsumerCoordinator:761] handle   [Consumer clientId=consumer-task.product.v1-3, groupId=task.product.v1] Successfully synced group in generation Generation{generationId=64, memberId='consumer-task.product.v1-3-992c556b-f5df-4e34-a2fb-740733f73b1a', protocol='range'}
2023-12-01 16:29:53.072 INFO  ---- [er#1-0-C-1] [ConsumerCoordinator:280] invokeOnAssignment   [Consumer clientId=consumer-task.product.v1-3, groupId=task.product.v1] Notifying assignor about the new Assignment(partitions=[task-product-0])
2023-12-01 16:29:53.072 INFO  ---- [er#1-0-C-1] [ConsumerCoordinator:292] invokePartitionsAssigned   [Consumer clientId=consumer-task.product.v1-3, groupId=task.product.v1] Adding newly assigned partitions: task-product-0
2023-12-01 16:29:53.073 INFO  ---- [er#1-0-C-1] [ConsumerCoordinator:1405] handle   [Consumer clientId=consumer-task.product.v1-3, groupId=task.product.v1] Found no committed offset for partition task-product-0
2023-12-01 16:29:53.075 INFO  ---- [er#1-0-C-1] [ConsumerCoordinator:1405] handle   [Consumer clientId=consumer-task.product.v1-3, groupId=task.product.v1] Found no committed offset for partition task-product-0
2023-12-01 16:29:53.092 INFO  ---- [er#1-0-C-1] [SubscriptionState:398] maybeSeekUnvalidated   [Consumer clientId=consumer-task.product.v1-3, groupId=task.product.v1] Resetting offset for partition task-product-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[127.0.0.1:9092 (id: 2 rack: null)], epoch=0}}.
2023-12-01 16:29:53.094 INFO  ---- [er#1-0-C-1] [KafkaMessageListenerContainer:292] info   task.product.v1: partitions assigned: [task-product-0]
2023-12-01 16:30:09.848 WARN  ---- [er#1-0-C-1] [Fetcher:1353] initializeCompletedFetch   [Consumer clientId=consumer-task.product.v1-3, groupId=task.product.v1] Received unknown topic or partition error in fetch for partition task-product-0
2023-12-01 16:30:09.854 WARN  ---- [er#1-0-C-1] [Fetcher:1353] initializeCompletedFetch   [Consumer clientId=consumer-task.product.v1-3, groupId=task.product.v1] Received unknown topic or partition error in fetch for partition task-product-0
2023-12-01 16:30:09.855 WARN  ---- [er#1-0-C-1] [NetworkClient:1103] handleSuccessfulResponse   [Consumer clientId=consumer-task.product.v1-3, groupId=task.product.v1] Error while fetching metadata with correlation id 353 : {task-product=LEADER_NOT_AVAILABLE}
2023-12-01 16:30:09.855 INFO  ---- [er#1-0-C-1] [ConsumerCoordinator:1000] requestRejoin   [Consumer clientId=consumer-task.product.v1-3, groupId=task.product.v1] Request joining group due to: cached metadata has changed from (version8: {task-product=1}) at the beginning of the rebalance to (version9: {})
2023-12-01 16:30:09.855 INFO  ---- [er#1-0-C-1] [ConsumerCoordinator:311] invokePartitionsRevoked   [Consumer clientId=consumer-task.product.v1-3, groupId=task.product.v1] Revoke previously assigned partitions task-product-0
2023-12-01 16:30:09.856 INFO  ---- [er#1-0-C-1] [KafkaMessageListenerContainer:292] info   task.product.v1: partitions revoked: [task-product-0]
2023-12-01 16:30:09.856 INFO  ---- [er#1-0-C-1] [ConsumerCoordinator:535] sendJoinGroupRequest   [Consumer clientId=consumer-task.product.v1-3, groupId=task.product.v1] (Re-)joining group
2023-12-01 16:30:09.860 INFO  ---- [er#1-0-C-1] [ConsumerCoordinator:595] handle   [Consumer clientId=consumer-task.product.v1-3, groupId=task.product.v1] Successfully joined group with generation Generation{generationId=65, memberId='consumer-task.product.v1-3-992c556b-f5df-4e34-a2fb-740733f73b1a', protocol='range'}
2023-12-01 16:30:10.037 WARN  ---- [er#1-0-C-1] [NetworkClient:1103] handleSuccessfulResponse   [Consumer clientId=consumer-task.product.v1-3, groupId=task.product.v1] Error while fetching metadata with correlation id 356 : {task-product=LEADER_NOT_AVAILABLE}
2023-12-01 16:30:10.038 INFO  ---- [er#1-0-C-1] [ConsumerCoordinator:659] performAssignment   [Consumer clientId=consumer-task.product.v1-3, groupId=task.product.v1] Finished assignment for group at generation 65: {consumer-task.product.v1-3-992c556b-f5df-4e34-a2fb-740733f73b1a=Assignment(partitions=[])}
2023-12-01 16:30:10.042 INFO  ---- [er#1-0-C-1] [ConsumerCoordinator:761] handle   [Consumer clientId=consumer-task.product.v1-3, groupId=task.product.v1] Successfully synced group in generation Generation{generationId=65, memberId='consumer-task.product.v1-3-992c556b-f5df-4e34-a2fb-740733f73b1a', protocol='range'}
2023-12-01 16:30:10.042 INFO  ---- [er#1-0-C-1] [ConsumerCoordinator:280] invokeOnAssignment   [Consumer clientId=consumer-task.product.v1-3, groupId=task.product.v1] Notifying assignor about the new Assignment(partitions=[])
2023-12-01 16:30:10.042 INFO  ---- [er#1-0-C-1] [ConsumerCoordinator:292] invokePartitionsAssigned   [Consumer clientId=consumer-task.product.v1-3, groupId=task.product.v1] Adding newly assigned partitions: 
2023-12-01 16:30:10.043 INFO  ---- [er#1-0-C-1] [KafkaMessageListenerContainer:292] info   task.product.v1: partitions assigned: []
2023-12-01 16:30:10.153 INFO  ---- [er#1-0-C-1] [Metadata:402] updateLatestMetadata   [Consumer clientId=consumer-task.product.v1-3, groupId=task.product.v1] Resetting the last seen epoch of partition task-product-0 to 0 since the associated topicId changed from null to rHudGKrvRLmT364TNKf0rA
2023-12-01 16:30:10.154 INFO  ---- [er#1-0-C-1] [ConsumerCoordinator:1000] requestRejoin   [Consumer clientId=consumer-task.product.v1-3, groupId=task.product.v1] Request joining group due to: cached metadata has changed from (version10: {}) at the beginning of the rebalance to (version11: {task-product=1})
2023-12-01 16:30:10.154 INFO  ---- [er#1-0-C-1] [ConsumerCoordinator:311] invokePartitionsRevoked   [Consumer clientId=consumer-task.product.v1-3, groupId=task.product.v1] Revoke previously assigned partitions 
2023-12-01 16:30:10.154 INFO  ---- [er#1-0-C-1] [KafkaMessageListenerContainer:292] info   task.product.v1: partitions revoked: []
2023-12-01 16:30:10.155 INFO  ---- [er#1-0-C-1] [ConsumerCoordinator:535] sendJoinGroupRequest   [Consumer clientId=consumer-task.product.v1-3, groupId=task.product.v1] (Re-)joining group
2023-12-01 16:30:10.158 INFO  ---- [er#1-0-C-1] [ConsumerCoordinator:595] handle   [Consumer clientId=consumer-task.product.v1-3, groupId=task.product.v1] Successfully joined group with generation Generation{generationId=66, memberId='consumer-task.product.v1-3-992c556b-f5df-4e34-a2fb-740733f73b1a', protocol='range'}
2023-12-01 16:30:10.159 INFO  ---- [er#1-0-C-1] [ConsumerCoordinator:659] performAssignment   [Consumer clientId=consumer-task.product.v1-3, groupId=task.product.v1] Finished assignment for group at generation 66: {consumer-task.product.v1-3-992c556b-f5df-4e34-a2fb-740733f73b1a=Assignment(partitions=[task-product-0])}
2023-12-01 16:30:10.162 INFO  ---- [er#1-0-C-1] [ConsumerCoordinator:761] handle   [Consumer clientId=consumer-task.product.v1-3, groupId=task.product.v1] Successfully synced group in generation Generation{generationId=66, memberId='consumer-task.product.v1-3-992c556b-f5df-4e34-a2fb-740733f73b1a', protocol='range'}
2023-12-01 16:30:10.163 INFO  ---- [er#1-0-C-1] [ConsumerCoordinator:280] invokeOnAssignment   [Consumer clientId=consumer-task.product.v1-3, groupId=task.product.v1] Notifying assignor about the new Assignment(partitions=[task-product-0])
2023-12-01 16:30:10.163 INFO  ---- [er#1-0-C-1] [ConsumerCoordinator:292] invokePartitionsAssigned   [Consumer clientId=consumer-task.product.v1-3, groupId=task.product.v1] Adding newly assigned partitions: task-product-0
2023-12-01 16:30:10.166 INFO  ---- [er#1-0-C-1] [ConsumerCoordinator:1405] handle   [Consumer clientId=consumer-task.product.v1-3, groupId=task.product.v1] Found no committed offset for partition task-product-0
2023-12-01 16:30:10.168 INFO  ---- [er#1-0-C-1] [ConsumerCoordinator:1405] handle   [Consumer clientId=consumer-task.product.v1-3, groupId=task.product.v1] Found no committed offset for partition task-product-0
2023-12-01 16:30:10.172 INFO  ---- [er#1-0-C-1] [SubscriptionState:398] maybeSeekUnvalidated   [Consumer clientId=consumer-task.product.v1-3, groupId=task.product.v1] Resetting offset for partition task-product-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[127.0.0.1:9093 (id: 3 rack: null)], epoch=0}}.
2023-12-01 16:30:10.175 INFO  ---- [er#1-0-C-1] [KafkaMessageListenerContainer:292] info   task.product.v1: partitions assigned: [task-product-0]
2023-12-01 16:30:24.647 WARN  ---- [er#1-0-C-1] [Fetcher:1353] initializeCompletedFetch   [Consumer clientId=consumer-task.product.v1-3, groupId=task.product.v1] Received unknown topic or partition error in fetch for partition task-product-0
2023-12-01 16:30:24.654 WARN  ---- [er#1-0-C-1] [Fetcher:1353] initializeCompletedFetch   [Consumer clientId=consumer-task.product.v1-3, groupId=task.product.v1] Received unknown topic or partition error in fetch for partition task-product-0
2023-12-01 16:30:24.656 WARN  ---- [er#1-0-C-1] [NetworkClient:1103] handleSuccessfulResponse   [Consumer clientId=consumer-task.product.v1-3, groupId=task.product.v1] Error while fetching metadata with correlation id 400 : {task-product=LEADER_NOT_AVAILABLE}
2023-12-01 16:30:24.656 INFO  ---- [er#1-0-C-1] [ConsumerCoordinator:1000] requestRejoin   [Consumer clientId=consumer-task.product.v1-3, groupId=task.product.v1] Request joining group due to: cached metadata has changed from (version11: {task-product=1}) at the beginning of the rebalance to (version12: {})
2023-12-01 16:30:24.657 INFO  ---- [er#1-0-C-1] [ConsumerCoordinator:311] invokePartitionsRevoked   [Consumer clientId=consumer-task.product.v1-3, groupId=task.product.v1] Revoke previously assigned partitions task-product-0
2023-12-01 16:30:24.657 INFO  ---- [er#1-0-C-1] [KafkaMessageListenerContainer:292] info   task.product.v1: partitions revoked: [task-product-0]
2023-12-01 16:30:24.657 INFO  ---- [er#1-0-C-1] [ConsumerCoordinator:535] sendJoinGroupRequest   [Consumer clientId=consumer-task.product.v1-3, groupId=task.product.v1] (Re-)joining group
2023-12-01 16:30:24.661 INFO  ---- [er#1-0-C-1] [ConsumerCoordinator:595] handle   [Consumer clientId=consumer-task.product.v1-3, groupId=task.product.v1] Successfully joined group with generation Generation{generationId=67, memberId='consumer-task.product.v1-3-992c556b-f5df-4e34-a2fb-740733f73b1a', protocol='range'}
2023-12-01 16:30:24.776 WARN  ---- [er#1-0-C-1] [NetworkClient:1103] handleSuccessfulResponse   [Consumer clientId=consumer-task.product.v1-3, groupId=task.product.v1] Error while fetching metadata with correlation id 403 : {task-product=LEADER_NOT_AVAILABLE}
2023-12-01 16:30:24.777 INFO  ---- [er#1-0-C-1] [ConsumerCoordinator:659] performAssignment   [Consumer clientId=consumer-task.product.v1-3, groupId=task.product.v1] Finished assignment for group at generation 67: {consumer-task.product.v1-3-992c556b-f5df-4e34-a2fb-740733f73b1a=Assignment(partitions=[])}
2023-12-01 16:30:24.783 INFO  ---- [er#1-0-C-1] [ConsumerCoordinator:761] handle   [Consumer clientId=consumer-task.product.v1-3, groupId=task.product.v1] Successfully synced group in generation Generation{generationId=67, memberId='consumer-task.product.v1-3-992c556b-f5df-4e34-a2fb-740733f73b1a', protocol='range'}
2023-12-01 16:30:24.783 INFO  ---- [er#1-0-C-1] [ConsumerCoordinator:280] invokeOnAssignment   [Consumer clientId=consumer-task.product.v1-3, groupId=task.product.v1] Notifying assignor about the new Assignment(partitions=[])
2023-12-01 16:30:24.784 INFO  ---- [er#1-0-C-1] [ConsumerCoordinator:292] invokePartitionsAssigned   [Consumer clientId=consumer-task.product.v1-3, groupId=task.product.v1] Adding newly assigned partitions: 
2023-12-01 16:30:24.784 INFO  ---- [er#1-0-C-1] [KafkaMessageListenerContainer:292] info   task.product.v1: partitions assigned: []
2023-12-01 16:30:24.886 INFO  ---- [er#1-0-C-1] [Metadata:402] updateLatestMetadata   [Consumer clientId=consumer-task.product.v1-3, groupId=task.product.v1] Resetting the last seen epoch of partition task-product-0 to 0 since the associated topicId changed from null to _ifMVhFvQty4tsfuyBDoPg
2023-12-01 16:30:24.887 INFO  ---- [er#1-0-C-1] [ConsumerCoordinator:1000] requestRejoin   [Consumer clientId=consumer-task.product.v1-3, groupId=task.product.v1] Request joining group due to: cached metadata has changed from (version13: {}) at the beginning of the rebalance to (version14: {task-product=1})
2023-12-01 16:30:24.887 INFO  ---- [er#1-0-C-1] [ConsumerCoordinator:311] invokePartitionsRevoked   [Consumer clientId=consumer-task.product.v1-3, groupId=task.product.v1] Revoke previously assigned partitions 
2023-12-01 16:30:24.887 INFO  ---- [er#1-0-C-1] [KafkaMessageListenerContainer:292] info   task.product.v1: partitions revoked: []
2023-12-01 16:30:24.888 INFO  ---- [er#1-0-C-1] [ConsumerCoordinator:535] sendJoinGroupRequest   [Consumer clientId=consumer-task.product.v1-3, groupId=task.product.v1] (Re-)joining group
2023-12-01 16:30:24.891 INFO  ---- [er#1-0-C-1] [ConsumerCoordinator:595] handle   [Consumer clientId=consumer-task.product.v1-3, groupId=task.product.v1] Successfully joined group with generation Generation{generationId=68, memberId='consumer-task.product.v1-3-992c556b-f5df-4e34-a2fb-740733f73b1a', protocol='range'}
2023-12-01 16:30:24.892 INFO  ---- [er#1-0-C-1] [ConsumerCoordinator:659] performAssignment   [Consumer clientId=consumer-task.product.v1-3, groupId=task.product.v1] Finished assignment for group at generation 68: {consumer-task.product.v1-3-992c556b-f5df-4e34-a2fb-740733f73b1a=Assignment(partitions=[task-product-0])}
2023-12-01 16:30:24.896 INFO  ---- [er#1-0-C-1] [ConsumerCoordinator:761] handle   [Consumer clientId=consumer-task.product.v1-3, groupId=task.product.v1] Successfully synced group in generation Generation{generationId=68, memberId='consumer-task.product.v1-3-992c556b-f5df-4e34-a2fb-740733f73b1a', protocol='range'}
2023-12-01 16:30:24.896 INFO  ---- [er#1-0-C-1] [ConsumerCoordinator:280] invokeOnAssignment   [Consumer clientId=consumer-task.product.v1-3, groupId=task.product.v1] Notifying assignor about the new Assignment(partitions=[task-product-0])
2023-12-01 16:30:24.896 INFO  ---- [er#1-0-C-1] [ConsumerCoordinator:292] invokePartitionsAssigned   [Consumer clientId=consumer-task.product.v1-3, groupId=task.product.v1] Adding newly assigned partitions: task-product-0
2023-12-01 16:30:24.898 INFO  ---- [er#1-0-C-1] [ConsumerCoordinator:1405] handle   [Consumer clientId=consumer-task.product.v1-3, groupId=task.product.v1] Found no committed offset for partition task-product-0
2023-12-01 16:30:24.900 INFO  ---- [er#1-0-C-1] [ConsumerCoordinator:1405] handle   [Consumer clientId=consumer-task.product.v1-3, groupId=task.product.v1] Found no committed offset for partition task-product-0
2023-12-01 16:30:24.902 INFO  ---- [er#1-0-C-1] [SubscriptionState:398] maybeSeekUnvalidated   [Consumer clientId=consumer-task.product.v1-3, groupId=task.product.v1] Resetting offset for partition task-product-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[127.0.0.1:9091 (id: 1 rack: null)], epoch=0}}.
2023-12-01 16:30:24.905 INFO  ---- [er#1-0-C-1] [KafkaMessageListenerContainer:292] info   task.product.v1: partitions assigned: [task-product-0]
2023-12-01 16:30:30.208 WARN  ---- [er#1-0-C-1] [Fetcher:1353] initializeCompletedFetch   [Consumer clientId=consumer-task.product.v1-3, groupId=task.product.v1] Received unknown topic or partition error in fetch for partition task-product-0
2023-12-01 16:30:30.218 WARN  ---- [er#1-0-C-1] [NetworkClient:1103] handleSuccessfulResponse   [Consumer clientId=consumer-task.product.v1-3, groupId=task.product.v1] Error while fetching metadata with correlation id 425 : {task-product=LEADER_NOT_AVAILABLE}
2023-12-01 16:30:30.219 INFO  ---- [er#1-0-C-1] [ConsumerCoordinator:1000] requestRejoin   [Consumer clientId=consumer-task.product.v1-3, groupId=task.product.v1] Request joining group due to: cached metadata has changed from (version14: {task-product=1}) at the beginning of the rebalance to (version15: {})
2023-12-01 16:30:30.219 INFO  ---- [er#1-0-C-1] [ConsumerCoordinator:311] invokePartitionsRevoked   [Consumer clientId=consumer-task.product.v1-3, groupId=task.product.v1] Revoke previously assigned partitions task-product-0
2023-12-01 16:30:30.219 INFO  ---- [er#1-0-C-1] [KafkaMessageListenerContainer:292] info   task.product.v1: partitions revoked: [task-product-0]
2023-12-01 16:30:30.220 INFO  ---- [er#1-0-C-1] [ConsumerCoordinator:535] sendJoinGroupRequest   [Consumer clientId=consumer-task.product.v1-3, groupId=task.product.v1] (Re-)joining group
2023-12-01 16:30:30.223 INFO  ---- [er#1-0-C-1] [ConsumerCoordinator:595] handle   [Consumer clientId=consumer-task.product.v1-3, groupId=task.product.v1] Successfully joined group with generation Generation{generationId=69, memberId='consumer-task.product.v1-3-992c556b-f5df-4e34-a2fb-740733f73b1a', protocol='range'}
2023-12-01 16:30:30.423 WARN  ---- [er#1-0-C-1] [NetworkClient:1103] handleSuccessfulResponse   [Consumer clientId=consumer-task.product.v1-3, groupId=task.product.v1] Error while fetching metadata with correlation id 427 : {task-product=LEADER_NOT_AVAILABLE}
2023-12-01 16:30:30.425 INFO  ---- [er#1-0-C-1] [ConsumerCoordinator:659] performAssignment   [Consumer clientId=consumer-task.product.v1-3, groupId=task.product.v1] Finished assignment for group at generation 69: {consumer-task.product.v1-3-992c556b-f5df-4e34-a2fb-740733f73b1a=Assignment(partitions=[])}
2023-12-01 16:30:30.429 INFO  ---- [er#1-0-C-1] [ConsumerCoordinator:761] handle   [Consumer clientId=consumer-task.product.v1-3, groupId=task.product.v1] Successfully synced group in generation Generation{generationId=69, memberId='consumer-task.product.v1-3-992c556b-f5df-4e34-a2fb-740733f73b1a', protocol='range'}
2023-12-01 16:30:30.430 INFO  ---- [er#1-0-C-1] [ConsumerCoordinator:280] invokeOnAssignment   [Consumer clientId=consumer-task.product.v1-3, groupId=task.product.v1] Notifying assignor about the new Assignment(partitions=[])
2023-12-01 16:30:30.430 INFO  ---- [er#1-0-C-1] [ConsumerCoordinator:292] invokePartitionsAssigned   [Consumer clientId=consumer-task.product.v1-3, groupId=task.product.v1] Adding newly assigned partitions: 
2023-12-01 16:30:30.430 INFO  ---- [er#1-0-C-1] [KafkaMessageListenerContainer:292] info   task.product.v1: partitions assigned: []
2023-12-01 16:30:30.538 INFO  ---- [er#1-0-C-1] [Metadata:402] updateLatestMetadata   [Consumer clientId=consumer-task.product.v1-3, groupId=task.product.v1] Resetting the last seen epoch of partition task-product-0 to 0 since the associated topicId changed from null to mXg2zMDGSq-hNx39fVasjw
2023-12-01 16:30:30.538 INFO  ---- [er#1-0-C-1] [ConsumerCoordinator:1000] requestRejoin   [Consumer clientId=consumer-task.product.v1-3, groupId=task.product.v1] Request joining group due to: cached metadata has changed from (version16: {}) at the beginning of the rebalance to (version17: {task-product=1})
2023-12-01 16:30:30.538 INFO  ---- [er#1-0-C-1] [ConsumerCoordinator:311] invokePartitionsRevoked   [Consumer clientId=consumer-task.product.v1-3, groupId=task.product.v1] Revoke previously assigned partitions 
2023-12-01 16:30:30.539 INFO  ---- [er#1-0-C-1] [KafkaMessageListenerContainer:292] info   task.product.v1: partitions revoked: []
2023-12-01 16:30:30.539 INFO  ---- [er#1-0-C-1] [ConsumerCoordinator:535] sendJoinGroupRequest   [Consumer clientId=consumer-task.product.v1-3, groupId=task.product.v1] (Re-)joining group
2023-12-01 16:30:30.541 INFO  ---- [er#1-0-C-1] [ConsumerCoordinator:595] handle   [Consumer clientId=consumer-task.product.v1-3, groupId=task.product.v1] Successfully joined group with generation Generation{generationId=70, memberId='consumer-task.product.v1-3-992c556b-f5df-4e34-a2fb-740733f73b1a', protocol='range'}
2023-12-01 16:30:30.541 INFO  ---- [er#1-0-C-1] [ConsumerCoordinator:659] performAssignment   [Consumer clientId=consumer-task.product.v1-3, groupId=task.product.v1] Finished assignment for group at generation 70: {consumer-task.product.v1-3-992c556b-f5df-4e34-a2fb-740733f73b1a=Assignment(partitions=[task-product-0])}
2023-12-01 16:30:30.544 INFO  ---- [er#1-0-C-1] [ConsumerCoordinator:761] handle   [Consumer clientId=consumer-task.product.v1-3, groupId=task.product.v1] Successfully synced group in generation Generation{generationId=70, memberId='consumer-task.product.v1-3-992c556b-f5df-4e34-a2fb-740733f73b1a', protocol='range'}
2023-12-01 16:30:30.544 INFO  ---- [er#1-0-C-1] [ConsumerCoordinator:280] invokeOnAssignment   [Consumer clientId=consumer-task.product.v1-3, groupId=task.product.v1] Notifying assignor about the new Assignment(partitions=[task-product-0])
2023-12-01 16:30:30.544 INFO  ---- [er#1-0-C-1] [ConsumerCoordinator:292] invokePartitionsAssigned   [Consumer clientId=consumer-task.product.v1-3, groupId=task.product.v1] Adding newly assigned partitions: task-product-0
2023-12-01 16:30:30.547 INFO  ---- [er#1-0-C-1] [ConsumerCoordinator:1405] handle   [Consumer clientId=consumer-task.product.v1-3, groupId=task.product.v1] Found no committed offset for partition task-product-0
2023-12-01 16:30:30.549 INFO  ---- [er#1-0-C-1] [ConsumerCoordinator:1405] handle   [Consumer clientId=consumer-task.product.v1-3, groupId=task.product.v1] Found no committed offset for partition task-product-0
2023-12-01 16:30:30.551 INFO  ---- [er#1-0-C-1] [SubscriptionState:398] maybeSeekUnvalidated   [Consumer clientId=consumer-task.product.v1-3, groupId=task.product.v1] Resetting offset for partition task-product-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[127.0.0.1:9093 (id: 3 rack: null)], epoch=0}}.
2023-12-01 16:30:30.565 INFO  ---- [er#1-0-C-1] [KafkaMessageListenerContainer:292] info   task.product.v1: partitions assigned: [task-product-0]
2023-12-01 16:31:37.439 INFO  ---- [tartedMain] [TaskConsumerApplication:55] logStarting   Starting TaskConsumerApplication using Java 11.0.13 on DESKTOP-MNMB87E with PID 15388 (C:\Users\tkdrb\IdeaProjects\ecommerce\task-consumer\build\classes\java\main started by tkdrb in C:\Users\tkdrb\IdeaProjects\ecommerce\task-consumer)
2023-12-01 16:31:37.448 INFO  ---- [tartedMain] [TaskConsumerApplication:631] logStartupProfileInfo   No active profile set, falling back to 1 default profile: "default"
2023-12-01 16:31:37.556 INFO  ---- [tartedMain] [DevToolsPropertyDefaultsPostProcessor:255] logTo   Devtools property defaults active! Set 'spring.devtools.add-properties' to 'false' to disable
2023-12-01 16:31:37.557 INFO  ---- [tartedMain] [DevToolsPropertyDefaultsPostProcessor:255] logTo   For additional web related logging consider setting the 'logging.level.web' property to 'DEBUG'
2023-12-01 16:31:39.219 INFO  ---- [tartedMain] [GenericScope:283] setSerializationId   BeanFactory id=7d336d03-7948-373b-80b2-3edd326128fe
2023-12-01 16:31:40.558 INFO  ---- [tartedMain] [TomcatWebServer:108] initialize   Tomcat initialized with port(s): 0 (http)
2023-12-01 16:31:40.574 INFO  ---- [tartedMain] [StandardService:173] log   Starting service [Tomcat]
2023-12-01 16:31:40.575 INFO  ---- [tartedMain] [StandardEngine:173] log   Starting Servlet engine: [Apache Tomcat/9.0.76]
2023-12-01 16:31:40.844 INFO  ---- [tartedMain] [[/]:173] log   Initializing Spring embedded WebApplicationContext
2023-12-01 16:31:40.845 INFO  ---- [tartedMain] [ServletWebServerApplicationContext:292] prepareWebApplicationContext   Root WebApplicationContext: initialization completed in 3287 ms
2023-12-01 16:31:41.906 WARN  ---- [tartedMain] [OptionalLiveReloadServer:62] startServer   Unable to start LiveReload server
2023-12-01 16:31:43.194 INFO  ---- [tartedMain] [DiscoveryClientOptionalArgsConfiguration:71] restTemplateDiscoveryClientOptionalArgs   Eureka HTTP Client uses RestTemplate.
2023-12-01 16:31:44.430 WARN  ---- [tartedMain] [LoadBalancerCacheAutoConfiguration$LoadBalancerCaffeineWarnLogger:83] logWarning   Spring Cloud LoadBalancer is currently working with the default cache. While this cache implementation is useful for development and tests, it's recommended to use Caffeine cache in production.You can switch to using Caffeine cache, by adding it and org.springframework.cache.caffeine.CaffeineCacheManager to the classpath.
2023-12-01 16:31:44.557 INFO  ---- [tartedMain] [ConsumerConfig:376] logAll   ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-order.group.v1-1
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = order.group.v1
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2023-12-01 16:31:44.754 INFO  ---- [tartedMain] [AppInfoParser:119] <init>   Kafka version: 3.1.2
2023-12-01 16:31:44.759 INFO  ---- [tartedMain] [AppInfoParser:120] <init>   Kafka commitId: f8c67dc3ae0a3265
2023-12-01 16:31:44.760 INFO  ---- [tartedMain] [AppInfoParser:121] <init>   Kafka startTimeMs: 1701415904752
2023-12-01 16:31:44.766 INFO  ---- [tartedMain] [KafkaConsumer:966] subscribe   [Consumer clientId=consumer-order.group.v1-1, groupId=order.group.v1] Subscribed to topic(s): order
2023-12-01 16:31:44.797 INFO  ---- [tartedMain] [ConsumerConfig:376] logAll   ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-task.product.v1-2
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = task.product.v1
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2023-12-01 16:31:44.806 INFO  ---- [tartedMain] [AppInfoParser:119] <init>   Kafka version: 3.1.2
2023-12-01 16:31:44.807 INFO  ---- [tartedMain] [AppInfoParser:120] <init>   Kafka commitId: f8c67dc3ae0a3265
2023-12-01 16:31:44.807 INFO  ---- [tartedMain] [AppInfoParser:121] <init>   Kafka startTimeMs: 1701415904806
2023-12-01 16:31:44.807 INFO  ---- [tartedMain] [KafkaConsumer:966] subscribe   [Consumer clientId=consumer-task.product.v1-2, groupId=task.product.v1] Subscribed to topic(s): task-product
2023-12-01 16:31:44.822 INFO  ---- [tartedMain] [ConsumerConfig:376] logAll   ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-task.member.v1-3
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = task.member.v1
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2023-12-01 16:31:44.832 INFO  ---- [tartedMain] [AppInfoParser:119] <init>   Kafka version: 3.1.2
2023-12-01 16:31:44.832 INFO  ---- [tartedMain] [AppInfoParser:120] <init>   Kafka commitId: f8c67dc3ae0a3265
2023-12-01 16:31:44.833 INFO  ---- [tartedMain] [AppInfoParser:121] <init>   Kafka startTimeMs: 1701415904832
2023-12-01 16:31:44.833 INFO  ---- [tartedMain] [KafkaConsumer:966] subscribe   [Consumer clientId=consumer-task.member.v1-3, groupId=task.member.v1] Subscribed to topic(s): task-member
2023-12-01 16:31:44.855 INFO  ---- [tartedMain] [TomcatWebServer:220] start   Tomcat started on port(s): 60864 (http) with context path ''
2023-12-01 16:31:44.857 INFO  ---- [tartedMain] [EurekaAutoServiceRegistration:144] onApplicationEvent   Updating port to 60864
2023-12-01 16:31:44.865 INFO  ---- [tartedMain] [InstanceInfoFactory:67] create   Setting initial instance status as: STARTING
2023-12-01 16:31:44.932 INFO  ---- [tartedMain] [DiscoveryClient:372] <init>   Initializing Eureka in region us-east-1
2023-12-01 16:31:44.940 INFO  ---- [tartedMain] [ConfigClusterResolver:43] getClusterEndpoints   Resolving eureka endpoints via configuration
2023-12-01 16:31:44.980 INFO  ---- [tartedMain] [DiscoveryClient:1007] fetchRegistry   Disable delta property : false
2023-12-01 16:31:44.980 INFO  ---- [tartedMain] [DiscoveryClient:1008] fetchRegistry   Single vip registry refresh property : null
2023-12-01 16:31:44.980 INFO  ---- [tartedMain] [DiscoveryClient:1009] fetchRegistry   Force full registry fetch : false
2023-12-01 16:31:44.980 INFO  ---- [tartedMain] [DiscoveryClient:1010] fetchRegistry   Application is null : false
2023-12-01 16:31:44.980 INFO  ---- [tartedMain] [DiscoveryClient:1011] fetchRegistry   Registered Applications size is zero : true
2023-12-01 16:31:44.981 INFO  ---- [tartedMain] [DiscoveryClient:1013] fetchRegistry   Application version is -1: true
2023-12-01 16:31:44.981 INFO  ---- [tartedMain] [DiscoveryClient:1097] getAndStoreFullRegistry   Getting all instance registry info from the eureka server
2023-12-01 16:31:45.337 INFO  ---- [er#1-0-C-1] [Metadata:402] updateLatestMetadata   [Consumer clientId=consumer-task.member.v1-3, groupId=task.member.v1] Resetting the last seen epoch of partition task-member-0 to 9 since the associated topicId changed from null to HvfbkcRhQ3meTIJFgCt9zw
2023-12-01 16:31:45.337 INFO  ---- [er#0-0-C-1] [Metadata:402] updateLatestMetadata   [Consumer clientId=consumer-task.product.v1-2, groupId=task.product.v1] Resetting the last seen epoch of partition task-product-0 to 0 since the associated topicId changed from null to Ta9PbxkNQBelhs_InU2wkQ
2023-12-01 16:31:45.337 INFO  ---- [er#2-0-C-1] [Metadata:402] updateLatestMetadata   [Consumer clientId=consumer-order.group.v1-1, groupId=order.group.v1] Resetting the last seen epoch of partition order-0 to 0 since the associated topicId changed from null to 8AIo0qkzSIiGJbn1bQxAkw
2023-12-01 16:31:45.343 INFO  ---- [er#0-0-C-1] [Metadata:287] update   [Consumer clientId=consumer-task.product.v1-2, groupId=task.product.v1] Cluster ID: 5_U1uds-SGaR4vItj-jqUw
2023-12-01 16:31:45.343 INFO  ---- [er#1-0-C-1] [Metadata:287] update   [Consumer clientId=consumer-task.member.v1-3, groupId=task.member.v1] Cluster ID: 5_U1uds-SGaR4vItj-jqUw
2023-12-01 16:31:45.343 INFO  ---- [er#2-0-C-1] [Metadata:287] update   [Consumer clientId=consumer-order.group.v1-1, groupId=order.group.v1] Cluster ID: 5_U1uds-SGaR4vItj-jqUw
2023-12-01 16:31:45.346 INFO  ---- [er#0-0-C-1] [ConsumerCoordinator:853] onSuccess   [Consumer clientId=consumer-task.product.v1-2, groupId=task.product.v1] Discovered group coordinator 127.0.0.1:9091 (id: 2147483646 rack: null)
2023-12-01 16:31:45.346 INFO  ---- [er#1-0-C-1] [ConsumerCoordinator:853] onSuccess   [Consumer clientId=consumer-task.member.v1-3, groupId=task.member.v1] Discovered group coordinator 127.0.0.1:9093 (id: 2147483644 rack: null)
2023-12-01 16:31:45.346 INFO  ---- [er#2-0-C-1] [ConsumerCoordinator:853] onSuccess   [Consumer clientId=consumer-order.group.v1-1, groupId=order.group.v1] Discovered group coordinator 127.0.0.1:9091 (id: 2147483646 rack: null)
2023-12-01 16:31:45.350 INFO  ---- [er#2-0-C-1] [ConsumerCoordinator:535] sendJoinGroupRequest   [Consumer clientId=consumer-order.group.v1-1, groupId=order.group.v1] (Re-)joining group
2023-12-01 16:31:45.350 INFO  ---- [er#1-0-C-1] [ConsumerCoordinator:535] sendJoinGroupRequest   [Consumer clientId=consumer-task.member.v1-3, groupId=task.member.v1] (Re-)joining group
2023-12-01 16:31:45.350 INFO  ---- [er#0-0-C-1] [ConsumerCoordinator:535] sendJoinGroupRequest   [Consumer clientId=consumer-task.product.v1-2, groupId=task.product.v1] (Re-)joining group
2023-12-01 16:31:45.401 INFO  ---- [er#1-0-C-1] [ConsumerCoordinator:1000] requestRejoin   [Consumer clientId=consumer-task.member.v1-3, groupId=task.member.v1] Request joining group due to: need to re-join with the given member-id
2023-12-01 16:31:45.401 INFO  ---- [er#2-0-C-1] [ConsumerCoordinator:1000] requestRejoin   [Consumer clientId=consumer-order.group.v1-1, groupId=order.group.v1] Request joining group due to: need to re-join with the given member-id
2023-12-01 16:31:45.402 INFO  ---- [er#1-0-C-1] [ConsumerCoordinator:535] sendJoinGroupRequest   [Consumer clientId=consumer-task.member.v1-3, groupId=task.member.v1] (Re-)joining group
2023-12-01 16:31:45.402 INFO  ---- [er#2-0-C-1] [ConsumerCoordinator:535] sendJoinGroupRequest   [Consumer clientId=consumer-order.group.v1-1, groupId=order.group.v1] (Re-)joining group
2023-12-01 16:31:45.404 INFO  ---- [er#0-0-C-1] [ConsumerCoordinator:1000] requestRejoin   [Consumer clientId=consumer-task.product.v1-2, groupId=task.product.v1] Request joining group due to: need to re-join with the given member-id
2023-12-01 16:31:45.405 INFO  ---- [er#0-0-C-1] [ConsumerCoordinator:535] sendJoinGroupRequest   [Consumer clientId=consumer-task.product.v1-2, groupId=task.product.v1] (Re-)joining group
2023-12-01 16:31:45.520 INFO  ---- [tartedMain] [DiscoveryClient:1106] getAndStoreFullRegistry   The response status is 200
2023-12-01 16:31:45.524 INFO  ---- [tartedMain] [DiscoveryClient:1321] initScheduledTasks   Starting heartbeat executor: renew interval is: 30
2023-12-01 16:31:45.528 INFO  ---- [tartedMain] [InstanceInfoReplicator:60] <init>   InstanceInfoReplicator onDemand update allowed rate per min is 4
2023-12-01 16:31:45.536 INFO  ---- [tartedMain] [DiscoveryClient:492] <init>   Discovery Client initialized at timestamp 1701415905534 with initial instances count: 5
2023-12-01 16:31:45.538 INFO  ---- [tartedMain] [EurekaServiceRegistry:41] register   Registering application TASK-SERVICE with eureka with status UP
2023-12-01 16:31:45.539 INFO  ---- [tartedMain] [DiscoveryClient:1352] notify   Saw local status change event StatusChangeEvent [timestamp=1701415905539, current=UP, previous=STARTING]
2023-12-01 16:31:45.547 INFO  ---- [plicator-0] [DiscoveryClient:873] register   DiscoveryClient_TASK-SERVICE/192.168.0.17:5750317851b2def076f868e9b792bc51: registering service...
2023-12-01 16:31:45.605 INFO  ---- [plicator-0] [DiscoveryClient:882] register   DiscoveryClient_TASK-SERVICE/192.168.0.17:5750317851b2def076f868e9b792bc51 - registration status: 204
2023-12-01 16:31:46.985 INFO  ---- [tartedMain] [TaskConsumerApplication:61] logStarted   Started TaskConsumerApplication in 12.91 seconds (JVM running for 14.579)
2023-12-01 16:31:48.413 INFO  ---- [er#0-0-C-1] [ConsumerCoordinator:595] handle   [Consumer clientId=consumer-task.product.v1-2, groupId=task.product.v1] Successfully joined group with generation Generation{generationId=72, memberId='consumer-task.product.v1-2-a4e6b4a4-9b4f-4dbb-8c6e-33167502252e', protocol='range'}
2023-12-01 16:31:48.413 INFO  ---- [er#1-0-C-1] [ConsumerCoordinator:595] handle   [Consumer clientId=consumer-task.member.v1-3, groupId=task.member.v1] Successfully joined group with generation Generation{generationId=60, memberId='consumer-task.member.v1-3-81411944-a0e2-48c7-9839-a4e4478d3eae', protocol='range'}
2023-12-01 16:31:48.414 INFO  ---- [er#2-0-C-1] [ConsumerCoordinator:595] handle   [Consumer clientId=consumer-order.group.v1-1, groupId=order.group.v1] Successfully joined group with generation Generation{generationId=16, memberId='consumer-order.group.v1-1-1daf4cc8-751b-4be4-9585-6c6f447d56e3', protocol='range'}
2023-12-01 16:31:48.417 INFO  ---- [er#2-0-C-1] [ConsumerCoordinator:659] performAssignment   [Consumer clientId=consumer-order.group.v1-1, groupId=order.group.v1] Finished assignment for group at generation 16: {consumer-order.group.v1-1-1daf4cc8-751b-4be4-9585-6c6f447d56e3=Assignment(partitions=[order-0])}
2023-12-01 16:31:48.417 INFO  ---- [er#0-0-C-1] [ConsumerCoordinator:659] performAssignment   [Consumer clientId=consumer-task.product.v1-2, groupId=task.product.v1] Finished assignment for group at generation 72: {consumer-task.product.v1-2-a4e6b4a4-9b4f-4dbb-8c6e-33167502252e=Assignment(partitions=[task-product-0])}
2023-12-01 16:31:48.417 INFO  ---- [er#1-0-C-1] [ConsumerCoordinator:659] performAssignment   [Consumer clientId=consumer-task.member.v1-3, groupId=task.member.v1] Finished assignment for group at generation 60: {consumer-task.member.v1-3-81411944-a0e2-48c7-9839-a4e4478d3eae=Assignment(partitions=[task-member-0])}
2023-12-01 16:31:48.432 INFO  ---- [er#2-0-C-1] [ConsumerCoordinator:761] handle   [Consumer clientId=consumer-order.group.v1-1, groupId=order.group.v1] Successfully synced group in generation Generation{generationId=16, memberId='consumer-order.group.v1-1-1daf4cc8-751b-4be4-9585-6c6f447d56e3', protocol='range'}
2023-12-01 16:31:48.432 INFO  ---- [er#0-0-C-1] [ConsumerCoordinator:761] handle   [Consumer clientId=consumer-task.product.v1-2, groupId=task.product.v1] Successfully synced group in generation Generation{generationId=72, memberId='consumer-task.product.v1-2-a4e6b4a4-9b4f-4dbb-8c6e-33167502252e', protocol='range'}
2023-12-01 16:31:48.433 INFO  ---- [er#2-0-C-1] [ConsumerCoordinator:280] invokeOnAssignment   [Consumer clientId=consumer-order.group.v1-1, groupId=order.group.v1] Notifying assignor about the new Assignment(partitions=[order-0])
2023-12-01 16:31:48.432 INFO  ---- [er#1-0-C-1] [ConsumerCoordinator:761] handle   [Consumer clientId=consumer-task.member.v1-3, groupId=task.member.v1] Successfully synced group in generation Generation{generationId=60, memberId='consumer-task.member.v1-3-81411944-a0e2-48c7-9839-a4e4478d3eae', protocol='range'}
2023-12-01 16:31:48.433 INFO  ---- [er#0-0-C-1] [ConsumerCoordinator:280] invokeOnAssignment   [Consumer clientId=consumer-task.product.v1-2, groupId=task.product.v1] Notifying assignor about the new Assignment(partitions=[task-product-0])
2023-12-01 16:31:48.433 INFO  ---- [er#1-0-C-1] [ConsumerCoordinator:280] invokeOnAssignment   [Consumer clientId=consumer-task.member.v1-3, groupId=task.member.v1] Notifying assignor about the new Assignment(partitions=[task-member-0])
2023-12-01 16:31:48.436 INFO  ---- [er#1-0-C-1] [ConsumerCoordinator:292] invokePartitionsAssigned   [Consumer clientId=consumer-task.member.v1-3, groupId=task.member.v1] Adding newly assigned partitions: task-member-0
2023-12-01 16:31:48.436 INFO  ---- [er#2-0-C-1] [ConsumerCoordinator:292] invokePartitionsAssigned   [Consumer clientId=consumer-order.group.v1-1, groupId=order.group.v1] Adding newly assigned partitions: order-0
2023-12-01 16:31:48.436 INFO  ---- [er#0-0-C-1] [ConsumerCoordinator:292] invokePartitionsAssigned   [Consumer clientId=consumer-task.product.v1-2, groupId=task.product.v1] Adding newly assigned partitions: task-product-0
2023-12-01 16:31:48.449 INFO  ---- [er#0-0-C-1] [ConsumerCoordinator:1405] handle   [Consumer clientId=consumer-task.product.v1-2, groupId=task.product.v1] Found no committed offset for partition task-product-0
2023-12-01 16:31:48.458 INFO  ---- [er#0-0-C-1] [ConsumerCoordinator:1405] handle   [Consumer clientId=consumer-task.product.v1-2, groupId=task.product.v1] Found no committed offset for partition task-product-0
2023-12-01 16:31:48.461 INFO  ---- [er#1-0-C-1] [ConsumerCoordinator:851] refreshCommittedOffsetsIfNeeded   [Consumer clientId=consumer-task.member.v1-3, groupId=task.member.v1] Setting offset for partition task-member-0 to the committed offset FetchPosition{offset=11, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[127.0.0.1:9091 (id: 1 rack: null)], epoch=9}}
2023-12-01 16:31:48.461 INFO  ---- [er#2-0-C-1] [ConsumerCoordinator:851] refreshCommittedOffsetsIfNeeded   [Consumer clientId=consumer-order.group.v1-1, groupId=order.group.v1] Setting offset for partition order-0 to the committed offset FetchPosition{offset=6, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[127.0.0.1:9092 (id: 2 rack: null)], epoch=0}}
2023-12-01 16:31:48.462 INFO  ---- [er#2-0-C-1] [KafkaMessageListenerContainer:292] info   order.group.v1: partitions assigned: [order-0]
2023-12-01 16:31:48.462 INFO  ---- [er#1-0-C-1] [KafkaMessageListenerContainer:292] info   task.member.v1: partitions assigned: [task-member-0]
2023-12-01 16:31:48.481 INFO  ---- [er#0-0-C-1] [SubscriptionState:398] maybeSeekUnvalidated   [Consumer clientId=consumer-task.product.v1-2, groupId=task.product.v1] Resetting offset for partition task-product-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[127.0.0.1:9093 (id: 3 rack: null)], epoch=0}}.
2023-12-01 16:31:48.494 INFO  ---- [er#0-0-C-1] [KafkaMessageListenerContainer:292] info   task.product.v1: partitions assigned: [task-product-0]
2023-12-01 16:31:48.566 INFO  ---- [er#2-0-C-1] [ProducerConfig:376] logAll   ProducerConfig values: 
	acks = -1
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-1
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2023-12-01 16:31:48.576 INFO  ---- [er#2-0-C-1] [KafkaProducer:572] configureTransactionState   [Producer clientId=producer-1] Instantiated an idempotent producer.
2023-12-01 16:31:48.597 INFO  ---- [er#2-0-C-1] [AppInfoParser:119] <init>   Kafka version: 3.1.2
2023-12-01 16:31:48.597 INFO  ---- [er#2-0-C-1] [AppInfoParser:120] <init>   Kafka commitId: f8c67dc3ae0a3265
2023-12-01 16:31:48.597 INFO  ---- [er#2-0-C-1] [AppInfoParser:121] <init>   Kafka startTimeMs: 1701415908597
2023-12-01 16:31:48.613 INFO  ---- [producer-1] [Metadata:402] updateLatestMetadata   [Producer clientId=producer-1] Resetting the last seen epoch of partition member-check-0 to 4 since the associated topicId changed from null to KYr4s4QASse48T8_YcW_QA
2023-12-01 16:31:48.614 INFO  ---- [producer-1] [Metadata:287] update   [Producer clientId=producer-1] Cluster ID: 5_U1uds-SGaR4vItj-jqUw
2023-12-01 16:31:48.615 INFO  ---- [producer-1] [TransactionManager:554] setProducerIdAndEpoch   [Producer clientId=producer-1] ProducerId set to 4019 with epoch 0
2023-12-01 16:31:56.878 INFO  ---- [producer-1] [Metadata:402] updateLatestMetadata   [Producer clientId=producer-1] Resetting the last seen epoch of partition product-check-0 to 0 since the associated topicId changed from null to s3iB_sksQs-tjMNRl3uQ2Q
2023-12-01 16:31:57.090 ERROR ---- [er#0-0-C-1] [OrderSubTaskConsumer:46] ProductTaskListener   taskListener Error message = {"taskId":"4c83c210-7850-4988-ae64-9a7e84033638","subTaskName":"validProductTask : 상품 유효성 검사","status":"FAIL","type":"PRODUCT","productId":269,"colorId":1,"quantity":3,"sizeId":271}
java.lang.NullPointerException: null
	at com.example.taskconsumer.consum.OrderSubTaskConsumer.setCountManager(OrderSubTaskConsumer.java:61)
	at com.example.taskconsumer.consum.OrderSubTaskConsumer.ProductTaskListener(OrderSubTaskConsumer.java:44)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
	at org.springframework.messaging.handler.invocation.InvocableHandlerMethod.doInvoke(InvocableHandlerMethod.java:169)
	at org.springframework.messaging.handler.invocation.InvocableHandlerMethod.invoke(InvocableHandlerMethod.java:119)
	at org.springframework.kafka.listener.adapter.HandlerAdapter.invoke(HandlerAdapter.java:56)
	at org.springframework.kafka.listener.adapter.MessagingMessageListenerAdapter.invokeHandler(MessagingMessageListenerAdapter.java:347)
	at org.springframework.kafka.listener.adapter.RecordMessagingMessageListenerAdapter.onMessage(RecordMessagingMessageListenerAdapter.java:92)
	at org.springframework.kafka.listener.adapter.RecordMessagingMessageListenerAdapter.onMessage(RecordMessagingMessageListenerAdapter.java:53)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeOnMessage(KafkaMessageListenerContainer.java:2670)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeOnMessage(KafkaMessageListenerContainer.java:2650)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeRecordListener(KafkaMessageListenerContainer.java:2577)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeWithRecords(KafkaMessageListenerContainer.java:2457)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeRecordListener(KafkaMessageListenerContainer.java:2335)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeListener(KafkaMessageListenerContainer.java:2006)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeIfHaveRecords(KafkaMessageListenerContainer.java:1375)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.pollAndInvoke(KafkaMessageListenerContainer.java:1366)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.run(KafkaMessageListenerContainer.java:1257)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.lang.Thread.run(Thread.java:834)
2023-12-01 16:37:57.390 INFO  ---- [tartedMain] [TaskConsumerApplication:55] logStarting   Starting TaskConsumerApplication using Java 11.0.13 on DESKTOP-MNMB87E with PID 26008 (C:\Users\tkdrb\IdeaProjects\ecommerce\task-consumer\build\classes\java\main started by tkdrb in C:\Users\tkdrb\IdeaProjects\ecommerce\task-consumer)
2023-12-01 16:37:57.392 INFO  ---- [tartedMain] [TaskConsumerApplication:631] logStartupProfileInfo   No active profile set, falling back to 1 default profile: "default"
2023-12-01 16:37:57.440 INFO  ---- [tartedMain] [DevToolsPropertyDefaultsPostProcessor:255] logTo   Devtools property defaults active! Set 'spring.devtools.add-properties' to 'false' to disable
2023-12-01 16:37:57.440 INFO  ---- [tartedMain] [DevToolsPropertyDefaultsPostProcessor:255] logTo   For additional web related logging consider setting the 'logging.level.web' property to 'DEBUG'
2023-12-01 16:37:58.395 INFO  ---- [tartedMain] [GenericScope:283] setSerializationId   BeanFactory id=7d336d03-7948-373b-80b2-3edd326128fe
2023-12-01 16:37:59.646 INFO  ---- [tartedMain] [TomcatWebServer:108] initialize   Tomcat initialized with port(s): 0 (http)
2023-12-01 16:37:59.668 INFO  ---- [tartedMain] [StandardService:173] log   Starting service [Tomcat]
2023-12-01 16:37:59.668 INFO  ---- [tartedMain] [StandardEngine:173] log   Starting Servlet engine: [Apache Tomcat/9.0.76]
2023-12-01 16:37:59.810 INFO  ---- [tartedMain] [[/]:173] log   Initializing Spring embedded WebApplicationContext
2023-12-01 16:37:59.811 INFO  ---- [tartedMain] [ServletWebServerApplicationContext:292] prepareWebApplicationContext   Root WebApplicationContext: initialization completed in 2370 ms
2023-12-01 16:38:00.394 INFO  ---- [tartedMain] [OptionalLiveReloadServer:59] startServer   LiveReload server is running on port 35729
2023-12-01 16:38:01.273 INFO  ---- [tartedMain] [DiscoveryClientOptionalArgsConfiguration:71] restTemplateDiscoveryClientOptionalArgs   Eureka HTTP Client uses RestTemplate.
2023-12-01 16:38:02.287 WARN  ---- [tartedMain] [LoadBalancerCacheAutoConfiguration$LoadBalancerCaffeineWarnLogger:83] logWarning   Spring Cloud LoadBalancer is currently working with the default cache. While this cache implementation is useful for development and tests, it's recommended to use Caffeine cache in production.You can switch to using Caffeine cache, by adding it and org.springframework.cache.caffeine.CaffeineCacheManager to the classpath.
2023-12-01 16:38:02.396 INFO  ---- [tartedMain] [ConsumerConfig:376] logAll   ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-order.group.v1-1
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = order.group.v1
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2023-12-01 16:38:02.570 INFO  ---- [tartedMain] [AppInfoParser:119] <init>   Kafka version: 3.1.2
2023-12-01 16:38:02.573 INFO  ---- [tartedMain] [AppInfoParser:120] <init>   Kafka commitId: f8c67dc3ae0a3265
2023-12-01 16:38:02.574 INFO  ---- [tartedMain] [AppInfoParser:121] <init>   Kafka startTimeMs: 1701416282568
2023-12-01 16:38:02.579 INFO  ---- [tartedMain] [KafkaConsumer:966] subscribe   [Consumer clientId=consumer-order.group.v1-1, groupId=order.group.v1] Subscribed to topic(s): order
2023-12-01 16:38:02.598 INFO  ---- [tartedMain] [ConsumerConfig:376] logAll   ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-task.member.v1-2
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = task.member.v1
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2023-12-01 16:38:02.607 INFO  ---- [tartedMain] [AppInfoParser:119] <init>   Kafka version: 3.1.2
2023-12-01 16:38:02.609 INFO  ---- [tartedMain] [AppInfoParser:120] <init>   Kafka commitId: f8c67dc3ae0a3265
2023-12-01 16:38:02.610 INFO  ---- [tartedMain] [AppInfoParser:121] <init>   Kafka startTimeMs: 1701416282607
2023-12-01 16:38:02.610 INFO  ---- [tartedMain] [KafkaConsumer:966] subscribe   [Consumer clientId=consumer-task.member.v1-2, groupId=task.member.v1] Subscribed to topic(s): task-member
2023-12-01 16:38:02.613 INFO  ---- [tartedMain] [ConsumerConfig:376] logAll   ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-task.product.v1-3
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = task.product.v1
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2023-12-01 16:38:02.621 INFO  ---- [tartedMain] [AppInfoParser:119] <init>   Kafka version: 3.1.2
2023-12-01 16:38:02.622 INFO  ---- [tartedMain] [AppInfoParser:120] <init>   Kafka commitId: f8c67dc3ae0a3265
2023-12-01 16:38:02.622 INFO  ---- [tartedMain] [AppInfoParser:121] <init>   Kafka startTimeMs: 1701416282621
2023-12-01 16:38:02.622 INFO  ---- [tartedMain] [KafkaConsumer:966] subscribe   [Consumer clientId=consumer-task.product.v1-3, groupId=task.product.v1] Subscribed to topic(s): task-product
2023-12-01 16:38:02.640 INFO  ---- [tartedMain] [TomcatWebServer:220] start   Tomcat started on port(s): 61095 (http) with context path ''
2023-12-01 16:38:02.642 INFO  ---- [tartedMain] [EurekaAutoServiceRegistration:144] onApplicationEvent   Updating port to 61095
2023-12-01 16:38:02.648 INFO  ---- [tartedMain] [InstanceInfoFactory:67] create   Setting initial instance status as: STARTING
2023-12-01 16:38:02.719 INFO  ---- [tartedMain] [DiscoveryClient:372] <init>   Initializing Eureka in region us-east-1
2023-12-01 16:38:02.727 INFO  ---- [tartedMain] [ConfigClusterResolver:43] getClusterEndpoints   Resolving eureka endpoints via configuration
2023-12-01 16:38:02.756 INFO  ---- [tartedMain] [DiscoveryClient:1007] fetchRegistry   Disable delta property : false
2023-12-01 16:38:02.756 INFO  ---- [tartedMain] [DiscoveryClient:1008] fetchRegistry   Single vip registry refresh property : null
2023-12-01 16:38:02.756 INFO  ---- [tartedMain] [DiscoveryClient:1009] fetchRegistry   Force full registry fetch : false
2023-12-01 16:38:02.756 INFO  ---- [tartedMain] [DiscoveryClient:1010] fetchRegistry   Application is null : false
2023-12-01 16:38:02.757 INFO  ---- [tartedMain] [DiscoveryClient:1011] fetchRegistry   Registered Applications size is zero : true
2023-12-01 16:38:02.757 INFO  ---- [tartedMain] [DiscoveryClient:1013] fetchRegistry   Application version is -1: true
2023-12-01 16:38:02.757 INFO  ---- [tartedMain] [DiscoveryClient:1097] getAndStoreFullRegistry   Getting all instance registry info from the eureka server
2023-12-01 16:38:03.097 INFO  ---- [er#2-0-C-1] [Metadata:402] updateLatestMetadata   [Consumer clientId=consumer-order.group.v1-1, groupId=order.group.v1] Resetting the last seen epoch of partition order-0 to 0 since the associated topicId changed from null to 8AIo0qkzSIiGJbn1bQxAkw
2023-12-01 16:38:03.097 INFO  ---- [er#1-0-C-1] [Metadata:402] updateLatestMetadata   [Consumer clientId=consumer-task.product.v1-3, groupId=task.product.v1] Resetting the last seen epoch of partition task-product-0 to 0 since the associated topicId changed from null to aPVZw1a3STycu2734KRZ3w
2023-12-01 16:38:03.097 INFO  ---- [er#0-0-C-1] [Metadata:402] updateLatestMetadata   [Consumer clientId=consumer-task.member.v1-2, groupId=task.member.v1] Resetting the last seen epoch of partition task-member-0 to 9 since the associated topicId changed from null to HvfbkcRhQ3meTIJFgCt9zw
2023-12-01 16:38:03.101 INFO  ---- [er#0-0-C-1] [Metadata:287] update   [Consumer clientId=consumer-task.member.v1-2, groupId=task.member.v1] Cluster ID: 5_U1uds-SGaR4vItj-jqUw
2023-12-01 16:38:03.101 INFO  ---- [er#2-0-C-1] [Metadata:287] update   [Consumer clientId=consumer-order.group.v1-1, groupId=order.group.v1] Cluster ID: 5_U1uds-SGaR4vItj-jqUw
2023-12-01 16:38:03.101 INFO  ---- [er#1-0-C-1] [Metadata:287] update   [Consumer clientId=consumer-task.product.v1-3, groupId=task.product.v1] Cluster ID: 5_U1uds-SGaR4vItj-jqUw
2023-12-01 16:38:03.104 INFO  ---- [er#0-0-C-1] [ConsumerCoordinator:853] onSuccess   [Consumer clientId=consumer-task.member.v1-2, groupId=task.member.v1] Discovered group coordinator 127.0.0.1:9093 (id: 2147483644 rack: null)
2023-12-01 16:38:03.104 INFO  ---- [er#2-0-C-1] [ConsumerCoordinator:853] onSuccess   [Consumer clientId=consumer-order.group.v1-1, groupId=order.group.v1] Discovered group coordinator 127.0.0.1:9091 (id: 2147483646 rack: null)
2023-12-01 16:38:03.104 INFO  ---- [er#1-0-C-1] [ConsumerCoordinator:853] onSuccess   [Consumer clientId=consumer-task.product.v1-3, groupId=task.product.v1] Discovered group coordinator 127.0.0.1:9091 (id: 2147483646 rack: null)
2023-12-01 16:38:03.108 INFO  ---- [er#2-0-C-1] [ConsumerCoordinator:535] sendJoinGroupRequest   [Consumer clientId=consumer-order.group.v1-1, groupId=order.group.v1] (Re-)joining group
2023-12-01 16:38:03.111 INFO  ---- [er#0-0-C-1] [ConsumerCoordinator:535] sendJoinGroupRequest   [Consumer clientId=consumer-task.member.v1-2, groupId=task.member.v1] (Re-)joining group
2023-12-01 16:38:03.111 INFO  ---- [er#1-0-C-1] [ConsumerCoordinator:535] sendJoinGroupRequest   [Consumer clientId=consumer-task.product.v1-3, groupId=task.product.v1] (Re-)joining group
2023-12-01 16:38:03.182 INFO  ---- [er#0-0-C-1] [ConsumerCoordinator:1000] requestRejoin   [Consumer clientId=consumer-task.member.v1-2, groupId=task.member.v1] Request joining group due to: need to re-join with the given member-id
2023-12-01 16:38:03.182 INFO  ---- [er#1-0-C-1] [ConsumerCoordinator:1000] requestRejoin   [Consumer clientId=consumer-task.product.v1-3, groupId=task.product.v1] Request joining group due to: need to re-join with the given member-id
2023-12-01 16:38:03.182 INFO  ---- [er#2-0-C-1] [ConsumerCoordinator:1000] requestRejoin   [Consumer clientId=consumer-order.group.v1-1, groupId=order.group.v1] Request joining group due to: need to re-join with the given member-id
2023-12-01 16:38:03.182 INFO  ---- [er#0-0-C-1] [ConsumerCoordinator:535] sendJoinGroupRequest   [Consumer clientId=consumer-task.member.v1-2, groupId=task.member.v1] (Re-)joining group
2023-12-01 16:38:03.182 INFO  ---- [er#1-0-C-1] [ConsumerCoordinator:535] sendJoinGroupRequest   [Consumer clientId=consumer-task.product.v1-3, groupId=task.product.v1] (Re-)joining group
2023-12-01 16:38:03.182 INFO  ---- [er#2-0-C-1] [ConsumerCoordinator:535] sendJoinGroupRequest   [Consumer clientId=consumer-order.group.v1-1, groupId=order.group.v1] (Re-)joining group
2023-12-01 16:38:03.238 INFO  ---- [tartedMain] [DiscoveryClient:1106] getAndStoreFullRegistry   The response status is 200
2023-12-01 16:38:03.243 INFO  ---- [tartedMain] [DiscoveryClient:1321] initScheduledTasks   Starting heartbeat executor: renew interval is: 30
2023-12-01 16:38:03.246 INFO  ---- [tartedMain] [InstanceInfoReplicator:60] <init>   InstanceInfoReplicator onDemand update allowed rate per min is 4
2023-12-01 16:38:03.255 INFO  ---- [tartedMain] [DiscoveryClient:492] <init>   Discovery Client initialized at timestamp 1701416283253 with initial instances count: 3
2023-12-01 16:38:03.257 INFO  ---- [tartedMain] [EurekaServiceRegistry:41] register   Registering application TASK-SERVICE with eureka with status UP
2023-12-01 16:38:03.258 INFO  ---- [tartedMain] [DiscoveryClient:1352] notify   Saw local status change event StatusChangeEvent [timestamp=1701416283258, current=UP, previous=STARTING]
2023-12-01 16:38:03.262 INFO  ---- [plicator-0] [DiscoveryClient:873] register   DiscoveryClient_TASK-SERVICE/192.168.0.17:1db46a66687574af32c83e75dc5d13e1: registering service...
2023-12-01 16:38:03.322 INFO  ---- [plicator-0] [DiscoveryClient:882] register   DiscoveryClient_TASK-SERVICE/192.168.0.17:1db46a66687574af32c83e75dc5d13e1 - registration status: 204
2023-12-01 16:38:04.294 INFO  ---- [tartedMain] [TaskConsumerApplication:61] logStarted   Started TaskConsumerApplication in 8.054 seconds (JVM running for 8.698)
2023-12-01 16:38:06.219 INFO  ---- [er#2-0-C-1] [ConsumerCoordinator:595] handle   [Consumer clientId=consumer-order.group.v1-1, groupId=order.group.v1] Successfully joined group with generation Generation{generationId=18, memberId='consumer-order.group.v1-1-a0bbc90d-5678-4f62-b03c-479c7a6f62be', protocol='range'}
2023-12-01 16:38:06.219 INFO  ---- [er#1-0-C-1] [ConsumerCoordinator:595] handle   [Consumer clientId=consumer-task.product.v1-3, groupId=task.product.v1] Successfully joined group with generation Generation{generationId=1, memberId='consumer-task.product.v1-3-28758a83-b52a-4619-adeb-05376e84e739', protocol='range'}
2023-12-01 16:38:06.219 INFO  ---- [er#0-0-C-1] [ConsumerCoordinator:595] handle   [Consumer clientId=consumer-task.member.v1-2, groupId=task.member.v1] Successfully joined group with generation Generation{generationId=62, memberId='consumer-task.member.v1-2-3376997a-2c41-43b4-9fa2-daeed9aa33e1', protocol='range'}
2023-12-01 16:38:06.223 INFO  ---- [er#1-0-C-1] [ConsumerCoordinator:659] performAssignment   [Consumer clientId=consumer-task.product.v1-3, groupId=task.product.v1] Finished assignment for group at generation 1: {consumer-task.product.v1-3-28758a83-b52a-4619-adeb-05376e84e739=Assignment(partitions=[task-product-0])}
2023-12-01 16:38:06.223 INFO  ---- [er#0-0-C-1] [ConsumerCoordinator:659] performAssignment   [Consumer clientId=consumer-task.member.v1-2, groupId=task.member.v1] Finished assignment for group at generation 62: {consumer-task.member.v1-2-3376997a-2c41-43b4-9fa2-daeed9aa33e1=Assignment(partitions=[task-member-0])}
2023-12-01 16:38:06.223 INFO  ---- [er#2-0-C-1] [ConsumerCoordinator:659] performAssignment   [Consumer clientId=consumer-order.group.v1-1, groupId=order.group.v1] Finished assignment for group at generation 18: {consumer-order.group.v1-1-a0bbc90d-5678-4f62-b03c-479c7a6f62be=Assignment(partitions=[order-0])}
2023-12-01 16:38:06.283 INFO  ---- [er#2-0-C-1] [ConsumerCoordinator:761] handle   [Consumer clientId=consumer-order.group.v1-1, groupId=order.group.v1] Successfully synced group in generation Generation{generationId=18, memberId='consumer-order.group.v1-1-a0bbc90d-5678-4f62-b03c-479c7a6f62be', protocol='range'}
2023-12-01 16:38:06.283 INFO  ---- [er#1-0-C-1] [ConsumerCoordinator:761] handle   [Consumer clientId=consumer-task.product.v1-3, groupId=task.product.v1] Successfully synced group in generation Generation{generationId=1, memberId='consumer-task.product.v1-3-28758a83-b52a-4619-adeb-05376e84e739', protocol='range'}
2023-12-01 16:38:06.283 INFO  ---- [er#0-0-C-1] [ConsumerCoordinator:761] handle   [Consumer clientId=consumer-task.member.v1-2, groupId=task.member.v1] Successfully synced group in generation Generation{generationId=62, memberId='consumer-task.member.v1-2-3376997a-2c41-43b4-9fa2-daeed9aa33e1', protocol='range'}
2023-12-01 16:38:06.284 INFO  ---- [er#0-0-C-1] [ConsumerCoordinator:280] invokeOnAssignment   [Consumer clientId=consumer-task.member.v1-2, groupId=task.member.v1] Notifying assignor about the new Assignment(partitions=[task-member-0])
2023-12-01 16:38:06.284 INFO  ---- [er#2-0-C-1] [ConsumerCoordinator:280] invokeOnAssignment   [Consumer clientId=consumer-order.group.v1-1, groupId=order.group.v1] Notifying assignor about the new Assignment(partitions=[order-0])
2023-12-01 16:38:06.284 INFO  ---- [er#1-0-C-1] [ConsumerCoordinator:280] invokeOnAssignment   [Consumer clientId=consumer-task.product.v1-3, groupId=task.product.v1] Notifying assignor about the new Assignment(partitions=[task-product-0])
2023-12-01 16:38:06.287 INFO  ---- [er#2-0-C-1] [ConsumerCoordinator:292] invokePartitionsAssigned   [Consumer clientId=consumer-order.group.v1-1, groupId=order.group.v1] Adding newly assigned partitions: order-0
2023-12-01 16:38:06.287 INFO  ---- [er#0-0-C-1] [ConsumerCoordinator:292] invokePartitionsAssigned   [Consumer clientId=consumer-task.member.v1-2, groupId=task.member.v1] Adding newly assigned partitions: task-member-0
2023-12-01 16:38:06.287 INFO  ---- [er#1-0-C-1] [ConsumerCoordinator:292] invokePartitionsAssigned   [Consumer clientId=consumer-task.product.v1-3, groupId=task.product.v1] Adding newly assigned partitions: task-product-0
2023-12-01 16:38:06.351 INFO  ---- [er#1-0-C-1] [ConsumerCoordinator:1405] handle   [Consumer clientId=consumer-task.product.v1-3, groupId=task.product.v1] Found no committed offset for partition task-product-0
2023-12-01 16:38:06.393 INFO  ---- [er#1-0-C-1] [ConsumerCoordinator:1405] handle   [Consumer clientId=consumer-task.product.v1-3, groupId=task.product.v1] Found no committed offset for partition task-product-0
2023-12-01 16:38:06.396 INFO  ---- [er#0-0-C-1] [ConsumerCoordinator:851] refreshCommittedOffsetsIfNeeded   [Consumer clientId=consumer-task.member.v1-2, groupId=task.member.v1] Setting offset for partition task-member-0 to the committed offset FetchPosition{offset=12, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[127.0.0.1:9091 (id: 1 rack: null)], epoch=9}}
2023-12-01 16:38:06.396 INFO  ---- [er#2-0-C-1] [ConsumerCoordinator:851] refreshCommittedOffsetsIfNeeded   [Consumer clientId=consumer-order.group.v1-1, groupId=order.group.v1] Setting offset for partition order-0 to the committed offset FetchPosition{offset=6, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[127.0.0.1:9092 (id: 2 rack: null)], epoch=0}}
2023-12-01 16:38:06.396 INFO  ---- [er#2-0-C-1] [KafkaMessageListenerContainer:292] info   order.group.v1: partitions assigned: [order-0]
2023-12-01 16:38:06.396 INFO  ---- [er#0-0-C-1] [KafkaMessageListenerContainer:292] info   task.member.v1: partitions assigned: [task-member-0]
2023-12-01 16:38:06.564 INFO  ---- [er#1-0-C-1] [SubscriptionState:398] maybeSeekUnvalidated   [Consumer clientId=consumer-task.product.v1-3, groupId=task.product.v1] Resetting offset for partition task-product-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[127.0.0.1:9093 (id: 3 rack: null)], epoch=0}}.
2023-12-01 16:38:06.616 INFO  ---- [er#1-0-C-1] [KafkaMessageListenerContainer:292] info   task.product.v1: partitions assigned: [task-product-0]
2023-12-01 16:38:06.650 INFO  ---- [er#2-0-C-1] [ProducerConfig:376] logAll   ProducerConfig values: 
	acks = -1
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-1
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2023-12-01 16:38:06.666 INFO  ---- [er#2-0-C-1] [KafkaProducer:572] configureTransactionState   [Producer clientId=producer-1] Instantiated an idempotent producer.
2023-12-01 16:38:06.682 INFO  ---- [er#2-0-C-1] [AppInfoParser:119] <init>   Kafka version: 3.1.2
2023-12-01 16:38:06.682 INFO  ---- [er#2-0-C-1] [AppInfoParser:120] <init>   Kafka commitId: f8c67dc3ae0a3265
2023-12-01 16:38:06.682 INFO  ---- [er#2-0-C-1] [AppInfoParser:121] <init>   Kafka startTimeMs: 1701416286682
2023-12-01 16:38:06.693 INFO  ---- [producer-1] [Metadata:402] updateLatestMetadata   [Producer clientId=producer-1] Resetting the last seen epoch of partition member-check-0 to 4 since the associated topicId changed from null to KYr4s4QASse48T8_YcW_QA
2023-12-01 16:38:06.694 INFO  ---- [producer-1] [Metadata:287] update   [Producer clientId=producer-1] Cluster ID: 5_U1uds-SGaR4vItj-jqUw
2023-12-01 16:38:06.696 INFO  ---- [producer-1] [TransactionManager:554] setProducerIdAndEpoch   [Producer clientId=producer-1] ProducerId set to 4023 with epoch 0
2023-12-01 16:38:54.934 INFO  ---- [producer-1] [Metadata:402] updateLatestMetadata   [Producer clientId=producer-1] Resetting the last seen epoch of partition product-check-0 to 0 since the associated topicId changed from null to s3iB_sksQs-tjMNRl3uQ2Q
2023-12-01 16:38:55.234 ERROR ---- [er#1-0-C-1] [OrderSubTaskConsumer:46] ProductTaskListener   taskListener Error message = {"taskId":"4c83c210-7850-4988-ae64-9a7e84033638","subTaskName":"validProductTask : 상품 유효성 검사","status":"FAIL","type":"PRODUCT","productId":269,"colorId":1,"quantity":3,"sizeId":271}
java.lang.NullPointerException: null
	at com.example.taskconsumer.consum.OrderSubTaskConsumer.setCountManager(OrderSubTaskConsumer.java:61)
	at com.example.taskconsumer.consum.OrderSubTaskConsumer.ProductTaskListener(OrderSubTaskConsumer.java:44)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
	at org.springframework.messaging.handler.invocation.InvocableHandlerMethod.doInvoke(InvocableHandlerMethod.java:169)
	at org.springframework.messaging.handler.invocation.InvocableHandlerMethod.invoke(InvocableHandlerMethod.java:119)
	at org.springframework.kafka.listener.adapter.HandlerAdapter.invoke(HandlerAdapter.java:56)
	at org.springframework.kafka.listener.adapter.MessagingMessageListenerAdapter.invokeHandler(MessagingMessageListenerAdapter.java:347)
	at org.springframework.kafka.listener.adapter.RecordMessagingMessageListenerAdapter.onMessage(RecordMessagingMessageListenerAdapter.java:92)
	at org.springframework.kafka.listener.adapter.RecordMessagingMessageListenerAdapter.onMessage(RecordMessagingMessageListenerAdapter.java:53)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeOnMessage(KafkaMessageListenerContainer.java:2670)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeOnMessage(KafkaMessageListenerContainer.java:2650)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeRecordListener(KafkaMessageListenerContainer.java:2577)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeWithRecords(KafkaMessageListenerContainer.java:2457)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeRecordListener(KafkaMessageListenerContainer.java:2335)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeListener(KafkaMessageListenerContainer.java:2006)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeIfHaveRecords(KafkaMessageListenerContainer.java:1375)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.pollAndInvoke(KafkaMessageListenerContainer.java:1366)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.run(KafkaMessageListenerContainer.java:1257)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.lang.Thread.run(Thread.java:834)
2023-12-01 16:41:00.689 INFO  ---- [tartedMain] [TaskConsumerApplication:55] logStarting   Starting TaskConsumerApplication using Java 11.0.13 on DESKTOP-MNMB87E with PID 25216 (C:\Users\tkdrb\IdeaProjects\ecommerce\task-consumer\build\classes\java\main started by tkdrb in C:\Users\tkdrb\IdeaProjects\ecommerce\task-consumer)
2023-12-01 16:41:00.691 INFO  ---- [tartedMain] [TaskConsumerApplication:631] logStartupProfileInfo   No active profile set, falling back to 1 default profile: "default"
2023-12-01 16:41:00.745 INFO  ---- [tartedMain] [DevToolsPropertyDefaultsPostProcessor:255] logTo   Devtools property defaults active! Set 'spring.devtools.add-properties' to 'false' to disable
2023-12-01 16:41:00.750 INFO  ---- [tartedMain] [DevToolsPropertyDefaultsPostProcessor:255] logTo   For additional web related logging consider setting the 'logging.level.web' property to 'DEBUG'
2023-12-01 16:41:02.209 INFO  ---- [tartedMain] [GenericScope:283] setSerializationId   BeanFactory id=7d336d03-7948-373b-80b2-3edd326128fe
2023-12-01 16:41:03.201 INFO  ---- [tartedMain] [TomcatWebServer:108] initialize   Tomcat initialized with port(s): 0 (http)
2023-12-01 16:41:03.212 INFO  ---- [tartedMain] [StandardService:173] log   Starting service [Tomcat]
2023-12-01 16:41:03.213 INFO  ---- [tartedMain] [StandardEngine:173] log   Starting Servlet engine: [Apache Tomcat/9.0.76]
2023-12-01 16:41:03.387 INFO  ---- [tartedMain] [[/]:173] log   Initializing Spring embedded WebApplicationContext
2023-12-01 16:41:03.387 INFO  ---- [tartedMain] [ServletWebServerApplicationContext:292] prepareWebApplicationContext   Root WebApplicationContext: initialization completed in 2635 ms
2023-12-01 16:41:03.851 WARN  ---- [tartedMain] [OptionalLiveReloadServer:62] startServer   Unable to start LiveReload server
2023-12-01 16:41:04.559 INFO  ---- [tartedMain] [DiscoveryClientOptionalArgsConfiguration:71] restTemplateDiscoveryClientOptionalArgs   Eureka HTTP Client uses RestTemplate.
2023-12-01 16:41:06.191 WARN  ---- [tartedMain] [LoadBalancerCacheAutoConfiguration$LoadBalancerCaffeineWarnLogger:83] logWarning   Spring Cloud LoadBalancer is currently working with the default cache. While this cache implementation is useful for development and tests, it's recommended to use Caffeine cache in production.You can switch to using Caffeine cache, by adding it and org.springframework.cache.caffeine.CaffeineCacheManager to the classpath.
2023-12-01 16:41:06.329 INFO  ---- [tartedMain] [ConsumerConfig:376] logAll   ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-order.group.v1-1
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = order.group.v1
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2023-12-01 16:41:06.539 INFO  ---- [tartedMain] [AppInfoParser:119] <init>   Kafka version: 3.1.2
2023-12-01 16:41:06.541 INFO  ---- [tartedMain] [AppInfoParser:120] <init>   Kafka commitId: f8c67dc3ae0a3265
2023-12-01 16:41:06.542 INFO  ---- [tartedMain] [AppInfoParser:121] <init>   Kafka startTimeMs: 1701416466537
2023-12-01 16:41:06.546 INFO  ---- [tartedMain] [KafkaConsumer:966] subscribe   [Consumer clientId=consumer-order.group.v1-1, groupId=order.group.v1] Subscribed to topic(s): order
2023-12-01 16:41:06.578 INFO  ---- [tartedMain] [ConsumerConfig:376] logAll   ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-task.member.v1-2
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = task.member.v1
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2023-12-01 16:41:06.588 INFO  ---- [tartedMain] [AppInfoParser:119] <init>   Kafka version: 3.1.2
2023-12-01 16:41:06.588 INFO  ---- [tartedMain] [AppInfoParser:120] <init>   Kafka commitId: f8c67dc3ae0a3265
2023-12-01 16:41:06.589 INFO  ---- [tartedMain] [AppInfoParser:121] <init>   Kafka startTimeMs: 1701416466588
2023-12-01 16:41:06.589 INFO  ---- [tartedMain] [KafkaConsumer:966] subscribe   [Consumer clientId=consumer-task.member.v1-2, groupId=task.member.v1] Subscribed to topic(s): task-member
2023-12-01 16:41:06.593 INFO  ---- [tartedMain] [ConsumerConfig:376] logAll   ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-task.product.v1-3
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = task.product.v1
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2023-12-01 16:41:06.604 INFO  ---- [tartedMain] [AppInfoParser:119] <init>   Kafka version: 3.1.2
2023-12-01 16:41:06.605 INFO  ---- [tartedMain] [AppInfoParser:120] <init>   Kafka commitId: f8c67dc3ae0a3265
2023-12-01 16:41:06.605 INFO  ---- [tartedMain] [AppInfoParser:121] <init>   Kafka startTimeMs: 1701416466604
2023-12-01 16:41:06.605 INFO  ---- [tartedMain] [KafkaConsumer:966] subscribe   [Consumer clientId=consumer-task.product.v1-3, groupId=task.product.v1] Subscribed to topic(s): task-product
2023-12-01 16:41:06.626 INFO  ---- [tartedMain] [TomcatWebServer:220] start   Tomcat started on port(s): 61291 (http) with context path ''
2023-12-01 16:41:06.627 INFO  ---- [tartedMain] [EurekaAutoServiceRegistration:144] onApplicationEvent   Updating port to 61291
2023-12-01 16:41:06.635 INFO  ---- [tartedMain] [InstanceInfoFactory:67] create   Setting initial instance status as: STARTING
2023-12-01 16:41:06.701 INFO  ---- [tartedMain] [DiscoveryClient:372] <init>   Initializing Eureka in region us-east-1
2023-12-01 16:41:06.709 INFO  ---- [tartedMain] [ConfigClusterResolver:43] getClusterEndpoints   Resolving eureka endpoints via configuration
2023-12-01 16:41:06.743 INFO  ---- [tartedMain] [DiscoveryClient:1007] fetchRegistry   Disable delta property : false
2023-12-01 16:41:06.744 INFO  ---- [tartedMain] [DiscoveryClient:1008] fetchRegistry   Single vip registry refresh property : null
2023-12-01 16:41:06.744 INFO  ---- [tartedMain] [DiscoveryClient:1009] fetchRegistry   Force full registry fetch : false
2023-12-01 16:41:06.744 INFO  ---- [tartedMain] [DiscoveryClient:1010] fetchRegistry   Application is null : false
2023-12-01 16:41:06.744 INFO  ---- [tartedMain] [DiscoveryClient:1011] fetchRegistry   Registered Applications size is zero : true
2023-12-01 16:41:06.744 INFO  ---- [tartedMain] [DiscoveryClient:1013] fetchRegistry   Application version is -1: true
2023-12-01 16:41:06.744 INFO  ---- [tartedMain] [DiscoveryClient:1097] getAndStoreFullRegistry   Getting all instance registry info from the eureka server
2023-12-01 16:41:07.083 INFO  ---- [er#2-0-C-1] [Metadata:402] updateLatestMetadata   [Consumer clientId=consumer-order.group.v1-1, groupId=order.group.v1] Resetting the last seen epoch of partition order-0 to 0 since the associated topicId changed from null to 8AIo0qkzSIiGJbn1bQxAkw
2023-12-01 16:41:07.083 INFO  ---- [er#1-0-C-1] [Metadata:402] updateLatestMetadata   [Consumer clientId=consumer-task.product.v1-3, groupId=task.product.v1] Resetting the last seen epoch of partition task-product-0 to 0 since the associated topicId changed from null to aPVZw1a3STycu2734KRZ3w
2023-12-01 16:41:07.083 INFO  ---- [er#0-0-C-1] [Metadata:402] updateLatestMetadata   [Consumer clientId=consumer-task.member.v1-2, groupId=task.member.v1] Resetting the last seen epoch of partition task-member-0 to 9 since the associated topicId changed from null to HvfbkcRhQ3meTIJFgCt9zw
2023-12-01 16:41:07.087 INFO  ---- [er#2-0-C-1] [Metadata:287] update   [Consumer clientId=consumer-order.group.v1-1, groupId=order.group.v1] Cluster ID: 5_U1uds-SGaR4vItj-jqUw
2023-12-01 16:41:07.087 INFO  ---- [er#0-0-C-1] [Metadata:287] update   [Consumer clientId=consumer-task.member.v1-2, groupId=task.member.v1] Cluster ID: 5_U1uds-SGaR4vItj-jqUw
2023-12-01 16:41:07.087 INFO  ---- [er#1-0-C-1] [Metadata:287] update   [Consumer clientId=consumer-task.product.v1-3, groupId=task.product.v1] Cluster ID: 5_U1uds-SGaR4vItj-jqUw
2023-12-01 16:41:07.089 INFO  ---- [er#1-0-C-1] [ConsumerCoordinator:853] onSuccess   [Consumer clientId=consumer-task.product.v1-3, groupId=task.product.v1] Discovered group coordinator 127.0.0.1:9091 (id: 2147483646 rack: null)
2023-12-01 16:41:07.089 INFO  ---- [er#2-0-C-1] [ConsumerCoordinator:853] onSuccess   [Consumer clientId=consumer-order.group.v1-1, groupId=order.group.v1] Discovered group coordinator 127.0.0.1:9091 (id: 2147483646 rack: null)
2023-12-01 16:41:07.089 INFO  ---- [er#0-0-C-1] [ConsumerCoordinator:853] onSuccess   [Consumer clientId=consumer-task.member.v1-2, groupId=task.member.v1] Discovered group coordinator 127.0.0.1:9093 (id: 2147483644 rack: null)
2023-12-01 16:41:07.093 INFO  ---- [er#0-0-C-1] [ConsumerCoordinator:535] sendJoinGroupRequest   [Consumer clientId=consumer-task.member.v1-2, groupId=task.member.v1] (Re-)joining group
2023-12-01 16:41:07.093 INFO  ---- [er#2-0-C-1] [ConsumerCoordinator:535] sendJoinGroupRequest   [Consumer clientId=consumer-order.group.v1-1, groupId=order.group.v1] (Re-)joining group
2023-12-01 16:41:07.093 INFO  ---- [er#1-0-C-1] [ConsumerCoordinator:535] sendJoinGroupRequest   [Consumer clientId=consumer-task.product.v1-3, groupId=task.product.v1] (Re-)joining group
2023-12-01 16:41:07.166 INFO  ---- [er#0-0-C-1] [ConsumerCoordinator:1000] requestRejoin   [Consumer clientId=consumer-task.member.v1-2, groupId=task.member.v1] Request joining group due to: need to re-join with the given member-id
2023-12-01 16:41:07.166 INFO  ---- [er#1-0-C-1] [ConsumerCoordinator:1000] requestRejoin   [Consumer clientId=consumer-task.product.v1-3, groupId=task.product.v1] Request joining group due to: need to re-join with the given member-id
2023-12-01 16:41:07.166 INFO  ---- [er#2-0-C-1] [ConsumerCoordinator:1000] requestRejoin   [Consumer clientId=consumer-order.group.v1-1, groupId=order.group.v1] Request joining group due to: need to re-join with the given member-id
2023-12-01 16:41:07.182 INFO  ---- [er#1-0-C-1] [ConsumerCoordinator:535] sendJoinGroupRequest   [Consumer clientId=consumer-task.product.v1-3, groupId=task.product.v1] (Re-)joining group
2023-12-01 16:41:07.182 INFO  ---- [er#0-0-C-1] [ConsumerCoordinator:535] sendJoinGroupRequest   [Consumer clientId=consumer-task.member.v1-2, groupId=task.member.v1] (Re-)joining group
2023-12-01 16:41:07.182 INFO  ---- [er#2-0-C-1] [ConsumerCoordinator:535] sendJoinGroupRequest   [Consumer clientId=consumer-order.group.v1-1, groupId=order.group.v1] (Re-)joining group
2023-12-01 16:41:07.242 INFO  ---- [tartedMain] [DiscoveryClient:1106] getAndStoreFullRegistry   The response status is 200
2023-12-01 16:41:07.247 INFO  ---- [tartedMain] [DiscoveryClient:1321] initScheduledTasks   Starting heartbeat executor: renew interval is: 30
2023-12-01 16:41:07.253 INFO  ---- [tartedMain] [InstanceInfoReplicator:60] <init>   InstanceInfoReplicator onDemand update allowed rate per min is 4
2023-12-01 16:41:07.261 INFO  ---- [tartedMain] [DiscoveryClient:492] <init>   Discovery Client initialized at timestamp 1701416467260 with initial instances count: 5
2023-12-01 16:41:07.264 INFO  ---- [tartedMain] [EurekaServiceRegistry:41] register   Registering application TASK-SERVICE with eureka with status UP
2023-12-01 16:41:07.266 INFO  ---- [tartedMain] [DiscoveryClient:1352] notify   Saw local status change event StatusChangeEvent [timestamp=1701416467265, current=UP, previous=STARTING]
2023-12-01 16:41:07.270 INFO  ---- [plicator-0] [DiscoveryClient:873] register   DiscoveryClient_TASK-SERVICE/192.168.0.17:023181473c8b34d448ab7cb5496c95f8: registering service...
2023-12-01 16:41:07.341 INFO  ---- [plicator-0] [DiscoveryClient:882] register   DiscoveryClient_TASK-SERVICE/192.168.0.17:023181473c8b34d448ab7cb5496c95f8 - registration status: 204
2023-12-01 16:41:09.438 INFO  ---- [tartedMain] [TaskConsumerApplication:61] logStarted   Started TaskConsumerApplication in 9.987 seconds (JVM running for 10.558)
2023-12-01 16:41:10.193 INFO  ---- [er#0-0-C-1] [ConsumerCoordinator:595] handle   [Consumer clientId=consumer-task.member.v1-2, groupId=task.member.v1] Successfully joined group with generation Generation{generationId=64, memberId='consumer-task.member.v1-2-c23699aa-bf88-4b75-aa2a-d57f020c8572', protocol='range'}
2023-12-01 16:41:10.193 INFO  ---- [er#2-0-C-1] [ConsumerCoordinator:595] handle   [Consumer clientId=consumer-order.group.v1-1, groupId=order.group.v1] Successfully joined group with generation Generation{generationId=20, memberId='consumer-order.group.v1-1-a7595d7d-90a7-46fa-9d1e-ead7efcede20', protocol='range'}
2023-12-01 16:41:10.193 INFO  ---- [er#1-0-C-1] [ConsumerCoordinator:595] handle   [Consumer clientId=consumer-task.product.v1-3, groupId=task.product.v1] Successfully joined group with generation Generation{generationId=3, memberId='consumer-task.product.v1-3-962db712-6c8c-4c62-b3a5-231dc4eb9420', protocol='range'}
2023-12-01 16:41:10.196 INFO  ---- [er#2-0-C-1] [ConsumerCoordinator:659] performAssignment   [Consumer clientId=consumer-order.group.v1-1, groupId=order.group.v1] Finished assignment for group at generation 20: {consumer-order.group.v1-1-a7595d7d-90a7-46fa-9d1e-ead7efcede20=Assignment(partitions=[order-0])}
2023-12-01 16:41:10.196 INFO  ---- [er#0-0-C-1] [ConsumerCoordinator:659] performAssignment   [Consumer clientId=consumer-task.member.v1-2, groupId=task.member.v1] Finished assignment for group at generation 64: {consumer-task.member.v1-2-c23699aa-bf88-4b75-aa2a-d57f020c8572=Assignment(partitions=[task-member-0])}
2023-12-01 16:41:10.196 INFO  ---- [er#1-0-C-1] [ConsumerCoordinator:659] performAssignment   [Consumer clientId=consumer-task.product.v1-3, groupId=task.product.v1] Finished assignment for group at generation 3: {consumer-task.product.v1-3-962db712-6c8c-4c62-b3a5-231dc4eb9420=Assignment(partitions=[task-product-0])}
2023-12-01 16:41:10.205 INFO  ---- [er#0-0-C-1] [ConsumerCoordinator:761] handle   [Consumer clientId=consumer-task.member.v1-2, groupId=task.member.v1] Successfully synced group in generation Generation{generationId=64, memberId='consumer-task.member.v1-2-c23699aa-bf88-4b75-aa2a-d57f020c8572', protocol='range'}
2023-12-01 16:41:10.205 INFO  ---- [er#2-0-C-1] [ConsumerCoordinator:761] handle   [Consumer clientId=consumer-order.group.v1-1, groupId=order.group.v1] Successfully synced group in generation Generation{generationId=20, memberId='consumer-order.group.v1-1-a7595d7d-90a7-46fa-9d1e-ead7efcede20', protocol='range'}
2023-12-01 16:41:10.205 INFO  ---- [er#1-0-C-1] [ConsumerCoordinator:761] handle   [Consumer clientId=consumer-task.product.v1-3, groupId=task.product.v1] Successfully synced group in generation Generation{generationId=3, memberId='consumer-task.product.v1-3-962db712-6c8c-4c62-b3a5-231dc4eb9420', protocol='range'}
2023-12-01 16:41:10.205 INFO  ---- [er#0-0-C-1] [ConsumerCoordinator:280] invokeOnAssignment   [Consumer clientId=consumer-task.member.v1-2, groupId=task.member.v1] Notifying assignor about the new Assignment(partitions=[task-member-0])
2023-12-01 16:41:10.205 INFO  ---- [er#1-0-C-1] [ConsumerCoordinator:280] invokeOnAssignment   [Consumer clientId=consumer-task.product.v1-3, groupId=task.product.v1] Notifying assignor about the new Assignment(partitions=[task-product-0])
2023-12-01 16:41:10.205 INFO  ---- [er#2-0-C-1] [ConsumerCoordinator:280] invokeOnAssignment   [Consumer clientId=consumer-order.group.v1-1, groupId=order.group.v1] Notifying assignor about the new Assignment(partitions=[order-0])
2023-12-01 16:41:10.208 INFO  ---- [er#2-0-C-1] [ConsumerCoordinator:292] invokePartitionsAssigned   [Consumer clientId=consumer-order.group.v1-1, groupId=order.group.v1] Adding newly assigned partitions: order-0
2023-12-01 16:41:10.208 INFO  ---- [er#0-0-C-1] [ConsumerCoordinator:292] invokePartitionsAssigned   [Consumer clientId=consumer-task.member.v1-2, groupId=task.member.v1] Adding newly assigned partitions: task-member-0
2023-12-01 16:41:10.208 INFO  ---- [er#1-0-C-1] [ConsumerCoordinator:292] invokePartitionsAssigned   [Consumer clientId=consumer-task.product.v1-3, groupId=task.product.v1] Adding newly assigned partitions: task-product-0
2023-12-01 16:41:10.222 INFO  ---- [er#1-0-C-1] [ConsumerCoordinator:851] refreshCommittedOffsetsIfNeeded   [Consumer clientId=consumer-task.product.v1-3, groupId=task.product.v1] Setting offset for partition task-product-0 to the committed offset FetchPosition{offset=1, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[127.0.0.1:9093 (id: 3 rack: null)], epoch=0}}
2023-12-01 16:41:10.222 INFO  ---- [er#2-0-C-1] [ConsumerCoordinator:851] refreshCommittedOffsetsIfNeeded   [Consumer clientId=consumer-order.group.v1-1, groupId=order.group.v1] Setting offset for partition order-0 to the committed offset FetchPosition{offset=6, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[127.0.0.1:9092 (id: 2 rack: null)], epoch=0}}
2023-12-01 16:41:10.222 INFO  ---- [er#0-0-C-1] [ConsumerCoordinator:851] refreshCommittedOffsetsIfNeeded   [Consumer clientId=consumer-task.member.v1-2, groupId=task.member.v1] Setting offset for partition task-member-0 to the committed offset FetchPosition{offset=13, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[127.0.0.1:9091 (id: 1 rack: null)], epoch=9}}
2023-12-01 16:41:10.223 INFO  ---- [er#1-0-C-1] [KafkaMessageListenerContainer:292] info   task.product.v1: partitions assigned: [task-product-0]
2023-12-01 16:41:10.223 INFO  ---- [er#0-0-C-1] [KafkaMessageListenerContainer:292] info   task.member.v1: partitions assigned: [task-member-0]
2023-12-01 16:41:10.223 INFO  ---- [er#2-0-C-1] [KafkaMessageListenerContainer:292] info   order.group.v1: partitions assigned: [order-0]
2023-12-01 16:41:10.304 INFO  ---- [er#2-0-C-1] [ProducerConfig:376] logAll   ProducerConfig values: 
	acks = -1
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-1
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2023-12-01 16:41:10.315 INFO  ---- [er#2-0-C-1] [KafkaProducer:572] configureTransactionState   [Producer clientId=producer-1] Instantiated an idempotent producer.
2023-12-01 16:41:10.333 INFO  ---- [er#2-0-C-1] [AppInfoParser:119] <init>   Kafka version: 3.1.2
2023-12-01 16:41:10.334 INFO  ---- [er#2-0-C-1] [AppInfoParser:120] <init>   Kafka commitId: f8c67dc3ae0a3265
2023-12-01 16:41:10.334 INFO  ---- [er#2-0-C-1] [AppInfoParser:121] <init>   Kafka startTimeMs: 1701416470333
2023-12-01 16:41:10.347 INFO  ---- [producer-1] [Metadata:402] updateLatestMetadata   [Producer clientId=producer-1] Resetting the last seen epoch of partition member-check-0 to 4 since the associated topicId changed from null to KYr4s4QASse48T8_YcW_QA
2023-12-01 16:41:10.348 INFO  ---- [producer-1] [Metadata:287] update   [Producer clientId=producer-1] Cluster ID: 5_U1uds-SGaR4vItj-jqUw
2023-12-01 16:41:10.349 INFO  ---- [producer-1] [TransactionManager:554] setProducerIdAndEpoch   [Producer clientId=producer-1] ProducerId set to 4026 with epoch 0
2023-12-01 16:41:50.206 INFO  ---- [producer-1] [Metadata:402] updateLatestMetadata   [Producer clientId=producer-1] Resetting the last seen epoch of partition product-check-0 to 0 since the associated topicId changed from null to Y1iKR5eGRsCHgtG8PgfcgA
2023-12-01 16:41:50.377 ERROR ---- [er#1-0-C-1] [OrderSubTaskConsumer:46] ProductTaskListener   taskListener Error message = {"taskId":"4c83c210-7850-4988-ae64-9a7e84033638","subTaskName":"validProductTask : 상품 유효성 검사","status":"FAIL","type":"PRODUCT","productId":269,"colorId":1,"quantity":3,"sizeId":271}
java.lang.NullPointerException: null
	at com.example.taskconsumer.consum.OrderSubTaskConsumer.setCountManager(OrderSubTaskConsumer.java:61)
	at com.example.taskconsumer.consum.OrderSubTaskConsumer.ProductTaskListener(OrderSubTaskConsumer.java:44)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
	at org.springframework.messaging.handler.invocation.InvocableHandlerMethod.doInvoke(InvocableHandlerMethod.java:169)
	at org.springframework.messaging.handler.invocation.InvocableHandlerMethod.invoke(InvocableHandlerMethod.java:119)
	at org.springframework.kafka.listener.adapter.HandlerAdapter.invoke(HandlerAdapter.java:56)
	at org.springframework.kafka.listener.adapter.MessagingMessageListenerAdapter.invokeHandler(MessagingMessageListenerAdapter.java:347)
	at org.springframework.kafka.listener.adapter.RecordMessagingMessageListenerAdapter.onMessage(RecordMessagingMessageListenerAdapter.java:92)
	at org.springframework.kafka.listener.adapter.RecordMessagingMessageListenerAdapter.onMessage(RecordMessagingMessageListenerAdapter.java:53)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeOnMessage(KafkaMessageListenerContainer.java:2670)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeOnMessage(KafkaMessageListenerContainer.java:2650)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeRecordListener(KafkaMessageListenerContainer.java:2577)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeWithRecords(KafkaMessageListenerContainer.java:2457)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeRecordListener(KafkaMessageListenerContainer.java:2335)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeListener(KafkaMessageListenerContainer.java:2006)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeIfHaveRecords(KafkaMessageListenerContainer.java:1375)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.pollAndInvoke(KafkaMessageListenerContainer.java:1366)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.run(KafkaMessageListenerContainer.java:1257)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.lang.Thread.run(Thread.java:834)
2023-12-01 16:49:00.303 INFO  ---- [tartedMain] [TaskConsumerApplication:55] logStarting   Starting TaskConsumerApplication using Java 11.0.13 on DESKTOP-MNMB87E with PID 12224 (C:\Users\tkdrb\IdeaProjects\ecommerce\task-consumer\build\classes\java\main started by tkdrb in C:\Users\tkdrb\IdeaProjects\ecommerce\task-consumer)
2023-12-01 16:49:00.305 INFO  ---- [tartedMain] [TaskConsumerApplication:631] logStartupProfileInfo   No active profile set, falling back to 1 default profile: "default"
2023-12-01 16:49:00.363 INFO  ---- [tartedMain] [DevToolsPropertyDefaultsPostProcessor:255] logTo   Devtools property defaults active! Set 'spring.devtools.add-properties' to 'false' to disable
2023-12-01 16:49:00.364 INFO  ---- [tartedMain] [DevToolsPropertyDefaultsPostProcessor:255] logTo   For additional web related logging consider setting the 'logging.level.web' property to 'DEBUG'
2023-12-01 16:49:01.648 INFO  ---- [tartedMain] [GenericScope:283] setSerializationId   BeanFactory id=7d336d03-7948-373b-80b2-3edd326128fe
2023-12-01 16:49:03.622 INFO  ---- [tartedMain] [TomcatWebServer:108] initialize   Tomcat initialized with port(s): 0 (http)
2023-12-01 16:49:03.644 INFO  ---- [tartedMain] [StandardService:173] log   Starting service [Tomcat]
2023-12-01 16:49:03.645 INFO  ---- [tartedMain] [StandardEngine:173] log   Starting Servlet engine: [Apache Tomcat/9.0.76]
2023-12-01 16:49:04.276 INFO  ---- [tartedMain] [[/]:173] log   Initializing Spring embedded WebApplicationContext
2023-12-01 16:49:04.276 INFO  ---- [tartedMain] [ServletWebServerApplicationContext:292] prepareWebApplicationContext   Root WebApplicationContext: initialization completed in 3902 ms
2023-12-01 16:49:05.122 WARN  ---- [tartedMain] [OptionalLiveReloadServer:62] startServer   Unable to start LiveReload server
2023-12-01 16:49:06.821 INFO  ---- [tartedMain] [DiscoveryClientOptionalArgsConfiguration:71] restTemplateDiscoveryClientOptionalArgs   Eureka HTTP Client uses RestTemplate.
2023-12-01 16:49:08.709 WARN  ---- [tartedMain] [LoadBalancerCacheAutoConfiguration$LoadBalancerCaffeineWarnLogger:83] logWarning   Spring Cloud LoadBalancer is currently working with the default cache. While this cache implementation is useful for development and tests, it's recommended to use Caffeine cache in production.You can switch to using Caffeine cache, by adding it and org.springframework.cache.caffeine.CaffeineCacheManager to the classpath.
2023-12-01 16:49:08.876 INFO  ---- [tartedMain] [ConsumerConfig:376] logAll   ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-order.group.v1-1
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = order.group.v1
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2023-12-01 16:49:09.216 INFO  ---- [tartedMain] [AppInfoParser:119] <init>   Kafka version: 3.1.2
2023-12-01 16:49:09.219 INFO  ---- [tartedMain] [AppInfoParser:120] <init>   Kafka commitId: f8c67dc3ae0a3265
2023-12-01 16:49:09.220 INFO  ---- [tartedMain] [AppInfoParser:121] <init>   Kafka startTimeMs: 1701416949207
2023-12-01 16:49:09.226 INFO  ---- [tartedMain] [KafkaConsumer:966] subscribe   [Consumer clientId=consumer-order.group.v1-1, groupId=order.group.v1] Subscribed to topic(s): order
2023-12-01 16:49:09.324 INFO  ---- [tartedMain] [ConsumerConfig:376] logAll   ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-task.member.v1-2
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = task.member.v1
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2023-12-01 16:49:09.340 INFO  ---- [tartedMain] [AppInfoParser:119] <init>   Kafka version: 3.1.2
2023-12-01 16:49:09.348 INFO  ---- [tartedMain] [AppInfoParser:120] <init>   Kafka commitId: f8c67dc3ae0a3265
2023-12-01 16:49:09.349 INFO  ---- [tartedMain] [AppInfoParser:121] <init>   Kafka startTimeMs: 1701416949340
2023-12-01 16:49:09.350 INFO  ---- [tartedMain] [KafkaConsumer:966] subscribe   [Consumer clientId=consumer-task.member.v1-2, groupId=task.member.v1] Subscribed to topic(s): task-member
2023-12-01 16:49:09.406 INFO  ---- [tartedMain] [ConsumerConfig:376] logAll   ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-task.product.v1-3
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = task.product.v1
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2023-12-01 16:49:09.431 INFO  ---- [tartedMain] [AppInfoParser:119] <init>   Kafka version: 3.1.2
2023-12-01 16:49:09.431 INFO  ---- [tartedMain] [AppInfoParser:120] <init>   Kafka commitId: f8c67dc3ae0a3265
2023-12-01 16:49:09.431 INFO  ---- [tartedMain] [AppInfoParser:121] <init>   Kafka startTimeMs: 1701416949431
2023-12-01 16:49:09.432 INFO  ---- [tartedMain] [KafkaConsumer:966] subscribe   [Consumer clientId=consumer-task.product.v1-3, groupId=task.product.v1] Subscribed to topic(s): task-product
2023-12-01 16:49:09.464 INFO  ---- [tartedMain] [TomcatWebServer:220] start   Tomcat started on port(s): 61638 (http) with context path ''
2023-12-01 16:49:09.465 INFO  ---- [tartedMain] [EurekaAutoServiceRegistration:144] onApplicationEvent   Updating port to 61638
2023-12-01 16:49:09.472 INFO  ---- [tartedMain] [InstanceInfoFactory:67] create   Setting initial instance status as: STARTING
2023-12-01 16:49:09.548 INFO  ---- [tartedMain] [DiscoveryClient:372] <init>   Initializing Eureka in region us-east-1
2023-12-01 16:49:09.564 INFO  ---- [tartedMain] [ConfigClusterResolver:43] getClusterEndpoints   Resolving eureka endpoints via configuration
2023-12-01 16:49:09.625 INFO  ---- [tartedMain] [DiscoveryClient:1007] fetchRegistry   Disable delta property : false
2023-12-01 16:49:09.627 INFO  ---- [tartedMain] [DiscoveryClient:1008] fetchRegistry   Single vip registry refresh property : null
2023-12-01 16:49:09.627 INFO  ---- [tartedMain] [DiscoveryClient:1009] fetchRegistry   Force full registry fetch : false
2023-12-01 16:49:09.627 INFO  ---- [tartedMain] [DiscoveryClient:1010] fetchRegistry   Application is null : false
2023-12-01 16:49:09.628 INFO  ---- [tartedMain] [DiscoveryClient:1011] fetchRegistry   Registered Applications size is zero : true
2023-12-01 16:49:09.629 INFO  ---- [tartedMain] [DiscoveryClient:1013] fetchRegistry   Application version is -1: true
2023-12-01 16:49:09.630 INFO  ---- [tartedMain] [DiscoveryClient:1097] getAndStoreFullRegistry   Getting all instance registry info from the eureka server
2023-12-01 16:49:10.161 INFO  ---- [er#0-0-C-1] [Metadata:402] updateLatestMetadata   [Consumer clientId=consumer-task.member.v1-2, groupId=task.member.v1] Resetting the last seen epoch of partition task-member-0 to 0 since the associated topicId changed from null to E7qrzAumTNaqvuwiYhCr-A
2023-12-01 16:49:10.170 INFO  ---- [er#0-0-C-1] [Metadata:287] update   [Consumer clientId=consumer-task.member.v1-2, groupId=task.member.v1] Cluster ID: 5_U1uds-SGaR4vItj-jqUw
2023-12-01 16:49:10.173 INFO  ---- [er#0-0-C-1] [ConsumerCoordinator:853] onSuccess   [Consumer clientId=consumer-task.member.v1-2, groupId=task.member.v1] Discovered group coordinator 127.0.0.1:9093 (id: 2147483644 rack: null)
2023-12-01 16:49:10.176 INFO  ---- [er#2-0-C-1] [Metadata:402] updateLatestMetadata   [Consumer clientId=consumer-order.group.v1-1, groupId=order.group.v1] Resetting the last seen epoch of partition order-0 to 0 since the associated topicId changed from null to 8AIo0qkzSIiGJbn1bQxAkw
2023-12-01 16:49:10.176 INFO  ---- [er#2-0-C-1] [Metadata:287] update   [Consumer clientId=consumer-order.group.v1-1, groupId=order.group.v1] Cluster ID: 5_U1uds-SGaR4vItj-jqUw
2023-12-01 16:49:10.177 INFO  ---- [er#1-0-C-1] [Metadata:402] updateLatestMetadata   [Consumer clientId=consumer-task.product.v1-3, groupId=task.product.v1] Resetting the last seen epoch of partition task-product-0 to 0 since the associated topicId changed from null to bIbTtjUjQhOPBTKjiX5Asw
2023-12-01 16:49:10.184 INFO  ---- [er#1-0-C-1] [Metadata:287] update   [Consumer clientId=consumer-task.product.v1-3, groupId=task.product.v1] Cluster ID: 5_U1uds-SGaR4vItj-jqUw
2023-12-01 16:49:10.184 INFO  ---- [er#1-0-C-1] [ConsumerCoordinator:853] onSuccess   [Consumer clientId=consumer-task.product.v1-3, groupId=task.product.v1] Discovered group coordinator 127.0.0.1:9091 (id: 2147483646 rack: null)
2023-12-01 16:49:10.177 INFO  ---- [er#2-0-C-1] [ConsumerCoordinator:853] onSuccess   [Consumer clientId=consumer-order.group.v1-1, groupId=order.group.v1] Discovered group coordinator 127.0.0.1:9091 (id: 2147483646 rack: null)
2023-12-01 16:49:10.186 INFO  ---- [er#2-0-C-1] [ConsumerCoordinator:535] sendJoinGroupRequest   [Consumer clientId=consumer-order.group.v1-1, groupId=order.group.v1] (Re-)joining group
2023-12-01 16:49:10.187 INFO  ---- [er#0-0-C-1] [ConsumerCoordinator:535] sendJoinGroupRequest   [Consumer clientId=consumer-task.member.v1-2, groupId=task.member.v1] (Re-)joining group
2023-12-01 16:49:10.190 INFO  ---- [er#1-0-C-1] [ConsumerCoordinator:535] sendJoinGroupRequest   [Consumer clientId=consumer-task.product.v1-3, groupId=task.product.v1] (Re-)joining group
2023-12-01 16:49:10.211 INFO  ---- [tartedMain] [DiscoveryClient:1106] getAndStoreFullRegistry   The response status is 200
2023-12-01 16:49:10.215 INFO  ---- [tartedMain] [DiscoveryClient:1321] initScheduledTasks   Starting heartbeat executor: renew interval is: 30
2023-12-01 16:49:10.219 INFO  ---- [tartedMain] [InstanceInfoReplicator:60] <init>   InstanceInfoReplicator onDemand update allowed rate per min is 4
2023-12-01 16:49:10.227 INFO  ---- [tartedMain] [DiscoveryClient:492] <init>   Discovery Client initialized at timestamp 1701416950225 with initial instances count: 5
2023-12-01 16:49:10.229 INFO  ---- [tartedMain] [EurekaServiceRegistry:41] register   Registering application TASK-SERVICE with eureka with status UP
2023-12-01 16:49:10.230 INFO  ---- [tartedMain] [DiscoveryClient:1352] notify   Saw local status change event StatusChangeEvent [timestamp=1701416950230, current=UP, previous=STARTING]
2023-12-01 16:49:10.243 INFO  ---- [plicator-0] [DiscoveryClient:873] register   DiscoveryClient_TASK-SERVICE/192.168.0.17:aa514d78c7d5b91ed2a49e75ca588c5c: registering service...
2023-12-01 16:49:10.312 INFO  ---- [er#1-0-C-1] [ConsumerCoordinator:1000] requestRejoin   [Consumer clientId=consumer-task.product.v1-3, groupId=task.product.v1] Request joining group due to: need to re-join with the given member-id
2023-12-01 16:49:10.312 INFO  ---- [er#0-0-C-1] [ConsumerCoordinator:1000] requestRejoin   [Consumer clientId=consumer-task.member.v1-2, groupId=task.member.v1] Request joining group due to: need to re-join with the given member-id
2023-12-01 16:49:10.312 INFO  ---- [er#2-0-C-1] [ConsumerCoordinator:1000] requestRejoin   [Consumer clientId=consumer-order.group.v1-1, groupId=order.group.v1] Request joining group due to: need to re-join with the given member-id
2023-12-01 16:49:10.313 INFO  ---- [er#1-0-C-1] [ConsumerCoordinator:535] sendJoinGroupRequest   [Consumer clientId=consumer-task.product.v1-3, groupId=task.product.v1] (Re-)joining group
2023-12-01 16:49:10.313 INFO  ---- [er#0-0-C-1] [ConsumerCoordinator:535] sendJoinGroupRequest   [Consumer clientId=consumer-task.member.v1-2, groupId=task.member.v1] (Re-)joining group
2023-12-01 16:49:10.313 INFO  ---- [er#2-0-C-1] [ConsumerCoordinator:535] sendJoinGroupRequest   [Consumer clientId=consumer-order.group.v1-1, groupId=order.group.v1] (Re-)joining group
2023-12-01 16:49:10.483 INFO  ---- [plicator-0] [DiscoveryClient:882] register   DiscoveryClient_TASK-SERVICE/192.168.0.17:aa514d78c7d5b91ed2a49e75ca588c5c - registration status: 204
2023-12-01 16:49:12.056 INFO  ---- [tartedMain] [TaskConsumerApplication:61] logStarted   Started TaskConsumerApplication in 13.818 seconds (JVM running for 14.709)
2023-12-01 16:49:13.323 INFO  ---- [er#1-0-C-1] [ConsumerCoordinator:595] handle   [Consumer clientId=consumer-task.product.v1-3, groupId=task.product.v1] Successfully joined group with generation Generation{generationId=1, memberId='consumer-task.product.v1-3-748bdebb-d2cb-4d61-9997-0aa0894608a1', protocol='range'}
2023-12-01 16:49:13.328 INFO  ---- [er#1-0-C-1] [ConsumerCoordinator:659] performAssignment   [Consumer clientId=consumer-task.product.v1-3, groupId=task.product.v1] Finished assignment for group at generation 1: {consumer-task.product.v1-3-748bdebb-d2cb-4d61-9997-0aa0894608a1=Assignment(partitions=[task-product-0])}
2023-12-01 16:49:13.331 INFO  ---- [er#2-0-C-1] [ConsumerCoordinator:595] handle   [Consumer clientId=consumer-order.group.v1-1, groupId=order.group.v1] Successfully joined group with generation Generation{generationId=22, memberId='consumer-order.group.v1-1-8d2fb7a8-dfe4-4064-aa67-82132d240314', protocol='range'}
2023-12-01 16:49:13.332 INFO  ---- [er#2-0-C-1] [ConsumerCoordinator:659] performAssignment   [Consumer clientId=consumer-order.group.v1-1, groupId=order.group.v1] Finished assignment for group at generation 22: {consumer-order.group.v1-1-8d2fb7a8-dfe4-4064-aa67-82132d240314=Assignment(partitions=[order-0])}
2023-12-01 16:49:13.336 INFO  ---- [er#0-0-C-1] [ConsumerCoordinator:595] handle   [Consumer clientId=consumer-task.member.v1-2, groupId=task.member.v1] Successfully joined group with generation Generation{generationId=1, memberId='consumer-task.member.v1-2-25a159b2-fd8e-4ad7-921b-321bd67f41a4', protocol='range'}
2023-12-01 16:49:13.337 INFO  ---- [er#0-0-C-1] [ConsumerCoordinator:659] performAssignment   [Consumer clientId=consumer-task.member.v1-2, groupId=task.member.v1] Finished assignment for group at generation 1: {consumer-task.member.v1-2-25a159b2-fd8e-4ad7-921b-321bd67f41a4=Assignment(partitions=[task-member-0])}
2023-12-01 16:49:13.346 INFO  ---- [er#1-0-C-1] [ConsumerCoordinator:761] handle   [Consumer clientId=consumer-task.product.v1-3, groupId=task.product.v1] Successfully synced group in generation Generation{generationId=1, memberId='consumer-task.product.v1-3-748bdebb-d2cb-4d61-9997-0aa0894608a1', protocol='range'}
2023-12-01 16:49:13.346 INFO  ---- [er#2-0-C-1] [ConsumerCoordinator:761] handle   [Consumer clientId=consumer-order.group.v1-1, groupId=order.group.v1] Successfully synced group in generation Generation{generationId=22, memberId='consumer-order.group.v1-1-8d2fb7a8-dfe4-4064-aa67-82132d240314', protocol='range'}
2023-12-01 16:49:13.346 INFO  ---- [er#0-0-C-1] [ConsumerCoordinator:761] handle   [Consumer clientId=consumer-task.member.v1-2, groupId=task.member.v1] Successfully synced group in generation Generation{generationId=1, memberId='consumer-task.member.v1-2-25a159b2-fd8e-4ad7-921b-321bd67f41a4', protocol='range'}
2023-12-01 16:49:13.347 INFO  ---- [er#2-0-C-1] [ConsumerCoordinator:280] invokeOnAssignment   [Consumer clientId=consumer-order.group.v1-1, groupId=order.group.v1] Notifying assignor about the new Assignment(partitions=[order-0])
2023-12-01 16:49:13.347 INFO  ---- [er#1-0-C-1] [ConsumerCoordinator:280] invokeOnAssignment   [Consumer clientId=consumer-task.product.v1-3, groupId=task.product.v1] Notifying assignor about the new Assignment(partitions=[task-product-0])
2023-12-01 16:49:13.347 INFO  ---- [er#0-0-C-1] [ConsumerCoordinator:280] invokeOnAssignment   [Consumer clientId=consumer-task.member.v1-2, groupId=task.member.v1] Notifying assignor about the new Assignment(partitions=[task-member-0])
2023-12-01 16:49:13.352 INFO  ---- [er#1-0-C-1] [ConsumerCoordinator:292] invokePartitionsAssigned   [Consumer clientId=consumer-task.product.v1-3, groupId=task.product.v1] Adding newly assigned partitions: task-product-0
2023-12-01 16:49:13.352 INFO  ---- [er#0-0-C-1] [ConsumerCoordinator:292] invokePartitionsAssigned   [Consumer clientId=consumer-task.member.v1-2, groupId=task.member.v1] Adding newly assigned partitions: task-member-0
2023-12-01 16:49:13.352 INFO  ---- [er#2-0-C-1] [ConsumerCoordinator:292] invokePartitionsAssigned   [Consumer clientId=consumer-order.group.v1-1, groupId=order.group.v1] Adding newly assigned partitions: order-0
2023-12-01 16:49:13.374 INFO  ---- [er#1-0-C-1] [ConsumerCoordinator:1405] handle   [Consumer clientId=consumer-task.product.v1-3, groupId=task.product.v1] Found no committed offset for partition task-product-0
2023-12-01 16:49:13.374 INFO  ---- [er#0-0-C-1] [ConsumerCoordinator:1405] handle   [Consumer clientId=consumer-task.member.v1-2, groupId=task.member.v1] Found no committed offset for partition task-member-0
2023-12-01 16:49:13.382 INFO  ---- [er#1-0-C-1] [ConsumerCoordinator:1405] handle   [Consumer clientId=consumer-task.product.v1-3, groupId=task.product.v1] Found no committed offset for partition task-product-0
2023-12-01 16:49:13.382 INFO  ---- [er#0-0-C-1] [ConsumerCoordinator:1405] handle   [Consumer clientId=consumer-task.member.v1-2, groupId=task.member.v1] Found no committed offset for partition task-member-0
2023-12-01 16:49:13.385 INFO  ---- [er#2-0-C-1] [ConsumerCoordinator:851] refreshCommittedOffsetsIfNeeded   [Consumer clientId=consumer-order.group.v1-1, groupId=order.group.v1] Setting offset for partition order-0 to the committed offset FetchPosition{offset=6, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[127.0.0.1:9092 (id: 2 rack: null)], epoch=0}}
2023-12-01 16:49:13.386 INFO  ---- [er#2-0-C-1] [KafkaMessageListenerContainer:292] info   order.group.v1: partitions assigned: [order-0]
2023-12-01 16:49:13.409 INFO  ---- [er#1-0-C-1] [SubscriptionState:398] maybeSeekUnvalidated   [Consumer clientId=consumer-task.product.v1-3, groupId=task.product.v1] Resetting offset for partition task-product-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[127.0.0.1:9093 (id: 3 rack: null)], epoch=0}}.
2023-12-01 16:49:13.409 INFO  ---- [er#0-0-C-1] [SubscriptionState:398] maybeSeekUnvalidated   [Consumer clientId=consumer-task.member.v1-2, groupId=task.member.v1] Resetting offset for partition task-member-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[127.0.0.1:9093 (id: 3 rack: null)], epoch=0}}.
2023-12-01 16:49:13.420 INFO  ---- [er#1-0-C-1] [KafkaMessageListenerContainer:292] info   task.product.v1: partitions assigned: [task-product-0]
2023-12-01 16:49:13.420 INFO  ---- [er#0-0-C-1] [KafkaMessageListenerContainer:292] info   task.member.v1: partitions assigned: [task-member-0]
2023-12-01 16:49:13.494 INFO  ---- [er#2-0-C-1] [ProducerConfig:376] logAll   ProducerConfig values: 
	acks = -1
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-1
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2023-12-01 16:49:13.507 INFO  ---- [er#2-0-C-1] [KafkaProducer:572] configureTransactionState   [Producer clientId=producer-1] Instantiated an idempotent producer.
2023-12-01 16:49:13.531 INFO  ---- [er#2-0-C-1] [AppInfoParser:119] <init>   Kafka version: 3.1.2
2023-12-01 16:49:13.531 INFO  ---- [er#2-0-C-1] [AppInfoParser:120] <init>   Kafka commitId: f8c67dc3ae0a3265
2023-12-01 16:49:13.531 INFO  ---- [er#2-0-C-1] [AppInfoParser:121] <init>   Kafka startTimeMs: 1701416953531
2023-12-01 16:49:13.545 INFO  ---- [producer-1] [Metadata:402] updateLatestMetadata   [Producer clientId=producer-1] Resetting the last seen epoch of partition member-check-0 to 0 since the associated topicId changed from null to wGkJy8HQR9S9DeSNaFT1sQ
2023-12-01 16:49:13.546 INFO  ---- [producer-1] [Metadata:287] update   [Producer clientId=producer-1] Cluster ID: 5_U1uds-SGaR4vItj-jqUw
2023-12-01 16:49:13.547 INFO  ---- [producer-1] [TransactionManager:554] setProducerIdAndEpoch   [Producer clientId=producer-1] ProducerId set to 4029 with epoch 0
2023-12-01 16:54:19.524 INFO  ---- [tartedMain] [TaskConsumerApplication:55] logStarting   Starting TaskConsumerApplication using Java 11.0.13 on DESKTOP-MNMB87E with PID 23396 (C:\Users\tkdrb\IdeaProjects\ecommerce\task-consumer\build\classes\java\main started by tkdrb in C:\Users\tkdrb\IdeaProjects\ecommerce\task-consumer)
2023-12-01 16:54:19.528 INFO  ---- [tartedMain] [TaskConsumerApplication:631] logStartupProfileInfo   No active profile set, falling back to 1 default profile: "default"
2023-12-01 16:54:19.629 INFO  ---- [tartedMain] [DevToolsPropertyDefaultsPostProcessor:255] logTo   Devtools property defaults active! Set 'spring.devtools.add-properties' to 'false' to disable
2023-12-01 16:54:19.629 INFO  ---- [tartedMain] [DevToolsPropertyDefaultsPostProcessor:255] logTo   For additional web related logging consider setting the 'logging.level.web' property to 'DEBUG'
2023-12-01 16:54:20.693 INFO  ---- [tartedMain] [GenericScope:283] setSerializationId   BeanFactory id=7d336d03-7948-373b-80b2-3edd326128fe
2023-12-01 16:54:22.282 INFO  ---- [tartedMain] [TomcatWebServer:108] initialize   Tomcat initialized with port(s): 0 (http)
2023-12-01 16:54:22.299 INFO  ---- [tartedMain] [StandardService:173] log   Starting service [Tomcat]
2023-12-01 16:54:22.300 INFO  ---- [tartedMain] [StandardEngine:173] log   Starting Servlet engine: [Apache Tomcat/9.0.76]
2023-12-01 16:54:22.541 INFO  ---- [tartedMain] [[/]:173] log   Initializing Spring embedded WebApplicationContext
2023-12-01 16:54:22.541 INFO  ---- [tartedMain] [ServletWebServerApplicationContext:292] prepareWebApplicationContext   Root WebApplicationContext: initialization completed in 2911 ms
2023-12-01 16:54:23.410 INFO  ---- [tartedMain] [OptionalLiveReloadServer:59] startServer   LiveReload server is running on port 35729
2023-12-01 16:54:24.567 INFO  ---- [tartedMain] [DiscoveryClientOptionalArgsConfiguration:71] restTemplateDiscoveryClientOptionalArgs   Eureka HTTP Client uses RestTemplate.
2023-12-01 16:54:25.936 WARN  ---- [tartedMain] [LoadBalancerCacheAutoConfiguration$LoadBalancerCaffeineWarnLogger:83] logWarning   Spring Cloud LoadBalancer is currently working with the default cache. While this cache implementation is useful for development and tests, it's recommended to use Caffeine cache in production.You can switch to using Caffeine cache, by adding it and org.springframework.cache.caffeine.CaffeineCacheManager to the classpath.
2023-12-01 16:54:26.070 INFO  ---- [tartedMain] [ConsumerConfig:376] logAll   ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-order.group.v1-1
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = order.group.v1
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2023-12-01 16:54:26.280 INFO  ---- [tartedMain] [AppInfoParser:119] <init>   Kafka version: 3.1.2
2023-12-01 16:54:26.282 INFO  ---- [tartedMain] [AppInfoParser:120] <init>   Kafka commitId: f8c67dc3ae0a3265
2023-12-01 16:54:26.283 INFO  ---- [tartedMain] [AppInfoParser:121] <init>   Kafka startTimeMs: 1701417266276
2023-12-01 16:54:26.287 INFO  ---- [tartedMain] [KafkaConsumer:966] subscribe   [Consumer clientId=consumer-order.group.v1-1, groupId=order.group.v1] Subscribed to topic(s): order
2023-12-01 16:54:26.308 INFO  ---- [tartedMain] [ConsumerConfig:376] logAll   ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-task.product.v1-2
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = task.product.v1
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2023-12-01 16:54:26.320 INFO  ---- [tartedMain] [AppInfoParser:119] <init>   Kafka version: 3.1.2
2023-12-01 16:54:26.321 INFO  ---- [tartedMain] [AppInfoParser:120] <init>   Kafka commitId: f8c67dc3ae0a3265
2023-12-01 16:54:26.322 INFO  ---- [tartedMain] [AppInfoParser:121] <init>   Kafka startTimeMs: 1701417266320
2023-12-01 16:54:26.322 INFO  ---- [tartedMain] [KafkaConsumer:966] subscribe   [Consumer clientId=consumer-task.product.v1-2, groupId=task.product.v1] Subscribed to topic(s): task-product
2023-12-01 16:54:26.327 INFO  ---- [tartedMain] [ConsumerConfig:376] logAll   ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-task.member.v1-3
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = task.member.v1
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2023-12-01 16:54:26.337 INFO  ---- [tartedMain] [AppInfoParser:119] <init>   Kafka version: 3.1.2
2023-12-01 16:54:26.337 INFO  ---- [tartedMain] [AppInfoParser:120] <init>   Kafka commitId: f8c67dc3ae0a3265
2023-12-01 16:54:26.337 INFO  ---- [tartedMain] [AppInfoParser:121] <init>   Kafka startTimeMs: 1701417266337
2023-12-01 16:54:26.338 INFO  ---- [tartedMain] [KafkaConsumer:966] subscribe   [Consumer clientId=consumer-task.member.v1-3, groupId=task.member.v1] Subscribed to topic(s): task-member
2023-12-01 16:54:26.375 INFO  ---- [tartedMain] [TomcatWebServer:220] start   Tomcat started on port(s): 61800 (http) with context path ''
2023-12-01 16:54:26.378 INFO  ---- [tartedMain] [EurekaAutoServiceRegistration:144] onApplicationEvent   Updating port to 61800
2023-12-01 16:54:26.384 INFO  ---- [tartedMain] [InstanceInfoFactory:67] create   Setting initial instance status as: STARTING
2023-12-01 16:54:26.465 INFO  ---- [tartedMain] [DiscoveryClient:372] <init>   Initializing Eureka in region us-east-1
2023-12-01 16:54:26.482 INFO  ---- [tartedMain] [ConfigClusterResolver:43] getClusterEndpoints   Resolving eureka endpoints via configuration
2023-12-01 16:54:26.519 INFO  ---- [tartedMain] [DiscoveryClient:1007] fetchRegistry   Disable delta property : false
2023-12-01 16:54:26.519 INFO  ---- [tartedMain] [DiscoveryClient:1008] fetchRegistry   Single vip registry refresh property : null
2023-12-01 16:54:26.520 INFO  ---- [tartedMain] [DiscoveryClient:1009] fetchRegistry   Force full registry fetch : false
2023-12-01 16:54:26.520 INFO  ---- [tartedMain] [DiscoveryClient:1010] fetchRegistry   Application is null : false
2023-12-01 16:54:26.520 INFO  ---- [tartedMain] [DiscoveryClient:1011] fetchRegistry   Registered Applications size is zero : true
2023-12-01 16:54:26.520 INFO  ---- [tartedMain] [DiscoveryClient:1013] fetchRegistry   Application version is -1: true
2023-12-01 16:54:26.520 INFO  ---- [tartedMain] [DiscoveryClient:1097] getAndStoreFullRegistry   Getting all instance registry info from the eureka server
2023-12-01 16:54:26.829 INFO  ---- [er#0-0-C-1] [Metadata:402] updateLatestMetadata   [Consumer clientId=consumer-task.product.v1-2, groupId=task.product.v1] Resetting the last seen epoch of partition task-product-0 to 0 since the associated topicId changed from null to bIbTtjUjQhOPBTKjiX5Asw
2023-12-01 16:54:26.829 INFO  ---- [er#1-0-C-1] [Metadata:402] updateLatestMetadata   [Consumer clientId=consumer-task.member.v1-3, groupId=task.member.v1] Resetting the last seen epoch of partition task-member-0 to 0 since the associated topicId changed from null to E7qrzAumTNaqvuwiYhCr-A
2023-12-01 16:54:26.829 INFO  ---- [er#2-0-C-1] [Metadata:402] updateLatestMetadata   [Consumer clientId=consumer-order.group.v1-1, groupId=order.group.v1] Resetting the last seen epoch of partition order-0 to 0 since the associated topicId changed from null to wkdBkssoTPWL_MV60_W2Sg
2023-12-01 16:54:26.833 INFO  ---- [er#1-0-C-1] [Metadata:287] update   [Consumer clientId=consumer-task.member.v1-3, groupId=task.member.v1] Cluster ID: 5_U1uds-SGaR4vItj-jqUw
2023-12-01 16:54:26.833 INFO  ---- [er#0-0-C-1] [Metadata:287] update   [Consumer clientId=consumer-task.product.v1-2, groupId=task.product.v1] Cluster ID: 5_U1uds-SGaR4vItj-jqUw
2023-12-01 16:54:26.833 INFO  ---- [er#2-0-C-1] [Metadata:287] update   [Consumer clientId=consumer-order.group.v1-1, groupId=order.group.v1] Cluster ID: 5_U1uds-SGaR4vItj-jqUw
2023-12-01 16:54:26.835 INFO  ---- [er#0-0-C-1] [ConsumerCoordinator:853] onSuccess   [Consumer clientId=consumer-task.product.v1-2, groupId=task.product.v1] Discovered group coordinator 127.0.0.1:9091 (id: 2147483646 rack: null)
2023-12-01 16:54:26.835 INFO  ---- [er#2-0-C-1] [ConsumerCoordinator:853] onSuccess   [Consumer clientId=consumer-order.group.v1-1, groupId=order.group.v1] Discovered group coordinator 127.0.0.1:9091 (id: 2147483646 rack: null)
2023-12-01 16:54:26.835 INFO  ---- [er#1-0-C-1] [ConsumerCoordinator:853] onSuccess   [Consumer clientId=consumer-task.member.v1-3, groupId=task.member.v1] Discovered group coordinator 127.0.0.1:9093 (id: 2147483644 rack: null)
2023-12-01 16:54:26.840 INFO  ---- [er#0-0-C-1] [ConsumerCoordinator:535] sendJoinGroupRequest   [Consumer clientId=consumer-task.product.v1-2, groupId=task.product.v1] (Re-)joining group
2023-12-01 16:54:26.840 INFO  ---- [er#1-0-C-1] [ConsumerCoordinator:535] sendJoinGroupRequest   [Consumer clientId=consumer-task.member.v1-3, groupId=task.member.v1] (Re-)joining group
2023-12-01 16:54:26.840 INFO  ---- [er#2-0-C-1] [ConsumerCoordinator:535] sendJoinGroupRequest   [Consumer clientId=consumer-order.group.v1-1, groupId=order.group.v1] (Re-)joining group
2023-12-01 16:54:26.880 INFO  ---- [er#0-0-C-1] [ConsumerCoordinator:1000] requestRejoin   [Consumer clientId=consumer-task.product.v1-2, groupId=task.product.v1] Request joining group due to: need to re-join with the given member-id
2023-12-01 16:54:26.880 INFO  ---- [er#2-0-C-1] [ConsumerCoordinator:1000] requestRejoin   [Consumer clientId=consumer-order.group.v1-1, groupId=order.group.v1] Request joining group due to: need to re-join with the given member-id
2023-12-01 16:54:26.880 INFO  ---- [er#1-0-C-1] [ConsumerCoordinator:1000] requestRejoin   [Consumer clientId=consumer-task.member.v1-3, groupId=task.member.v1] Request joining group due to: need to re-join with the given member-id
2023-12-01 16:54:26.881 INFO  ---- [er#0-0-C-1] [ConsumerCoordinator:535] sendJoinGroupRequest   [Consumer clientId=consumer-task.product.v1-2, groupId=task.product.v1] (Re-)joining group
2023-12-01 16:54:26.881 INFO  ---- [er#2-0-C-1] [ConsumerCoordinator:535] sendJoinGroupRequest   [Consumer clientId=consumer-order.group.v1-1, groupId=order.group.v1] (Re-)joining group
2023-12-01 16:54:26.881 INFO  ---- [er#1-0-C-1] [ConsumerCoordinator:535] sendJoinGroupRequest   [Consumer clientId=consumer-task.member.v1-3, groupId=task.member.v1] (Re-)joining group
2023-12-01 16:54:26.942 INFO  ---- [tartedMain] [DiscoveryClient:1106] getAndStoreFullRegistry   The response status is 200
2023-12-01 16:54:26.946 INFO  ---- [tartedMain] [DiscoveryClient:1321] initScheduledTasks   Starting heartbeat executor: renew interval is: 30
2023-12-01 16:54:26.951 INFO  ---- [tartedMain] [InstanceInfoReplicator:60] <init>   InstanceInfoReplicator onDemand update allowed rate per min is 4
2023-12-01 16:54:26.959 INFO  ---- [tartedMain] [DiscoveryClient:492] <init>   Discovery Client initialized at timestamp 1701417266958 with initial instances count: 5
2023-12-01 16:54:26.962 INFO  ---- [tartedMain] [EurekaServiceRegistry:41] register   Registering application TASK-SERVICE with eureka with status UP
2023-12-01 16:54:26.963 INFO  ---- [tartedMain] [DiscoveryClient:1352] notify   Saw local status change event StatusChangeEvent [timestamp=1701417266962, current=UP, previous=STARTING]
2023-12-01 16:54:26.966 INFO  ---- [plicator-0] [DiscoveryClient:873] register   DiscoveryClient_TASK-SERVICE/192.168.0.17:9120e3ccdbd2659326e66823b1b4aba8: registering service...
2023-12-01 16:54:27.027 INFO  ---- [plicator-0] [DiscoveryClient:882] register   DiscoveryClient_TASK-SERVICE/192.168.0.17:9120e3ccdbd2659326e66823b1b4aba8 - registration status: 204
2023-12-01 16:54:28.132 INFO  ---- [tartedMain] [TaskConsumerApplication:61] logStarted   Started TaskConsumerApplication in 10.299 seconds (JVM running for 10.932)
2023-12-01 16:54:29.889 INFO  ---- [er#0-0-C-1] [ConsumerCoordinator:595] handle   [Consumer clientId=consumer-task.product.v1-2, groupId=task.product.v1] Successfully joined group with generation Generation{generationId=3, memberId='consumer-task.product.v1-2-b65ecc4e-e239-45e7-928c-9c582217a7e5', protocol='range'}
2023-12-01 16:54:29.889 INFO  ---- [er#2-0-C-1] [ConsumerCoordinator:595] handle   [Consumer clientId=consumer-order.group.v1-1, groupId=order.group.v1] Successfully joined group with generation Generation{generationId=24, memberId='consumer-order.group.v1-1-fa9e6479-e9b3-4e3e-a484-a20f075e3303', protocol='range'}
2023-12-01 16:54:29.889 INFO  ---- [er#1-0-C-1] [ConsumerCoordinator:595] handle   [Consumer clientId=consumer-task.member.v1-3, groupId=task.member.v1] Successfully joined group with generation Generation{generationId=3, memberId='consumer-task.member.v1-3-8a21c91e-ae4b-40c5-9830-cdb18e08ec5b', protocol='range'}
2023-12-01 16:54:29.893 INFO  ---- [er#0-0-C-1] [ConsumerCoordinator:659] performAssignment   [Consumer clientId=consumer-task.product.v1-2, groupId=task.product.v1] Finished assignment for group at generation 3: {consumer-task.product.v1-2-b65ecc4e-e239-45e7-928c-9c582217a7e5=Assignment(partitions=[task-product-0])}
2023-12-01 16:54:29.893 INFO  ---- [er#1-0-C-1] [ConsumerCoordinator:659] performAssignment   [Consumer clientId=consumer-task.member.v1-3, groupId=task.member.v1] Finished assignment for group at generation 3: {consumer-task.member.v1-3-8a21c91e-ae4b-40c5-9830-cdb18e08ec5b=Assignment(partitions=[task-member-0])}
2023-12-01 16:54:29.893 INFO  ---- [er#2-0-C-1] [ConsumerCoordinator:659] performAssignment   [Consumer clientId=consumer-order.group.v1-1, groupId=order.group.v1] Finished assignment for group at generation 24: {consumer-order.group.v1-1-fa9e6479-e9b3-4e3e-a484-a20f075e3303=Assignment(partitions=[order-0])}
2023-12-01 16:54:29.907 INFO  ---- [er#0-0-C-1] [ConsumerCoordinator:761] handle   [Consumer clientId=consumer-task.product.v1-2, groupId=task.product.v1] Successfully synced group in generation Generation{generationId=3, memberId='consumer-task.product.v1-2-b65ecc4e-e239-45e7-928c-9c582217a7e5', protocol='range'}
2023-12-01 16:54:29.907 INFO  ---- [er#1-0-C-1] [ConsumerCoordinator:761] handle   [Consumer clientId=consumer-task.member.v1-3, groupId=task.member.v1] Successfully synced group in generation Generation{generationId=3, memberId='consumer-task.member.v1-3-8a21c91e-ae4b-40c5-9830-cdb18e08ec5b', protocol='range'}
2023-12-01 16:54:29.908 INFO  ---- [er#1-0-C-1] [ConsumerCoordinator:280] invokeOnAssignment   [Consumer clientId=consumer-task.member.v1-3, groupId=task.member.v1] Notifying assignor about the new Assignment(partitions=[task-member-0])
2023-12-01 16:54:29.908 INFO  ---- [er#2-0-C-1] [ConsumerCoordinator:761] handle   [Consumer clientId=consumer-order.group.v1-1, groupId=order.group.v1] Successfully synced group in generation Generation{generationId=24, memberId='consumer-order.group.v1-1-fa9e6479-e9b3-4e3e-a484-a20f075e3303', protocol='range'}
2023-12-01 16:54:29.908 INFO  ---- [er#0-0-C-1] [ConsumerCoordinator:280] invokeOnAssignment   [Consumer clientId=consumer-task.product.v1-2, groupId=task.product.v1] Notifying assignor about the new Assignment(partitions=[task-product-0])
2023-12-01 16:54:29.909 INFO  ---- [er#2-0-C-1] [ConsumerCoordinator:280] invokeOnAssignment   [Consumer clientId=consumer-order.group.v1-1, groupId=order.group.v1] Notifying assignor about the new Assignment(partitions=[order-0])
2023-12-01 16:54:29.913 INFO  ---- [er#0-0-C-1] [ConsumerCoordinator:292] invokePartitionsAssigned   [Consumer clientId=consumer-task.product.v1-2, groupId=task.product.v1] Adding newly assigned partitions: task-product-0
2023-12-01 16:54:29.913 INFO  ---- [er#2-0-C-1] [ConsumerCoordinator:292] invokePartitionsAssigned   [Consumer clientId=consumer-order.group.v1-1, groupId=order.group.v1] Adding newly assigned partitions: order-0
2023-12-01 16:54:29.913 INFO  ---- [er#1-0-C-1] [ConsumerCoordinator:292] invokePartitionsAssigned   [Consumer clientId=consumer-task.member.v1-3, groupId=task.member.v1] Adding newly assigned partitions: task-member-0
2023-12-01 16:54:29.923 INFO  ---- [er#2-0-C-1] [ConsumerCoordinator:1405] handle   [Consumer clientId=consumer-order.group.v1-1, groupId=order.group.v1] Found no committed offset for partition order-0
2023-12-01 16:54:29.930 INFO  ---- [er#2-0-C-1] [ConsumerCoordinator:1405] handle   [Consumer clientId=consumer-order.group.v1-1, groupId=order.group.v1] Found no committed offset for partition order-0
2023-12-01 16:54:29.932 INFO  ---- [er#0-0-C-1] [ConsumerCoordinator:851] refreshCommittedOffsetsIfNeeded   [Consumer clientId=consumer-task.product.v1-2, groupId=task.product.v1] Setting offset for partition task-product-0 to the committed offset FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[127.0.0.1:9093 (id: 3 rack: null)], epoch=0}}
2023-12-01 16:54:29.932 INFO  ---- [er#1-0-C-1] [ConsumerCoordinator:851] refreshCommittedOffsetsIfNeeded   [Consumer clientId=consumer-task.member.v1-3, groupId=task.member.v1] Setting offset for partition task-member-0 to the committed offset FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[127.0.0.1:9093 (id: 3 rack: null)], epoch=0}}
2023-12-01 16:54:29.933 INFO  ---- [er#1-0-C-1] [KafkaMessageListenerContainer:292] info   task.member.v1: partitions assigned: [task-member-0]
2023-12-01 16:54:29.933 INFO  ---- [er#0-0-C-1] [KafkaMessageListenerContainer:292] info   task.product.v1: partitions assigned: [task-product-0]
2023-12-01 16:54:29.950 INFO  ---- [er#2-0-C-1] [SubscriptionState:398] maybeSeekUnvalidated   [Consumer clientId=consumer-order.group.v1-1, groupId=order.group.v1] Resetting offset for partition order-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[127.0.0.1:9092 (id: 2 rack: null)], epoch=0}}.
2023-12-01 16:54:29.960 INFO  ---- [er#2-0-C-1] [KafkaMessageListenerContainer:292] info   order.group.v1: partitions assigned: [order-0]
2023-12-01 16:55:40.770 INFO  ---- [er#2-0-C-1] [ProducerConfig:376] logAll   ProducerConfig values: 
	acks = -1
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-1
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2023-12-01 16:55:40.779 INFO  ---- [er#2-0-C-1] [KafkaProducer:572] configureTransactionState   [Producer clientId=producer-1] Instantiated an idempotent producer.
2023-12-01 16:55:40.795 INFO  ---- [er#2-0-C-1] [AppInfoParser:119] <init>   Kafka version: 3.1.2
2023-12-01 16:55:40.796 INFO  ---- [er#2-0-C-1] [AppInfoParser:120] <init>   Kafka commitId: f8c67dc3ae0a3265
2023-12-01 16:55:40.796 INFO  ---- [er#2-0-C-1] [AppInfoParser:121] <init>   Kafka startTimeMs: 1701417340795
2023-12-01 16:55:40.806 INFO  ---- [producer-1] [Metadata:402] updateLatestMetadata   [Producer clientId=producer-1] Resetting the last seen epoch of partition member-check-0 to 0 since the associated topicId changed from null to wGkJy8HQR9S9DeSNaFT1sQ
2023-12-01 16:55:40.807 INFO  ---- [producer-1] [Metadata:287] update   [Producer clientId=producer-1] Cluster ID: 5_U1uds-SGaR4vItj-jqUw
2023-12-01 16:55:40.808 INFO  ---- [producer-1] [TransactionManager:554] setProducerIdAndEpoch   [Producer clientId=producer-1] ProducerId set to 4032 with epoch 0
2023-12-01 16:55:41.138 INFO  ---- [producer-1] [Metadata:402] updateLatestMetadata   [Producer clientId=producer-1] Resetting the last seen epoch of partition product-check-0 to 0 since the associated topicId changed from null to 47KrZrVNRT-GSFQ_B1uyRA
2023-12-01 16:55:41.383 ERROR ---- [er#0-0-C-1] [OrderSubTaskConsumer:46] ProductTaskListener   taskListener Error message = {"taskId":"673ebb90-ac9f-4780-9e3f-5d2b8f824f4e","subTaskName":"validProductTask : 상품 유효성 검사","status":"FAIL","type":"PRODUCT","productId":269,"colorId":1,"quantity":3,"sizeId":271}
java.lang.NullPointerException: null
	at com.example.taskconsumer.consum.OrderSubTaskConsumer.setCountManager(OrderSubTaskConsumer.java:61)
	at com.example.taskconsumer.consum.OrderSubTaskConsumer.ProductTaskListener(OrderSubTaskConsumer.java:44)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
	at org.springframework.messaging.handler.invocation.InvocableHandlerMethod.doInvoke(InvocableHandlerMethod.java:169)
	at org.springframework.messaging.handler.invocation.InvocableHandlerMethod.invoke(InvocableHandlerMethod.java:119)
	at org.springframework.kafka.listener.adapter.HandlerAdapter.invoke(HandlerAdapter.java:56)
	at org.springframework.kafka.listener.adapter.MessagingMessageListenerAdapter.invokeHandler(MessagingMessageListenerAdapter.java:347)
	at org.springframework.kafka.listener.adapter.RecordMessagingMessageListenerAdapter.onMessage(RecordMessagingMessageListenerAdapter.java:92)
	at org.springframework.kafka.listener.adapter.RecordMessagingMessageListenerAdapter.onMessage(RecordMessagingMessageListenerAdapter.java:53)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeOnMessage(KafkaMessageListenerContainer.java:2670)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeOnMessage(KafkaMessageListenerContainer.java:2650)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeRecordListener(KafkaMessageListenerContainer.java:2577)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeWithRecords(KafkaMessageListenerContainer.java:2457)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeRecordListener(KafkaMessageListenerContainer.java:2335)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeListener(KafkaMessageListenerContainer.java:2006)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeIfHaveRecords(KafkaMessageListenerContainer.java:1375)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.pollAndInvoke(KafkaMessageListenerContainer.java:1366)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.run(KafkaMessageListenerContainer.java:1257)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.lang.Thread.run(Thread.java:834)
2023-12-01 16:57:46.515 INFO  ---- [tartedMain] [TaskConsumerApplication:55] logStarting   Starting TaskConsumerApplication using Java 11.0.13 on DESKTOP-MNMB87E with PID 35464 (C:\Users\tkdrb\IdeaProjects\ecommerce\task-consumer\build\classes\java\main started by tkdrb in C:\Users\tkdrb\IdeaProjects\ecommerce\task-consumer)
2023-12-01 16:57:46.518 INFO  ---- [tartedMain] [TaskConsumerApplication:631] logStartupProfileInfo   No active profile set, falling back to 1 default profile: "default"
2023-12-01 16:57:46.602 INFO  ---- [tartedMain] [DevToolsPropertyDefaultsPostProcessor:255] logTo   Devtools property defaults active! Set 'spring.devtools.add-properties' to 'false' to disable
2023-12-01 16:57:46.603 INFO  ---- [tartedMain] [DevToolsPropertyDefaultsPostProcessor:255] logTo   For additional web related logging consider setting the 'logging.level.web' property to 'DEBUG'
2023-12-01 16:57:48.094 INFO  ---- [tartedMain] [GenericScope:283] setSerializationId   BeanFactory id=7d336d03-7948-373b-80b2-3edd326128fe
2023-12-01 16:57:49.700 INFO  ---- [tartedMain] [TomcatWebServer:108] initialize   Tomcat initialized with port(s): 0 (http)
2023-12-01 16:57:49.718 INFO  ---- [tartedMain] [StandardService:173] log   Starting service [Tomcat]
2023-12-01 16:57:49.719 INFO  ---- [tartedMain] [StandardEngine:173] log   Starting Servlet engine: [Apache Tomcat/9.0.76]
2023-12-01 16:57:49.958 INFO  ---- [tartedMain] [[/]:173] log   Initializing Spring embedded WebApplicationContext
2023-12-01 16:57:49.958 INFO  ---- [tartedMain] [ServletWebServerApplicationContext:292] prepareWebApplicationContext   Root WebApplicationContext: initialization completed in 3353 ms
2023-12-01 16:57:50.842 WARN  ---- [tartedMain] [OptionalLiveReloadServer:62] startServer   Unable to start LiveReload server
2023-12-01 16:57:52.287 INFO  ---- [tartedMain] [DiscoveryClientOptionalArgsConfiguration:71] restTemplateDiscoveryClientOptionalArgs   Eureka HTTP Client uses RestTemplate.
2023-12-01 16:57:53.574 WARN  ---- [tartedMain] [LoadBalancerCacheAutoConfiguration$LoadBalancerCaffeineWarnLogger:83] logWarning   Spring Cloud LoadBalancer is currently working with the default cache. While this cache implementation is useful for development and tests, it's recommended to use Caffeine cache in production.You can switch to using Caffeine cache, by adding it and org.springframework.cache.caffeine.CaffeineCacheManager to the classpath.
2023-12-01 16:57:53.681 INFO  ---- [tartedMain] [ConsumerConfig:376] logAll   ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-order.group.v1-1
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = order.group.v1
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2023-12-01 16:57:53.813 INFO  ---- [tartedMain] [AppInfoParser:119] <init>   Kafka version: 3.1.2
2023-12-01 16:57:53.815 INFO  ---- [tartedMain] [AppInfoParser:120] <init>   Kafka commitId: f8c67dc3ae0a3265
2023-12-01 16:57:53.815 INFO  ---- [tartedMain] [AppInfoParser:121] <init>   Kafka startTimeMs: 1701417473811
2023-12-01 16:57:53.818 INFO  ---- [tartedMain] [KafkaConsumer:966] subscribe   [Consumer clientId=consumer-order.group.v1-1, groupId=order.group.v1] Subscribed to topic(s): order
2023-12-01 16:57:53.832 INFO  ---- [tartedMain] [ConsumerConfig:376] logAll   ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-task.member.v1-2
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = task.member.v1
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2023-12-01 16:57:53.842 INFO  ---- [tartedMain] [AppInfoParser:119] <init>   Kafka version: 3.1.2
2023-12-01 16:57:53.843 INFO  ---- [tartedMain] [AppInfoParser:120] <init>   Kafka commitId: f8c67dc3ae0a3265
2023-12-01 16:57:53.843 INFO  ---- [tartedMain] [AppInfoParser:121] <init>   Kafka startTimeMs: 1701417473842
2023-12-01 16:57:53.844 INFO  ---- [tartedMain] [KafkaConsumer:966] subscribe   [Consumer clientId=consumer-task.member.v1-2, groupId=task.member.v1] Subscribed to topic(s): task-member
2023-12-01 16:57:53.848 INFO  ---- [tartedMain] [ConsumerConfig:376] logAll   ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-task.product.v1-3
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = task.product.v1
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2023-12-01 16:57:53.860 INFO  ---- [tartedMain] [AppInfoParser:119] <init>   Kafka version: 3.1.2
2023-12-01 16:57:53.860 INFO  ---- [tartedMain] [AppInfoParser:120] <init>   Kafka commitId: f8c67dc3ae0a3265
2023-12-01 16:57:53.861 INFO  ---- [tartedMain] [AppInfoParser:121] <init>   Kafka startTimeMs: 1701417473860
2023-12-01 16:57:53.861 INFO  ---- [tartedMain] [KafkaConsumer:966] subscribe   [Consumer clientId=consumer-task.product.v1-3, groupId=task.product.v1] Subscribed to topic(s): task-product
2023-12-01 16:57:53.878 INFO  ---- [tartedMain] [TomcatWebServer:220] start   Tomcat started on port(s): 62005 (http) with context path ''
2023-12-01 16:57:53.879 INFO  ---- [tartedMain] [EurekaAutoServiceRegistration:144] onApplicationEvent   Updating port to 62005
2023-12-01 16:57:53.884 INFO  ---- [tartedMain] [InstanceInfoFactory:67] create   Setting initial instance status as: STARTING
2023-12-01 16:57:53.927 INFO  ---- [tartedMain] [DiscoveryClient:372] <init>   Initializing Eureka in region us-east-1
2023-12-01 16:57:53.934 INFO  ---- [tartedMain] [ConfigClusterResolver:43] getClusterEndpoints   Resolving eureka endpoints via configuration
2023-12-01 16:57:53.960 INFO  ---- [tartedMain] [DiscoveryClient:1007] fetchRegistry   Disable delta property : false
2023-12-01 16:57:53.960 INFO  ---- [tartedMain] [DiscoveryClient:1008] fetchRegistry   Single vip registry refresh property : null
2023-12-01 16:57:53.960 INFO  ---- [tartedMain] [DiscoveryClient:1009] fetchRegistry   Force full registry fetch : false
2023-12-01 16:57:53.961 INFO  ---- [tartedMain] [DiscoveryClient:1010] fetchRegistry   Application is null : false
2023-12-01 16:57:53.961 INFO  ---- [tartedMain] [DiscoveryClient:1011] fetchRegistry   Registered Applications size is zero : true
2023-12-01 16:57:53.961 INFO  ---- [tartedMain] [DiscoveryClient:1013] fetchRegistry   Application version is -1: true
2023-12-01 16:57:53.961 INFO  ---- [tartedMain] [DiscoveryClient:1097] getAndStoreFullRegistry   Getting all instance registry info from the eureka server
2023-12-01 16:57:54.147 INFO  ---- [er#0-0-C-1] [Metadata:402] updateLatestMetadata   [Consumer clientId=consumer-task.member.v1-2, groupId=task.member.v1] Resetting the last seen epoch of partition task-member-0 to 0 since the associated topicId changed from null to E7qrzAumTNaqvuwiYhCr-A
2023-12-01 16:57:54.147 INFO  ---- [er#1-0-C-1] [Metadata:402] updateLatestMetadata   [Consumer clientId=consumer-task.product.v1-3, groupId=task.product.v1] Resetting the last seen epoch of partition task-product-0 to 0 since the associated topicId changed from null to bIbTtjUjQhOPBTKjiX5Asw
2023-12-01 16:57:54.147 INFO  ---- [er#2-0-C-1] [Metadata:402] updateLatestMetadata   [Consumer clientId=consumer-order.group.v1-1, groupId=order.group.v1] Resetting the last seen epoch of partition order-0 to 0 since the associated topicId changed from null to wkdBkssoTPWL_MV60_W2Sg
2023-12-01 16:57:54.151 INFO  ---- [er#1-0-C-1] [Metadata:287] update   [Consumer clientId=consumer-task.product.v1-3, groupId=task.product.v1] Cluster ID: 5_U1uds-SGaR4vItj-jqUw
2023-12-01 16:57:54.151 INFO  ---- [er#0-0-C-1] [Metadata:287] update   [Consumer clientId=consumer-task.member.v1-2, groupId=task.member.v1] Cluster ID: 5_U1uds-SGaR4vItj-jqUw
2023-12-01 16:57:54.151 INFO  ---- [er#2-0-C-1] [Metadata:287] update   [Consumer clientId=consumer-order.group.v1-1, groupId=order.group.v1] Cluster ID: 5_U1uds-SGaR4vItj-jqUw
2023-12-01 16:57:54.153 INFO  ---- [er#0-0-C-1] [ConsumerCoordinator:853] onSuccess   [Consumer clientId=consumer-task.member.v1-2, groupId=task.member.v1] Discovered group coordinator 127.0.0.1:9093 (id: 2147483644 rack: null)
2023-12-01 16:57:54.153 INFO  ---- [er#1-0-C-1] [ConsumerCoordinator:853] onSuccess   [Consumer clientId=consumer-task.product.v1-3, groupId=task.product.v1] Discovered group coordinator 127.0.0.1:9091 (id: 2147483646 rack: null)
2023-12-01 16:57:54.153 INFO  ---- [er#2-0-C-1] [ConsumerCoordinator:853] onSuccess   [Consumer clientId=consumer-order.group.v1-1, groupId=order.group.v1] Discovered group coordinator 127.0.0.1:9091 (id: 2147483646 rack: null)
2023-12-01 16:57:54.156 INFO  ---- [er#0-0-C-1] [ConsumerCoordinator:535] sendJoinGroupRequest   [Consumer clientId=consumer-task.member.v1-2, groupId=task.member.v1] (Re-)joining group
2023-12-01 16:57:54.156 INFO  ---- [er#1-0-C-1] [ConsumerCoordinator:535] sendJoinGroupRequest   [Consumer clientId=consumer-task.product.v1-3, groupId=task.product.v1] (Re-)joining group
2023-12-01 16:57:54.156 INFO  ---- [er#2-0-C-1] [ConsumerCoordinator:535] sendJoinGroupRequest   [Consumer clientId=consumer-order.group.v1-1, groupId=order.group.v1] (Re-)joining group
2023-12-01 16:57:54.176 INFO  ---- [er#1-0-C-1] [ConsumerCoordinator:1000] requestRejoin   [Consumer clientId=consumer-task.product.v1-3, groupId=task.product.v1] Request joining group due to: need to re-join with the given member-id
2023-12-01 16:57:54.176 INFO  ---- [er#0-0-C-1] [ConsumerCoordinator:1000] requestRejoin   [Consumer clientId=consumer-task.member.v1-2, groupId=task.member.v1] Request joining group due to: need to re-join with the given member-id
2023-12-01 16:57:54.176 INFO  ---- [er#2-0-C-1] [ConsumerCoordinator:1000] requestRejoin   [Consumer clientId=consumer-order.group.v1-1, groupId=order.group.v1] Request joining group due to: need to re-join with the given member-id
2023-12-01 16:57:54.177 INFO  ---- [er#1-0-C-1] [ConsumerCoordinator:535] sendJoinGroupRequest   [Consumer clientId=consumer-task.product.v1-3, groupId=task.product.v1] (Re-)joining group
2023-12-01 16:57:54.177 INFO  ---- [er#0-0-C-1] [ConsumerCoordinator:535] sendJoinGroupRequest   [Consumer clientId=consumer-task.member.v1-2, groupId=task.member.v1] (Re-)joining group
2023-12-01 16:57:54.177 INFO  ---- [er#2-0-C-1] [ConsumerCoordinator:535] sendJoinGroupRequest   [Consumer clientId=consumer-order.group.v1-1, groupId=order.group.v1] (Re-)joining group
2023-12-01 16:57:54.289 INFO  ---- [tartedMain] [DiscoveryClient:1106] getAndStoreFullRegistry   The response status is 200
2023-12-01 16:57:54.292 INFO  ---- [tartedMain] [DiscoveryClient:1321] initScheduledTasks   Starting heartbeat executor: renew interval is: 30
2023-12-01 16:57:54.294 INFO  ---- [tartedMain] [InstanceInfoReplicator:60] <init>   InstanceInfoReplicator onDemand update allowed rate per min is 4
2023-12-01 16:57:54.299 INFO  ---- [tartedMain] [DiscoveryClient:492] <init>   Discovery Client initialized at timestamp 1701417474298 with initial instances count: 5
2023-12-01 16:57:54.300 INFO  ---- [tartedMain] [EurekaServiceRegistry:41] register   Registering application TASK-SERVICE with eureka with status UP
2023-12-01 16:57:54.301 INFO  ---- [tartedMain] [DiscoveryClient:1352] notify   Saw local status change event StatusChangeEvent [timestamp=1701417474301, current=UP, previous=STARTING]
2023-12-01 16:57:54.303 INFO  ---- [plicator-0] [DiscoveryClient:873] register   DiscoveryClient_TASK-SERVICE/192.168.0.17:08c82ab939e68fefe7ee477be6eb3888: registering service...
2023-12-01 16:57:54.345 INFO  ---- [plicator-0] [DiscoveryClient:882] register   DiscoveryClient_TASK-SERVICE/192.168.0.17:08c82ab939e68fefe7ee477be6eb3888 - registration status: 204
2023-12-01 16:57:55.069 INFO  ---- [tartedMain] [TaskConsumerApplication:61] logStarted   Started TaskConsumerApplication in 10.44 seconds (JVM running for 11.46)
2023-12-01 16:57:57.182 INFO  ---- [er#0-0-C-1] [ConsumerCoordinator:595] handle   [Consumer clientId=consumer-task.member.v1-2, groupId=task.member.v1] Successfully joined group with generation Generation{generationId=5, memberId='consumer-task.member.v1-2-cacb3790-c159-4a94-bd63-5e45f3459c4a', protocol='range'}
2023-12-01 16:57:57.183 INFO  ---- [er#1-0-C-1] [ConsumerCoordinator:595] handle   [Consumer clientId=consumer-task.product.v1-3, groupId=task.product.v1] Successfully joined group with generation Generation{generationId=5, memberId='consumer-task.product.v1-3-fcbad6cb-5df2-45a4-9512-6f5016ea7e7f', protocol='range'}
2023-12-01 16:57:57.182 INFO  ---- [er#2-0-C-1] [ConsumerCoordinator:595] handle   [Consumer clientId=consumer-order.group.v1-1, groupId=order.group.v1] Successfully joined group with generation Generation{generationId=26, memberId='consumer-order.group.v1-1-5415fc36-75f1-4633-9826-44c6844e8cec', protocol='range'}
2023-12-01 16:57:57.185 INFO  ---- [er#0-0-C-1] [ConsumerCoordinator:659] performAssignment   [Consumer clientId=consumer-task.member.v1-2, groupId=task.member.v1] Finished assignment for group at generation 5: {consumer-task.member.v1-2-cacb3790-c159-4a94-bd63-5e45f3459c4a=Assignment(partitions=[task-member-0])}
2023-12-01 16:57:57.185 INFO  ---- [er#2-0-C-1] [ConsumerCoordinator:659] performAssignment   [Consumer clientId=consumer-order.group.v1-1, groupId=order.group.v1] Finished assignment for group at generation 26: {consumer-order.group.v1-1-5415fc36-75f1-4633-9826-44c6844e8cec=Assignment(partitions=[order-0])}
2023-12-01 16:57:57.185 INFO  ---- [er#1-0-C-1] [ConsumerCoordinator:659] performAssignment   [Consumer clientId=consumer-task.product.v1-3, groupId=task.product.v1] Finished assignment for group at generation 5: {consumer-task.product.v1-3-fcbad6cb-5df2-45a4-9512-6f5016ea7e7f=Assignment(partitions=[task-product-0])}
2023-12-01 16:57:57.195 INFO  ---- [er#2-0-C-1] [ConsumerCoordinator:761] handle   [Consumer clientId=consumer-order.group.v1-1, groupId=order.group.v1] Successfully synced group in generation Generation{generationId=26, memberId='consumer-order.group.v1-1-5415fc36-75f1-4633-9826-44c6844e8cec', protocol='range'}
2023-12-01 16:57:57.195 INFO  ---- [er#0-0-C-1] [ConsumerCoordinator:761] handle   [Consumer clientId=consumer-task.member.v1-2, groupId=task.member.v1] Successfully synced group in generation Generation{generationId=5, memberId='consumer-task.member.v1-2-cacb3790-c159-4a94-bd63-5e45f3459c4a', protocol='range'}
2023-12-01 16:57:57.195 INFO  ---- [er#1-0-C-1] [ConsumerCoordinator:761] handle   [Consumer clientId=consumer-task.product.v1-3, groupId=task.product.v1] Successfully synced group in generation Generation{generationId=5, memberId='consumer-task.product.v1-3-fcbad6cb-5df2-45a4-9512-6f5016ea7e7f', protocol='range'}
2023-12-01 16:57:57.197 INFO  ---- [er#2-0-C-1] [ConsumerCoordinator:280] invokeOnAssignment   [Consumer clientId=consumer-order.group.v1-1, groupId=order.group.v1] Notifying assignor about the new Assignment(partitions=[order-0])
2023-12-01 16:57:57.197 INFO  ---- [er#1-0-C-1] [ConsumerCoordinator:280] invokeOnAssignment   [Consumer clientId=consumer-task.product.v1-3, groupId=task.product.v1] Notifying assignor about the new Assignment(partitions=[task-product-0])
2023-12-01 16:57:57.197 INFO  ---- [er#0-0-C-1] [ConsumerCoordinator:280] invokeOnAssignment   [Consumer clientId=consumer-task.member.v1-2, groupId=task.member.v1] Notifying assignor about the new Assignment(partitions=[task-member-0])
2023-12-01 16:57:57.199 INFO  ---- [er#1-0-C-1] [ConsumerCoordinator:292] invokePartitionsAssigned   [Consumer clientId=consumer-task.product.v1-3, groupId=task.product.v1] Adding newly assigned partitions: task-product-0
2023-12-01 16:57:57.199 INFO  ---- [er#0-0-C-1] [ConsumerCoordinator:292] invokePartitionsAssigned   [Consumer clientId=consumer-task.member.v1-2, groupId=task.member.v1] Adding newly assigned partitions: task-member-0
2023-12-01 16:57:57.199 INFO  ---- [er#2-0-C-1] [ConsumerCoordinator:292] invokePartitionsAssigned   [Consumer clientId=consumer-order.group.v1-1, groupId=order.group.v1] Adding newly assigned partitions: order-0
2023-12-01 16:57:57.215 INFO  ---- [er#1-0-C-1] [ConsumerCoordinator:851] refreshCommittedOffsetsIfNeeded   [Consumer clientId=consumer-task.product.v1-3, groupId=task.product.v1] Setting offset for partition task-product-0 to the committed offset FetchPosition{offset=1, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[127.0.0.1:9093 (id: 3 rack: null)], epoch=0}}
2023-12-01 16:57:57.215 INFO  ---- [er#2-0-C-1] [ConsumerCoordinator:851] refreshCommittedOffsetsIfNeeded   [Consumer clientId=consumer-order.group.v1-1, groupId=order.group.v1] Setting offset for partition order-0 to the committed offset FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[127.0.0.1:9092 (id: 2 rack: null)], epoch=0}}
2023-12-01 16:57:57.215 INFO  ---- [er#0-0-C-1] [ConsumerCoordinator:851] refreshCommittedOffsetsIfNeeded   [Consumer clientId=consumer-task.member.v1-2, groupId=task.member.v1] Setting offset for partition task-member-0 to the committed offset FetchPosition{offset=1, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[127.0.0.1:9093 (id: 3 rack: null)], epoch=0}}
2023-12-01 16:57:57.216 INFO  ---- [er#2-0-C-1] [KafkaMessageListenerContainer:292] info   order.group.v1: partitions assigned: [order-0]
2023-12-01 16:57:57.216 INFO  ---- [er#0-0-C-1] [KafkaMessageListenerContainer:292] info   task.member.v1: partitions assigned: [task-member-0]
2023-12-01 16:57:57.216 INFO  ---- [er#1-0-C-1] [KafkaMessageListenerContainer:292] info   task.product.v1: partitions assigned: [task-product-0]
2023-12-01 16:57:57.297 INFO  ---- [er#2-0-C-1] [ProducerConfig:376] logAll   ProducerConfig values: 
	acks = -1
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-1
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2023-12-01 16:57:57.303 INFO  ---- [er#2-0-C-1] [KafkaProducer:572] configureTransactionState   [Producer clientId=producer-1] Instantiated an idempotent producer.
2023-12-01 16:57:57.314 INFO  ---- [er#2-0-C-1] [AppInfoParser:119] <init>   Kafka version: 3.1.2
2023-12-01 16:57:57.314 INFO  ---- [er#2-0-C-1] [AppInfoParser:120] <init>   Kafka commitId: f8c67dc3ae0a3265
2023-12-01 16:57:57.314 INFO  ---- [er#2-0-C-1] [AppInfoParser:121] <init>   Kafka startTimeMs: 1701417477314
2023-12-01 16:57:57.323 INFO  ---- [producer-1] [Metadata:402] updateLatestMetadata   [Producer clientId=producer-1] Resetting the last seen epoch of partition member-check-0 to 0 since the associated topicId changed from null to wGkJy8HQR9S9DeSNaFT1sQ
2023-12-01 16:57:57.323 INFO  ---- [producer-1] [Metadata:287] update   [Producer clientId=producer-1] Cluster ID: 5_U1uds-SGaR4vItj-jqUw
2023-12-01 16:57:57.324 INFO  ---- [producer-1] [TransactionManager:554] setProducerIdAndEpoch   [Producer clientId=producer-1] ProducerId set to 4035 with epoch 0
2023-12-01 16:57:59.652 INFO  ---- [producer-1] [Metadata:402] updateLatestMetadata   [Producer clientId=producer-1] Resetting the last seen epoch of partition product-check-0 to 0 since the associated topicId changed from null to 47KrZrVNRT-GSFQ_B1uyRA
2023-12-01 16:57:59.914 INFO  ---- [producer-1] [Metadata:402] updateLatestMetadata   [Producer clientId=producer-1] Resetting the last seen epoch of partition order-topic-0 to 0 since the associated topicId changed from null to ib1mJqgARzuAvYCkjlzq-A
2023-12-01 17:02:53.967 INFO  ---- [executor-0] [ConfigClusterResolver:43] getClusterEndpoints   Resolving eureka endpoints via configuration
2023-12-01 17:02:57.330 INFO  ---- [producer-1] [Metadata:402] updateLatestMetadata   [Producer clientId=producer-1] Resetting the last seen epoch of partition member-check-0 to 0 since the associated topicId changed from null to wGkJy8HQR9S9DeSNaFT1sQ
2023-12-01 17:02:57.331 INFO  ---- [producer-1] [Metadata:402] updateLatestMetadata   [Producer clientId=producer-1] Resetting the last seen epoch of partition product-check-0 to 0 since the associated topicId changed from null to 47KrZrVNRT-GSFQ_B1uyRA
